2022-01-25 18:22:20,087 - Log file for this run: /disks/disk2/lishengyan/mcuev/max7800-dev/ai8x-training/logs/2022.01.25-182220/2022.01.25-182220.log
2022-01-25 18:22:20,088 - Number of CPUs: 48
2022-01-25 18:22:20,189 - Number of GPUs: 4
2022-01-25 18:22:20,190 - CUDA version: 10.2
2022-01-25 18:22:20,190 - CUDNN version: 7605
2022-01-25 18:22:20,190 - Kernel: 5.11.0-43-generic
2022-01-25 18:22:20,190 - Python: 3.8.11 (default, Aug  3 2021, 15:09:35) 
[GCC 7.5.0]
2022-01-25 18:22:20,190 - pip freeze: {'absl-py': '1.0.0', 'appdirs': '1.4.4', 'argon2-cffi': '21.3.0', 'argon2-cffi-bindings': '21.2.0', 'asttokens': '2.0.5', 'atomicwrites': '1.4.0', 'attrs': '21.4.0', 'audioread': '2.1.9', 'backcall': '0.2.0', 'black': '21.12b0', 'bleach': '4.1.0', 'bqplot': '0.11.5', 'cachetools': '4.2.4', 'certifi': '2021.10.8', 'cffi': '1.15.0', 'charset-normalizer': '2.0.10', 'click': '8.0.3', 'cloudpickle': '2.0.0', 'colorama': '0.4.4', 'cycler': '0.11.0', 'debugpy': '1.5.1', 'decorator': '5.1.1', 'defusedxml': '0.7.1', 'deprecated': '1.2.13', 'distiller': '0.4.0rc0', 'entrypoints': '0.3', 'executing': '0.8.2', 'fonttools': '4.28.5', 'future': '0.18.2', 'gitdb': '4.0.9', 'gitpython': '3.1.26', 'google-auth': '1.35.0', 'google-auth-oauthlib': '0.4.6', 'graphviz': '0.10.1', 'grpcio': '1.43.0', 'gym': '0.12.5', 'idna': '3.3', 'importlib-metadata': '4.10.1', 'importlib-resources': '5.4.0', 'ipykernel': '6.7.0', 'ipython': '8.0.1', 'ipython-genutils': '0.2.0', 'ipywidgets': '7.4.2', 'jedi': '0.18.1', 'jinja2': '3.0.3', 'joblib': '1.1.0', 'jsonpatch': '1.32', 'jsonpointer': '2.2', 'jsonschema': '4.4.0', 'jupyter': '1.0.0', 'jupyter-client': '7.1.2', 'jupyter-console': '6.4.0', 'jupyter-core': '4.9.1', 'jupyterlab-pygments': '0.1.2', 'kiwisolver': '1.3.2', 'librosa': '0.8.1', 'llvmlite': '0.32.1', 'markdown': '3.3.6', 'markupsafe': '2.0.1', 'matplotlib': '3.5.1', 'matplotlib-inline': '0.1.3', 'mistune': '0.8.4', 'more-itertools': '8.12.0', 'munch': '2.5.0', 'mypy-extensions': '0.4.3', 'nbclient': '0.5.10', 'nbconvert': '6.4.0', 'nbformat': '5.1.3', 'nest-asyncio': '1.5.4', 'notebook': '6.4.7', 'numba': '0.49.1', 'numpy': '1.20.3', 'oauthlib': '3.1.1', 'onnx': '1.10.2', 'opencv-python': '4.5.5.62', 'packaging': '21.3', 'pandas': '1.4.0', 'pandocfilters': '1.5.0', 'parso': '0.8.3', 'pathspec': '0.9.0', 'pexpect': '4.8.0', 'pickleshare': '0.7.5', 'pillow': '9.0.0', 'pip': '21.3.1', 'platformdirs': '2.4.1', 'pluggy': '0.13.1', 'pooch': '1.6.0', 'pretrainedmodels': '0.7.4', 'prometheus-client': '0.12.0', 'prompt-toolkit': '3.0.24', 'protobuf': '3.19.3', 'ptyprocess': '0.7.0', 'pure-eval': '0.2.2', 'py': '1.11.0', 'pyasn1': '0.4.8', 'pyasn1-modules': '0.2.8', 'pycparser': '2.21', 'pydot': '1.4.1', 'pygithub': '1.55', 'pyglet': '1.5.21', 'pygments': '2.11.2', 'pyjwt': '2.3.0', 'pynacl': '1.5.0', 'pyparsing': '3.0.7', 'pyrsistent': '0.18.1', 'pytest': '4.6.11', 'python-dateutil': '2.8.2', 'pytsmod': '0.3.3', 'pytz': '2021.3', 'pyyaml': '6.0', 'pyzmq': '22.3.0', 'qgrid': '1.1.1', 'qtconsole': '5.2.2', 'qtpy': '2.0.0', 'requests': '2.27.1', 'requests-oauthlib': '1.3.0', 'resampy': '0.2.2', 'rsa': '4.8', 'scikit-learn': '0.23.2', 'scipy': '1.7.3', 'send2trash': '1.8.0', 'setuptools': '60.5.0', 'shap': '0.40.0', 'six': '1.16.0', 'slicer': '0.0.7', 'smmap': '5.0.0', 'soundfile': '0.10.3.post1', 'stack-data': '0.1.4', 'tabulate': '0.8.3', 'tensorboard': '2.4.1', 'tensorboard-plugin-wit': '1.8.1', 'terminado': '0.12.1', 'testpath': '0.5.0', 'threadpoolctl': '3.0.0', 'tk': '0.1.0', 'tomli': '1.2.3', 'torch': '1.8.1', 'torchfile': '0.1.0', 'torchnet': '0.0.4', 'torchvision': '0.9.1', 'tornado': '6.1', 'tqdm': '4.33.0', 'traitlets': '5.1.1', 'traittypes': '0.2.1', 'typing-extensions': '4.0.1', 'urllib3': '1.26.8', 'visdom': '0.1.8.9', 'wcwidth': '0.2.5', 'webencodings': '0.5.1', 'websocket-client': '1.2.3', 'werkzeug': '2.0.2', 'wheel': '0.37.1', 'widgetsnbextension': '3.4.2', 'wrapt': '1.13.3', 'xlsxwriter': '3.0.2', 'yamllint': '1.26.3', 'zipp': '3.7.0'}
2022-01-25 18:22:20,190 - Command line: train.py --gpus 0 --epochs 100 --deterministic --compress schedule.yaml --model ai85net5 --dataset MNIST --confusion --param-hist --pr-curves --embedding --device MAX78000
2022-01-25 18:22:20,191 - Distiller: 0.4.0rc0
2022-01-25 18:22:20,191 - set_deterministic was invoked
2022-01-25 18:22:22,916 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2022-01-25 18:22:22,917 - Optimizer Args: {'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False}
2022-01-25 18:22:30,410 - The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)

2022-01-25 18:22:30,553 - set_deterministic was invoked
2022-01-25 18:22:30,561 - Dataset sizes:
	training=54000
	validation=6000
	test=10000
2022-01-25 18:22:30,562 - Reading compression schedule from: schedule.yaml
2022-01-25 18:22:30,564 - Schedule contents:
{
  "lr_schedulers": {
    "training_lr": {
      "class": "MultiStepLR",
      "milestones": [
        100,
        140,
        170
      ],
      "gamma": 0.1
    }
  },
  "policies": [
    {
      "lr_scheduler": {
        "instance_name": "training_lr"
      },
      "starting_epoch": 0,
      "ending_epoch": 200,
      "frequency": 1
    }
  ]
}
2022-01-25 18:22:30,567 - 

2022-01-25 18:22:30,567 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:22:31,323 - Epoch: [0][   10/  211]    Overall Loss 2.298435    Objective Loss 2.298435                                        LR 0.100000    Time 0.075526    
2022-01-25 18:22:31,524 - Epoch: [0][   20/  211]    Overall Loss 2.267120    Objective Loss 2.267120                                        LR 0.100000    Time 0.047798    
2022-01-25 18:22:31,760 - Epoch: [0][   30/  211]    Overall Loss 2.208791    Objective Loss 2.208791                                        LR 0.100000    Time 0.039710    
2022-01-25 18:22:31,954 - Epoch: [0][   40/  211]    Overall Loss 2.098299    Objective Loss 2.098299                                        LR 0.100000    Time 0.034632    
2022-01-25 18:22:32,189 - Epoch: [0][   50/  211]    Overall Loss 1.961854    Objective Loss 1.961854                                        LR 0.100000    Time 0.032401    
2022-01-25 18:22:32,391 - Epoch: [0][   60/  211]    Overall Loss 1.831510    Objective Loss 1.831510                                        LR 0.100000    Time 0.030364    
2022-01-25 18:22:32,634 - Epoch: [0][   70/  211]    Overall Loss 1.698363    Objective Loss 1.698363                                        LR 0.100000    Time 0.029485    
2022-01-25 18:22:32,836 - Epoch: [0][   80/  211]    Overall Loss 1.595781    Objective Loss 1.595781                                        LR 0.100000    Time 0.028319    
2022-01-25 18:22:33,073 - Epoch: [0][   90/  211]    Overall Loss 1.496473    Objective Loss 1.496473                                        LR 0.100000    Time 0.027807    
2022-01-25 18:22:33,274 - Epoch: [0][  100/  211]    Overall Loss 1.406879    Objective Loss 1.406879                                        LR 0.100000    Time 0.027029    
2022-01-25 18:22:33,519 - Epoch: [0][  110/  211]    Overall Loss 1.336988    Objective Loss 1.336988                                        LR 0.100000    Time 0.026797    
2022-01-25 18:22:33,719 - Epoch: [0][  120/  211]    Overall Loss 1.272065    Objective Loss 1.272065                                        LR 0.100000    Time 0.026227    
2022-01-25 18:22:33,957 - Epoch: [0][  130/  211]    Overall Loss 1.212060    Objective Loss 1.212060                                        LR 0.100000    Time 0.026037    
2022-01-25 18:22:34,157 - Epoch: [0][  140/  211]    Overall Loss 1.154519    Objective Loss 1.154519                                        LR 0.100000    Time 0.025607    
2022-01-25 18:22:34,401 - Epoch: [0][  150/  211]    Overall Loss 1.104796    Objective Loss 1.104796                                        LR 0.100000    Time 0.025523    
2022-01-25 18:22:34,599 - Epoch: [0][  160/  211]    Overall Loss 1.057746    Objective Loss 1.057746                                        LR 0.100000    Time 0.025162    
2022-01-25 18:22:34,839 - Epoch: [0][  170/  211]    Overall Loss 1.014214    Objective Loss 1.014214                                        LR 0.100000    Time 0.025094    
2022-01-25 18:22:35,038 - Epoch: [0][  180/  211]    Overall Loss 0.974867    Objective Loss 0.974867                                        LR 0.100000    Time 0.024799    
2022-01-25 18:22:35,277 - Epoch: [0][  190/  211]    Overall Loss 0.939530    Objective Loss 0.939530                                        LR 0.100000    Time 0.024750    
2022-01-25 18:22:35,483 - Epoch: [0][  200/  211]    Overall Loss 0.907891    Objective Loss 0.907891                                        LR 0.100000    Time 0.024545    
2022-01-25 18:22:35,718 - Epoch: [0][  210/  211]    Overall Loss 0.877590    Objective Loss 0.877590    Top1 91.406250    Top5 99.218750    LR 0.100000    Time 0.024491    
2022-01-25 18:22:35,733 - Epoch: [0][  211/  211]    Overall Loss 0.875117    Objective Loss 0.875117    Top1 91.129032    Top5 98.991935    LR 0.100000    Time 0.024446    
2022-01-25 18:22:35,790 - --- validate (epoch=0)-----------
2022-01-25 18:22:35,791 - 6000 samples (256 per mini-batch)
2022-01-25 18:22:36,252 - Epoch: [0][   10/   24]    Loss 0.253814    Top1 92.578125    Top5 99.765625    
2022-01-25 18:22:36,440 - Epoch: [0][   20/   24]    Loss 0.259718    Top1 92.402344    Top5 99.687500    
2022-01-25 18:22:36,526 - Epoch: [0][   24/   24]    Loss 0.261173    Top1 92.250000    Top5 99.683333    
2022-01-25 18:22:36,580 - ==> Top1: 92.250    Top5: 99.683    Loss: 0.261

2022-01-25 18:22:36,581 - ==> Confusion:
[[563   1   9   1   1   3  10   2  11   4]
 [  0 670   6   1   3   0   4   3   1   0]
 [  1   1 536  11   4   2   3  11  15   2]
 [  0   1  12 548   0   4   1   8   7   2]
 [  3   4   9   0 507   1   7   9   3  22]
 [  0   1   7  10   2 466   8   4  11   9]
 [  3   2   4   0   7   3 603   0   9   0]
 [  0   5  20  12   2   6   0 562   0  18]
 [  0   1  10   2   5   8  16   1 530  11]
 [  2   2   9  11  13  10   2   7   9 550]]

2022-01-25 18:22:36,584 - ==> Best [Top1: 92.250   Top5: 99.683   Sparsity:0.00   Params: 71148 on epoch: 0]
2022-01-25 18:22:36,584 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:22:36,592 - 

2022-01-25 18:22:36,592 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:22:37,487 - Epoch: [1][   10/  211]    Overall Loss 0.276141    Objective Loss 0.276141                                        LR 0.100000    Time 0.089396    
2022-01-25 18:22:37,726 - Epoch: [1][   20/  211]    Overall Loss 0.276881    Objective Loss 0.276881                                        LR 0.100000    Time 0.056622    
2022-01-25 18:22:38,013 - Epoch: [1][   30/  211]    Overall Loss 0.278511    Objective Loss 0.278511                                        LR 0.100000    Time 0.047297    
2022-01-25 18:22:38,246 - Epoch: [1][   40/  211]    Overall Loss 0.284240    Objective Loss 0.284240                                        LR 0.100000    Time 0.041308    
2022-01-25 18:22:38,547 - Epoch: [1][   50/  211]    Overall Loss 0.282717    Objective Loss 0.282717                                        LR 0.100000    Time 0.039057    
2022-01-25 18:22:38,787 - Epoch: [1][   60/  211]    Overall Loss 0.276010    Objective Loss 0.276010                                        LR 0.100000    Time 0.036538    
2022-01-25 18:22:39,085 - Epoch: [1][   70/  211]    Overall Loss 0.266631    Objective Loss 0.266631                                        LR 0.100000    Time 0.035568    
2022-01-25 18:22:39,319 - Epoch: [1][   80/  211]    Overall Loss 0.260289    Objective Loss 0.260289                                        LR 0.100000    Time 0.034041    
2022-01-25 18:22:39,609 - Epoch: [1][   90/  211]    Overall Loss 0.255703    Objective Loss 0.255703                                        LR 0.100000    Time 0.033478    
2022-01-25 18:22:39,850 - Epoch: [1][  100/  211]    Overall Loss 0.252355    Objective Loss 0.252355                                        LR 0.100000    Time 0.032534    
2022-01-25 18:22:40,153 - Epoch: [1][  110/  211]    Overall Loss 0.250043    Objective Loss 0.250043                                        LR 0.100000    Time 0.032328    
2022-01-25 18:22:40,383 - Epoch: [1][  120/  211]    Overall Loss 0.247842    Objective Loss 0.247842                                        LR 0.100000    Time 0.031548    
2022-01-25 18:22:40,673 - Epoch: [1][  130/  211]    Overall Loss 0.244201    Objective Loss 0.244201                                        LR 0.100000    Time 0.031350    
2022-01-25 18:22:40,911 - Epoch: [1][  140/  211]    Overall Loss 0.239624    Objective Loss 0.239624                                        LR 0.100000    Time 0.030804    
2022-01-25 18:22:41,154 - Epoch: [1][  150/  211]    Overall Loss 0.236154    Objective Loss 0.236154                                        LR 0.100000    Time 0.030369    
2022-01-25 18:22:41,357 - Epoch: [1][  160/  211]    Overall Loss 0.234157    Objective Loss 0.234157                                        LR 0.100000    Time 0.029723    
2022-01-25 18:22:41,596 - Epoch: [1][  170/  211]    Overall Loss 0.230125    Objective Loss 0.230125                                        LR 0.100000    Time 0.029380    
2022-01-25 18:22:41,787 - Epoch: [1][  180/  211]    Overall Loss 0.228616    Objective Loss 0.228616                                        LR 0.100000    Time 0.028808    
2022-01-25 18:22:42,017 - Epoch: [1][  190/  211]    Overall Loss 0.227552    Objective Loss 0.227552                                        LR 0.100000    Time 0.028502    
2022-01-25 18:22:42,210 - Epoch: [1][  200/  211]    Overall Loss 0.226893    Objective Loss 0.226893                                        LR 0.100000    Time 0.028040    
2022-01-25 18:22:42,448 - Epoch: [1][  210/  211]    Overall Loss 0.225994    Objective Loss 0.225994    Top1 94.140625    Top5 100.000000    LR 0.100000    Time 0.027832    
2022-01-25 18:22:42,459 - Epoch: [1][  211/  211]    Overall Loss 0.225845    Objective Loss 0.225845    Top1 93.750000    Top5 99.798387    LR 0.100000    Time 0.027752    
2022-01-25 18:22:42,554 - --- validate (epoch=1)-----------
2022-01-25 18:22:42,555 - 6000 samples (256 per mini-batch)
2022-01-25 18:22:43,092 - Epoch: [1][   10/   24]    Loss 0.183106    Top1 94.335938    Top5 99.882812    
2022-01-25 18:22:43,272 - Epoch: [1][   20/   24]    Loss 0.182713    Top1 94.335938    Top5 99.785156    
2022-01-25 18:22:43,357 - Epoch: [1][   24/   24]    Loss 0.182584    Top1 94.216667    Top5 99.750000    
2022-01-25 18:22:43,419 - ==> Top1: 94.217    Top5: 99.750    Loss: 0.183

2022-01-25 18:22:43,419 - ==> Confusion:
[[599   0   2   0   0   0   2   0   2   0]
 [  3 668   6   0   4   1   2   4   0   0]
 [ 13   1 552   0   2   2   0  10   6   0]
 [  6   0  22 534   1   7   0   5   8   0]
 [  2   0   4   1 548   0   2   1   0   7]
 [ 12   0   2   0   3 480   5   1  10   5]
 [ 11   0   1   0   7   3 598   0  11   0]
 [  5   2   8   1   9   2   0 590   1   7]
 [ 19   0   5   0   8   0  12   0 532   8]
 [ 10   0   1   0  29   9   0   7   7 552]]

2022-01-25 18:22:43,421 - ==> Best [Top1: 94.217   Top5: 99.750   Sparsity:0.00   Params: 71148 on epoch: 1]
2022-01-25 18:22:43,421 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:22:43,428 - 

2022-01-25 18:22:43,428 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:22:43,996 - Epoch: [2][   10/  211]    Overall Loss 0.182607    Objective Loss 0.182607                                        LR 0.100000    Time 0.056726    
2022-01-25 18:22:44,228 - Epoch: [2][   20/  211]    Overall Loss 0.186662    Objective Loss 0.186662                                        LR 0.100000    Time 0.039930    
2022-01-25 18:22:44,505 - Epoch: [2][   30/  211]    Overall Loss 0.190632    Objective Loss 0.190632                                        LR 0.100000    Time 0.035861    
2022-01-25 18:22:44,722 - Epoch: [2][   40/  211]    Overall Loss 0.190941    Objective Loss 0.190941                                        LR 0.100000    Time 0.032290    
2022-01-25 18:22:44,960 - Epoch: [2][   50/  211]    Overall Loss 0.192170    Objective Loss 0.192170                                        LR 0.100000    Time 0.030603    
2022-01-25 18:22:45,164 - Epoch: [2][   60/  211]    Overall Loss 0.194475    Objective Loss 0.194475                                        LR 0.100000    Time 0.028891    
2022-01-25 18:22:45,405 - Epoch: [2][   70/  211]    Overall Loss 0.189847    Objective Loss 0.189847                                        LR 0.100000    Time 0.028202    
2022-01-25 18:22:45,605 - Epoch: [2][   80/  211]    Overall Loss 0.187377    Objective Loss 0.187377                                        LR 0.100000    Time 0.027170    
2022-01-25 18:22:45,840 - Epoch: [2][   90/  211]    Overall Loss 0.188088    Objective Loss 0.188088                                        LR 0.100000    Time 0.026759    
2022-01-25 18:22:46,042 - Epoch: [2][  100/  211]    Overall Loss 0.186999    Objective Loss 0.186999                                        LR 0.100000    Time 0.026094    
2022-01-25 18:22:46,285 - Epoch: [2][  110/  211]    Overall Loss 0.184339    Objective Loss 0.184339                                        LR 0.100000    Time 0.025936    
2022-01-25 18:22:46,491 - Epoch: [2][  120/  211]    Overall Loss 0.183865    Objective Loss 0.183865                                        LR 0.100000    Time 0.025482    
2022-01-25 18:22:46,727 - Epoch: [2][  130/  211]    Overall Loss 0.183053    Objective Loss 0.183053                                        LR 0.100000    Time 0.025333    
2022-01-25 18:22:46,924 - Epoch: [2][  140/  211]    Overall Loss 0.182409    Objective Loss 0.182409                                        LR 0.100000    Time 0.024932    
2022-01-25 18:22:47,165 - Epoch: [2][  150/  211]    Overall Loss 0.181531    Objective Loss 0.181531                                        LR 0.100000    Time 0.024872    
2022-01-25 18:22:47,374 - Epoch: [2][  160/  211]    Overall Loss 0.179875    Objective Loss 0.179875                                        LR 0.100000    Time 0.024621    
2022-01-25 18:22:47,604 - Epoch: [2][  170/  211]    Overall Loss 0.179883    Objective Loss 0.179883                                        LR 0.100000    Time 0.024526    
2022-01-25 18:22:47,800 - Epoch: [2][  180/  211]    Overall Loss 0.177945    Objective Loss 0.177945                                        LR 0.100000    Time 0.024249    
2022-01-25 18:22:48,034 - Epoch: [2][  190/  211]    Overall Loss 0.175961    Objective Loss 0.175961                                        LR 0.100000    Time 0.024201    
2022-01-25 18:22:48,232 - Epoch: [2][  200/  211]    Overall Loss 0.173870    Objective Loss 0.173870                                        LR 0.100000    Time 0.023980    
2022-01-25 18:22:48,472 - Epoch: [2][  210/  211]    Overall Loss 0.172032    Objective Loss 0.172032    Top1 96.875000    Top5 100.000000    LR 0.100000    Time 0.023979    
2022-01-25 18:22:48,484 - Epoch: [2][  211/  211]    Overall Loss 0.171697    Objective Loss 0.171697    Top1 96.572581    Top5 100.000000    LR 0.100000    Time 0.023922    
2022-01-25 18:22:48,567 - --- validate (epoch=2)-----------
2022-01-25 18:22:48,567 - 6000 samples (256 per mini-batch)
2022-01-25 18:22:49,030 - Epoch: [2][   10/   24]    Loss 0.145586    Top1 95.781250    Top5 99.726562    
2022-01-25 18:22:49,216 - Epoch: [2][   20/   24]    Loss 0.142281    Top1 95.937500    Top5 99.785156    
2022-01-25 18:22:49,299 - Epoch: [2][   24/   24]    Loss 0.139662    Top1 96.016667    Top5 99.800000    
2022-01-25 18:22:49,358 - ==> Top1: 96.017    Top5: 99.800    Loss: 0.140

2022-01-25 18:22:49,358 - ==> Confusion:
[[596   0   2   1   0   2   3   1   0   0]
 [  0 684   1   1   1   0   0   1   0   0]
 [  1   6 540   3   3   3   0  23   2   5]
 [  0   2   5 557   0   7   0   8   3   1]
 [  0   2   1   1 550   0   0   2   0   9]
 [  0   2   1   1   1 507   3   0   2   1]
 [  4   2   0   0   7   9 603   0   6   0]
 [  0   2   1   1   3   1   0 615   0   2]
 [  5   1   4   3   7   6   8   2 537  11]
 [  3   2   0   4  12   7   0  11   4 572]]

2022-01-25 18:22:49,360 - ==> Best [Top1: 96.017   Top5: 99.800   Sparsity:0.00   Params: 71148 on epoch: 2]
2022-01-25 18:22:49,360 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:22:49,367 - 

2022-01-25 18:22:49,367 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:22:50,163 - Epoch: [3][   10/  211]    Overall Loss 0.142089    Objective Loss 0.142089                                        LR 0.100000    Time 0.079539    
2022-01-25 18:22:50,373 - Epoch: [3][   20/  211]    Overall Loss 0.140792    Objective Loss 0.140792                                        LR 0.100000    Time 0.050252    
2022-01-25 18:22:50,610 - Epoch: [3][   30/  211]    Overall Loss 0.142988    Objective Loss 0.142988                                        LR 0.100000    Time 0.041377    
2022-01-25 18:22:50,808 - Epoch: [3][   40/  211]    Overall Loss 0.141335    Objective Loss 0.141335                                        LR 0.100000    Time 0.035981    
2022-01-25 18:22:51,049 - Epoch: [3][   50/  211]    Overall Loss 0.143136    Objective Loss 0.143136                                        LR 0.100000    Time 0.033592    
2022-01-25 18:22:51,246 - Epoch: [3][   60/  211]    Overall Loss 0.142967    Objective Loss 0.142967                                        LR 0.100000    Time 0.031278    
2022-01-25 18:22:51,482 - Epoch: [3][   70/  211]    Overall Loss 0.143173    Objective Loss 0.143173                                        LR 0.100000    Time 0.030178    
2022-01-25 18:22:51,698 - Epoch: [3][   80/  211]    Overall Loss 0.141425    Objective Loss 0.141425                                        LR 0.100000    Time 0.029093    
2022-01-25 18:22:51,934 - Epoch: [3][   90/  211]    Overall Loss 0.140507    Objective Loss 0.140507                                        LR 0.100000    Time 0.028478    
2022-01-25 18:22:52,136 - Epoch: [3][  100/  211]    Overall Loss 0.142827    Objective Loss 0.142827                                        LR 0.100000    Time 0.027652    
2022-01-25 18:22:52,373 - Epoch: [3][  110/  211]    Overall Loss 0.144484    Objective Loss 0.144484                                        LR 0.100000    Time 0.027292    
2022-01-25 18:22:52,573 - Epoch: [3][  120/  211]    Overall Loss 0.141739    Objective Loss 0.141739                                        LR 0.100000    Time 0.026678    
2022-01-25 18:22:52,814 - Epoch: [3][  130/  211]    Overall Loss 0.140448    Objective Loss 0.140448                                        LR 0.100000    Time 0.026479    
2022-01-25 18:22:53,013 - Epoch: [3][  140/  211]    Overall Loss 0.138527    Objective Loss 0.138527                                        LR 0.100000    Time 0.026008    
2022-01-25 18:22:53,262 - Epoch: [3][  150/  211]    Overall Loss 0.137249    Objective Loss 0.137249                                        LR 0.100000    Time 0.025928    
2022-01-25 18:22:53,461 - Epoch: [3][  160/  211]    Overall Loss 0.135747    Objective Loss 0.135747                                        LR 0.100000    Time 0.025551    
2022-01-25 18:22:53,697 - Epoch: [3][  170/  211]    Overall Loss 0.134177    Objective Loss 0.134177                                        LR 0.100000    Time 0.025435    
2022-01-25 18:22:53,899 - Epoch: [3][  180/  211]    Overall Loss 0.133312    Objective Loss 0.133312                                        LR 0.100000    Time 0.025140    
2022-01-25 18:22:54,133 - Epoch: [3][  190/  211]    Overall Loss 0.132102    Objective Loss 0.132102                                        LR 0.100000    Time 0.025051    
2022-01-25 18:22:54,336 - Epoch: [3][  200/  211]    Overall Loss 0.132313    Objective Loss 0.132313                                        LR 0.100000    Time 0.024808    
2022-01-25 18:22:54,575 - Epoch: [3][  210/  211]    Overall Loss 0.131280    Objective Loss 0.131280    Top1 96.875000    Top5 99.609375    LR 0.100000    Time 0.024766    
2022-01-25 18:22:54,589 - Epoch: [3][  211/  211]    Overall Loss 0.131450    Objective Loss 0.131450    Top1 95.766129    Top5 99.798387    LR 0.100000    Time 0.024712    
2022-01-25 18:22:54,662 - --- validate (epoch=3)-----------
2022-01-25 18:22:54,662 - 6000 samples (256 per mini-batch)
2022-01-25 18:22:55,133 - Epoch: [3][   10/   24]    Loss 0.109644    Top1 96.679688    Top5 99.921875    
2022-01-25 18:22:55,336 - Epoch: [3][   20/   24]    Loss 0.115118    Top1 96.601562    Top5 99.902344    
2022-01-25 18:22:55,440 - Epoch: [3][   24/   24]    Loss 0.115080    Top1 96.583333    Top5 99.916667    
2022-01-25 18:22:55,492 - ==> Top1: 96.583    Top5: 99.917    Loss: 0.115

2022-01-25 18:22:55,493 - ==> Confusion:
[[601   0   1   0   0   0   1   0   1   1]
 [  0 675   4   3   0   1   0   4   0   1]
 [  1   1 570   4   0   0   0   8   1   1]
 [  0   0   7 565   0   3   0   4   3   1]
 [  0   1   6   0 537   0   1   4   2  14]
 [  2   0   1   2   1 507   1   1   2   1]
 [  5   1   4   0   3  18 596   0   4   0]
 [  0   6  10   2   2   0   0 604   0   1]
 [  3   0   7   3   2   5   2   2 555   5]
 [  4   2   1   4   5   5   0   6   3 585]]

2022-01-25 18:22:55,495 - ==> Best [Top1: 96.583   Top5: 99.917   Sparsity:0.00   Params: 71148 on epoch: 3]
2022-01-25 18:22:55,495 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:22:55,504 - 

2022-01-25 18:22:55,504 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:22:56,198 - Epoch: [4][   10/  211]    Overall Loss 0.116918    Objective Loss 0.116918                                        LR 0.100000    Time 0.069380    
2022-01-25 18:22:56,392 - Epoch: [4][   20/  211]    Overall Loss 0.123314    Objective Loss 0.123314                                        LR 0.100000    Time 0.044380    
2022-01-25 18:22:56,628 - Epoch: [4][   30/  211]    Overall Loss 0.124627    Objective Loss 0.124627                                        LR 0.100000    Time 0.037422    
2022-01-25 18:22:56,825 - Epoch: [4][   40/  211]    Overall Loss 0.120461    Objective Loss 0.120461                                        LR 0.100000    Time 0.032990    
2022-01-25 18:22:57,064 - Epoch: [4][   50/  211]    Overall Loss 0.120616    Objective Loss 0.120616                                        LR 0.100000    Time 0.031163    
2022-01-25 18:22:57,262 - Epoch: [4][   60/  211]    Overall Loss 0.121601    Objective Loss 0.121601                                        LR 0.100000    Time 0.029258    
2022-01-25 18:22:57,507 - Epoch: [4][   70/  211]    Overall Loss 0.125698    Objective Loss 0.125698                                        LR 0.100000    Time 0.028579    
2022-01-25 18:22:57,703 - Epoch: [4][   80/  211]    Overall Loss 0.127788    Objective Loss 0.127788                                        LR 0.100000    Time 0.027443    
2022-01-25 18:22:57,940 - Epoch: [4][   90/  211]    Overall Loss 0.126478    Objective Loss 0.126478                                        LR 0.100000    Time 0.027022    
2022-01-25 18:22:58,137 - Epoch: [4][  100/  211]    Overall Loss 0.125654    Objective Loss 0.125654                                        LR 0.100000    Time 0.026290    
2022-01-25 18:22:58,377 - Epoch: [4][  110/  211]    Overall Loss 0.126301    Objective Loss 0.126301                                        LR 0.100000    Time 0.026082    
2022-01-25 18:22:58,573 - Epoch: [4][  120/  211]    Overall Loss 0.125453    Objective Loss 0.125453                                        LR 0.100000    Time 0.025532    
2022-01-25 18:22:58,815 - Epoch: [4][  130/  211]    Overall Loss 0.126031    Objective Loss 0.126031                                        LR 0.100000    Time 0.025428    
2022-01-25 18:22:59,014 - Epoch: [4][  140/  211]    Overall Loss 0.126689    Objective Loss 0.126689                                        LR 0.100000    Time 0.025030    
2022-01-25 18:22:59,249 - Epoch: [4][  150/  211]    Overall Loss 0.126071    Objective Loss 0.126071                                        LR 0.100000    Time 0.024925    
2022-01-25 18:22:59,451 - Epoch: [4][  160/  211]    Overall Loss 0.126022    Objective Loss 0.126022                                        LR 0.100000    Time 0.024628    
2022-01-25 18:22:59,686 - Epoch: [4][  170/  211]    Overall Loss 0.125945    Objective Loss 0.125945                                        LR 0.100000    Time 0.024560    
2022-01-25 18:22:59,883 - Epoch: [4][  180/  211]    Overall Loss 0.124670    Objective Loss 0.124670                                        LR 0.100000    Time 0.024290    
2022-01-25 18:23:00,126 - Epoch: [4][  190/  211]    Overall Loss 0.124261    Objective Loss 0.124261                                        LR 0.100000    Time 0.024288    
2022-01-25 18:23:00,323 - Epoch: [4][  200/  211]    Overall Loss 0.124696    Objective Loss 0.124696                                        LR 0.100000    Time 0.024057    
2022-01-25 18:23:00,556 - Epoch: [4][  210/  211]    Overall Loss 0.124881    Objective Loss 0.124881    Top1 93.359375    Top5 100.000000    LR 0.100000    Time 0.024022    
2022-01-25 18:23:00,569 - Epoch: [4][  211/  211]    Overall Loss 0.124789    Objective Loss 0.124789    Top1 94.758065    Top5 100.000000    LR 0.100000    Time 0.023967    
2022-01-25 18:23:00,625 - --- validate (epoch=4)-----------
2022-01-25 18:23:00,626 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:01,086 - Epoch: [4][   10/   24]    Loss 0.102970    Top1 96.835938    Top5 99.921875    
2022-01-25 18:23:01,280 - Epoch: [4][   20/   24]    Loss 0.104721    Top1 96.777344    Top5 99.921875    
2022-01-25 18:23:01,364 - Epoch: [4][   24/   24]    Loss 0.108585    Top1 96.566667    Top5 99.933333    
2022-01-25 18:23:01,426 - ==> Top1: 96.567    Top5: 99.933    Loss: 0.109

2022-01-25 18:23:01,427 - ==> Confusion:
[[580   0   2   2   0   5   6   0   5   5]
 [  0 679   4   2   1   0   0   2   0   0]
 [  0   2 556  11   1   0   1  10   3   2]
 [  0   0   0 571   0   3   0   6   2   1]
 [  0   1   3   0 539   0   2   4   1  15]
 [  0   0   0   4   0 507   4   0   3   0]
 [  2   1   0   0   3   8 615   0   1   1]
 [  0   5   4   5   1   0   0 604   0   6]
 [  1   0   2   5   4   3  11   0 550   8]
 [  1   1   0   4   4   4   2   4   2 593]]

2022-01-25 18:23:01,429 - ==> Best [Top1: 96.583   Top5: 99.917   Sparsity:0.00   Params: 71148 on epoch: 3]
2022-01-25 18:23:01,429 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:23:01,435 - 

2022-01-25 18:23:01,436 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:01,977 - Epoch: [5][   10/  211]    Overall Loss 0.128198    Objective Loss 0.128198                                        LR 0.100000    Time 0.054078    
2022-01-25 18:23:02,175 - Epoch: [5][   20/  211]    Overall Loss 0.133283    Objective Loss 0.133283                                        LR 0.100000    Time 0.036921    
2022-01-25 18:23:02,406 - Epoch: [5][   30/  211]    Overall Loss 0.124746    Objective Loss 0.124746                                        LR 0.100000    Time 0.032285    
2022-01-25 18:23:02,600 - Epoch: [5][   40/  211]    Overall Loss 0.127132    Objective Loss 0.127132                                        LR 0.100000    Time 0.029070    
2022-01-25 18:23:02,833 - Epoch: [5][   50/  211]    Overall Loss 0.122049    Objective Loss 0.122049                                        LR 0.100000    Time 0.027903    
2022-01-25 18:23:03,033 - Epoch: [5][   60/  211]    Overall Loss 0.125111    Objective Loss 0.125111                                        LR 0.100000    Time 0.026575    
2022-01-25 18:23:03,274 - Epoch: [5][   70/  211]    Overall Loss 0.127167    Objective Loss 0.127167                                        LR 0.100000    Time 0.026217    
2022-01-25 18:23:03,473 - Epoch: [5][   80/  211]    Overall Loss 0.126112    Objective Loss 0.126112                                        LR 0.100000    Time 0.025425    
2022-01-25 18:23:03,712 - Epoch: [5][   90/  211]    Overall Loss 0.125220    Objective Loss 0.125220                                        LR 0.100000    Time 0.025252    
2022-01-25 18:23:03,909 - Epoch: [5][  100/  211]    Overall Loss 0.125193    Objective Loss 0.125193                                        LR 0.100000    Time 0.024694    
2022-01-25 18:23:04,166 - Epoch: [5][  110/  211]    Overall Loss 0.123313    Objective Loss 0.123313                                        LR 0.100000    Time 0.024779    
2022-01-25 18:23:04,366 - Epoch: [5][  120/  211]    Overall Loss 0.121783    Objective Loss 0.121783                                        LR 0.100000    Time 0.024375    
2022-01-25 18:23:04,608 - Epoch: [5][  130/  211]    Overall Loss 0.121166    Objective Loss 0.121166                                        LR 0.100000    Time 0.024363    
2022-01-25 18:23:04,891 - Epoch: [5][  140/  211]    Overall Loss 0.119055    Objective Loss 0.119055                                        LR 0.100000    Time 0.024641    
2022-01-25 18:23:05,127 - Epoch: [5][  150/  211]    Overall Loss 0.118085    Objective Loss 0.118085                                        LR 0.100000    Time 0.024572    
2022-01-25 18:23:05,420 - Epoch: [5][  160/  211]    Overall Loss 0.116718    Objective Loss 0.116718                                        LR 0.100000    Time 0.024864    
2022-01-25 18:23:05,662 - Epoch: [5][  170/  211]    Overall Loss 0.116010    Objective Loss 0.116010                                        LR 0.100000    Time 0.024823    
2022-01-25 18:23:05,953 - Epoch: [5][  180/  211]    Overall Loss 0.115530    Objective Loss 0.115530                                        LR 0.100000    Time 0.025061    
2022-01-25 18:23:06,187 - Epoch: [5][  190/  211]    Overall Loss 0.114512    Objective Loss 0.114512                                        LR 0.100000    Time 0.024965    
2022-01-25 18:23:06,478 - Epoch: [5][  200/  211]    Overall Loss 0.113509    Objective Loss 0.113509                                        LR 0.100000    Time 0.025173    
2022-01-25 18:23:06,713 - Epoch: [5][  210/  211]    Overall Loss 0.113037    Objective Loss 0.113037    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.025090    
2022-01-25 18:23:06,725 - Epoch: [5][  211/  211]    Overall Loss 0.113079    Objective Loss 0.113079    Top1 96.169355    Top5 100.000000    LR 0.100000    Time 0.025030    
2022-01-25 18:23:06,780 - --- validate (epoch=5)-----------
2022-01-25 18:23:06,781 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:07,237 - Epoch: [5][   10/   24]    Loss 0.102372    Top1 96.679688    Top5 99.882812    
2022-01-25 18:23:07,508 - Epoch: [5][   20/   24]    Loss 0.106812    Top1 96.523438    Top5 99.843750    
2022-01-25 18:23:07,615 - Epoch: [5][   24/   24]    Loss 0.104675    Top1 96.600000    Top5 99.833333    
2022-01-25 18:23:07,671 - ==> Top1: 96.600    Top5: 99.833    Loss: 0.105

2022-01-25 18:23:07,672 - ==> Confusion:
[[593   0   3   0   0   0   6   0   0   3]
 [  1 677   4   0   0   2   2   1   1   0]
 [  1   0 572   1   1   0   0   4   4   3]
 [  1   0   3 564   0   9   0   0   2   4]
 [  0   1   3   0 534   1   2   1   0  23]
 [  1   0   1   1   0 508   6   0   0   1]
 [  1   1   0   0   3   4 620   0   1   1]
 [  0   3  18   5   5   2   0 580   0  12]
 [  4   0   2   1   2   5  14   1 550   5]
 [  1   1   1   1   6   2   0   2   3 598]]

2022-01-25 18:23:07,673 - ==> Best [Top1: 96.600   Top5: 99.833   Sparsity:0.00   Params: 71148 on epoch: 5]
2022-01-25 18:23:07,674 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:23:07,680 - 

2022-01-25 18:23:07,680 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:08,378 - Epoch: [6][   10/  211]    Overall Loss 0.114895    Objective Loss 0.114895                                        LR 0.100000    Time 0.069745    
2022-01-25 18:23:08,577 - Epoch: [6][   20/  211]    Overall Loss 0.107676    Objective Loss 0.107676                                        LR 0.100000    Time 0.044766    
2022-01-25 18:23:08,816 - Epoch: [6][   30/  211]    Overall Loss 0.108218    Objective Loss 0.108218                                        LR 0.100000    Time 0.037792    
2022-01-25 18:23:09,011 - Epoch: [6][   40/  211]    Overall Loss 0.103453    Objective Loss 0.103453                                        LR 0.100000    Time 0.033223    
2022-01-25 18:23:09,251 - Epoch: [6][   50/  211]    Overall Loss 0.101508    Objective Loss 0.101508                                        LR 0.100000    Time 0.031373    
2022-01-25 18:23:09,457 - Epoch: [6][   60/  211]    Overall Loss 0.100092    Objective Loss 0.100092                                        LR 0.100000    Time 0.029574    
2022-01-25 18:23:09,694 - Epoch: [6][   70/  211]    Overall Loss 0.099150    Objective Loss 0.099150                                        LR 0.100000    Time 0.028720    
2022-01-25 18:23:09,894 - Epoch: [6][   80/  211]    Overall Loss 0.098370    Objective Loss 0.098370                                        LR 0.100000    Time 0.027627    
2022-01-25 18:23:10,130 - Epoch: [6][   90/  211]    Overall Loss 0.098712    Objective Loss 0.098712                                        LR 0.100000    Time 0.027185    
2022-01-25 18:23:10,333 - Epoch: [6][  100/  211]    Overall Loss 0.099802    Objective Loss 0.099802                                        LR 0.100000    Time 0.026490    
2022-01-25 18:23:10,571 - Epoch: [6][  110/  211]    Overall Loss 0.099731    Objective Loss 0.099731                                        LR 0.100000    Time 0.026239    
2022-01-25 18:23:10,780 - Epoch: [6][  120/  211]    Overall Loss 0.099782    Objective Loss 0.099782                                        LR 0.100000    Time 0.025790    
2022-01-25 18:23:11,015 - Epoch: [6][  130/  211]    Overall Loss 0.099480    Objective Loss 0.099480                                        LR 0.100000    Time 0.025614    
2022-01-25 18:23:11,217 - Epoch: [6][  140/  211]    Overall Loss 0.098486    Objective Loss 0.098486                                        LR 0.100000    Time 0.025225    
2022-01-25 18:23:11,454 - Epoch: [6][  150/  211]    Overall Loss 0.098735    Objective Loss 0.098735                                        LR 0.100000    Time 0.025120    
2022-01-25 18:23:11,673 - Epoch: [6][  160/  211]    Overall Loss 0.100052    Objective Loss 0.100052                                        LR 0.100000    Time 0.024919    
2022-01-25 18:23:11,978 - Epoch: [6][  170/  211]    Overall Loss 0.101494    Objective Loss 0.101494                                        LR 0.100000    Time 0.025242    
2022-01-25 18:23:12,208 - Epoch: [6][  180/  211]    Overall Loss 0.101706    Objective Loss 0.101706                                        LR 0.100000    Time 0.025118    
2022-01-25 18:23:12,498 - Epoch: [6][  190/  211]    Overall Loss 0.101882    Objective Loss 0.101882                                        LR 0.100000    Time 0.025318    
2022-01-25 18:23:12,736 - Epoch: [6][  200/  211]    Overall Loss 0.100689    Objective Loss 0.100689                                        LR 0.100000    Time 0.025244    
2022-01-25 18:23:13,024 - Epoch: [6][  210/  211]    Overall Loss 0.100615    Objective Loss 0.100615    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.025411    
2022-01-25 18:23:13,038 - Epoch: [6][  211/  211]    Overall Loss 0.100503    Objective Loss 0.100503    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.025355    
2022-01-25 18:23:13,096 - --- validate (epoch=6)-----------
2022-01-25 18:23:13,097 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:13,562 - Epoch: [6][   10/   24]    Loss 0.124086    Top1 96.015625    Top5 100.000000    
2022-01-25 18:23:13,773 - Epoch: [6][   20/   24]    Loss 0.112194    Top1 96.484375    Top5 99.980469    
2022-01-25 18:23:13,859 - Epoch: [6][   24/   24]    Loss 0.115920    Top1 96.366667    Top5 99.950000    
2022-01-25 18:23:13,914 - ==> Top1: 96.367    Top5: 99.950    Loss: 0.116

2022-01-25 18:23:13,915 - ==> Confusion:
[[595   0   1   0   0   0   1   0   8   0]
 [  1 683   3   0   0   0   1   0   0   0]
 [  2   2 573   0   0   0   0   4   5   0]
 [  1   2   7 555   0   6   0   3   8   1]
 [  3   7  10   0 517   1   4   4   7  12]
 [  2   0   1   1   0 498   6   1   8   1]
 [  1   4   0   0   0   0 625   0   1   0]
 [  1   7  12   2   0   0   0 600   0   3]
 [  0   1   1   1   0   1  10   0 569   1]
 [  1   5   2   1   8   3   1   3  24 567]]

2022-01-25 18:23:13,916 - ==> Best [Top1: 96.600   Top5: 99.833   Sparsity:0.00   Params: 71148 on epoch: 5]
2022-01-25 18:23:13,916 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:23:13,923 - 

2022-01-25 18:23:13,923 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:14,462 - Epoch: [7][   10/  211]    Overall Loss 0.093145    Objective Loss 0.093145                                        LR 0.100000    Time 0.053802    
2022-01-25 18:23:14,673 - Epoch: [7][   20/  211]    Overall Loss 0.095740    Objective Loss 0.095740                                        LR 0.100000    Time 0.037455    
2022-01-25 18:23:14,906 - Epoch: [7][   30/  211]    Overall Loss 0.096558    Objective Loss 0.096558                                        LR 0.100000    Time 0.032727    
2022-01-25 18:23:15,143 - Epoch: [7][   40/  211]    Overall Loss 0.100402    Objective Loss 0.100402                                        LR 0.100000    Time 0.030452    
2022-01-25 18:23:15,430 - Epoch: [7][   50/  211]    Overall Loss 0.098944    Objective Loss 0.098944                                        LR 0.100000    Time 0.030105    
2022-01-25 18:23:15,663 - Epoch: [7][   60/  211]    Overall Loss 0.101669    Objective Loss 0.101669                                        LR 0.100000    Time 0.028963    
2022-01-25 18:23:15,954 - Epoch: [7][   70/  211]    Overall Loss 0.100106    Objective Loss 0.100106                                        LR 0.100000    Time 0.028978    
2022-01-25 18:23:16,187 - Epoch: [7][   80/  211]    Overall Loss 0.098470    Objective Loss 0.098470                                        LR 0.100000    Time 0.028263    
2022-01-25 18:23:16,476 - Epoch: [7][   90/  211]    Overall Loss 0.096201    Objective Loss 0.096201                                        LR 0.100000    Time 0.028333    
2022-01-25 18:23:16,712 - Epoch: [7][  100/  211]    Overall Loss 0.096179    Objective Loss 0.096179                                        LR 0.100000    Time 0.027848    
2022-01-25 18:23:17,000 - Epoch: [7][  110/  211]    Overall Loss 0.098098    Objective Loss 0.098098                                        LR 0.100000    Time 0.027933    
2022-01-25 18:23:17,235 - Epoch: [7][  120/  211]    Overall Loss 0.099373    Objective Loss 0.099373                                        LR 0.100000    Time 0.027563    
2022-01-25 18:23:17,523 - Epoch: [7][  130/  211]    Overall Loss 0.099934    Objective Loss 0.099934                                        LR 0.100000    Time 0.027654    
2022-01-25 18:23:17,761 - Epoch: [7][  140/  211]    Overall Loss 0.099411    Objective Loss 0.099411                                        LR 0.100000    Time 0.027375    
2022-01-25 18:23:18,059 - Epoch: [7][  150/  211]    Overall Loss 0.099299    Objective Loss 0.099299                                        LR 0.100000    Time 0.027537    
2022-01-25 18:23:18,292 - Epoch: [7][  160/  211]    Overall Loss 0.099285    Objective Loss 0.099285                                        LR 0.100000    Time 0.027267    
2022-01-25 18:23:18,584 - Epoch: [7][  170/  211]    Overall Loss 0.098366    Objective Loss 0.098366                                        LR 0.100000    Time 0.027380    
2022-01-25 18:23:18,823 - Epoch: [7][  180/  211]    Overall Loss 0.098473    Objective Loss 0.098473                                        LR 0.100000    Time 0.027183    
2022-01-25 18:23:19,112 - Epoch: [7][  190/  211]    Overall Loss 0.097810    Objective Loss 0.097810                                        LR 0.100000    Time 0.027273    
2022-01-25 18:23:19,353 - Epoch: [7][  200/  211]    Overall Loss 0.096630    Objective Loss 0.096630                                        LR 0.100000    Time 0.027112    
2022-01-25 18:23:19,644 - Epoch: [7][  210/  211]    Overall Loss 0.096727    Objective Loss 0.096727    Top1 95.703125    Top5 99.609375    LR 0.100000    Time 0.027204    
2022-01-25 18:23:19,657 - Epoch: [7][  211/  211]    Overall Loss 0.096719    Objective Loss 0.096719    Top1 96.370968    Top5 99.798387    LR 0.100000    Time 0.027136    
2022-01-25 18:23:19,709 - --- validate (epoch=7)-----------
2022-01-25 18:23:19,710 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:20,490 - Epoch: [7][   10/   24]    Loss 0.089277    Top1 97.265625    Top5 99.843750    
2022-01-25 18:23:20,716 - Epoch: [7][   20/   24]    Loss 0.101601    Top1 96.796875    Top5 99.882812    
2022-01-25 18:23:20,819 - Epoch: [7][   24/   24]    Loss 0.096654    Top1 96.950000    Top5 99.883333    
2022-01-25 18:23:20,882 - ==> Top1: 96.950    Top5: 99.883    Loss: 0.097

2022-01-25 18:23:20,882 - ==> Confusion:
[[588   0   3   0   3   1   7   0   2   1]
 [  0 685   1   0   0   1   0   1   0   0]
 [  2   1 576   0   0   1   1   3   1   1]
 [  1   1   8 556   2   6   0   7   1   1]
 [  1   2   1   0 551   0   3   2   0   5]
 [  1   0   0   1   0 513   3   0   0   0]
 [  2   3   1   0   4   3 617   0   1   0]
 [  0   8   2   0   2   1   0 612   0   0]
 [  3   3   3   1   7   8  12   1 538   8]
 [  1   2   2   0  14   7   0   6   2 581]]

2022-01-25 18:23:20,884 - ==> Best [Top1: 96.950   Top5: 99.883   Sparsity:0.00   Params: 71148 on epoch: 7]
2022-01-25 18:23:20,884 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:23:20,890 - 

2022-01-25 18:23:20,890 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:21,433 - Epoch: [8][   10/  211]    Overall Loss 0.105491    Objective Loss 0.105491                                        LR 0.100000    Time 0.054158    
2022-01-25 18:23:21,628 - Epoch: [8][   20/  211]    Overall Loss 0.093879    Objective Loss 0.093879                                        LR 0.100000    Time 0.036816    
2022-01-25 18:23:21,864 - Epoch: [8][   30/  211]    Overall Loss 0.090970    Objective Loss 0.090970                                        LR 0.100000    Time 0.032403    
2022-01-25 18:23:22,084 - Epoch: [8][   40/  211]    Overall Loss 0.094384    Objective Loss 0.094384                                        LR 0.100000    Time 0.029808    
2022-01-25 18:23:22,302 - Epoch: [8][   50/  211]    Overall Loss 0.095701    Objective Loss 0.095701                                        LR 0.100000    Time 0.028181    
2022-01-25 18:23:22,547 - Epoch: [8][   60/  211]    Overall Loss 0.096578    Objective Loss 0.096578                                        LR 0.100000    Time 0.027569    
2022-01-25 18:23:22,756 - Epoch: [8][   70/  211]    Overall Loss 0.094730    Objective Loss 0.094730                                        LR 0.100000    Time 0.026617    
2022-01-25 18:23:23,009 - Epoch: [8][   80/  211]    Overall Loss 0.093623    Objective Loss 0.093623                                        LR 0.100000    Time 0.026449    
2022-01-25 18:23:23,217 - Epoch: [8][   90/  211]    Overall Loss 0.093415    Objective Loss 0.093415                                        LR 0.100000    Time 0.025810    
2022-01-25 18:23:23,466 - Epoch: [8][  100/  211]    Overall Loss 0.093722    Objective Loss 0.093722                                        LR 0.100000    Time 0.025713    
2022-01-25 18:23:23,675 - Epoch: [8][  110/  211]    Overall Loss 0.092067    Objective Loss 0.092067                                        LR 0.100000    Time 0.025274    
2022-01-25 18:23:23,935 - Epoch: [8][  120/  211]    Overall Loss 0.089858    Objective Loss 0.089858                                        LR 0.100000    Time 0.025332    
2022-01-25 18:23:24,132 - Epoch: [8][  130/  211]    Overall Loss 0.090032    Objective Loss 0.090032                                        LR 0.100000    Time 0.024897    
2022-01-25 18:23:24,371 - Epoch: [8][  140/  211]    Overall Loss 0.090363    Objective Loss 0.090363                                        LR 0.100000    Time 0.024821    
2022-01-25 18:23:24,572 - Epoch: [8][  150/  211]    Overall Loss 0.090938    Objective Loss 0.090938                                        LR 0.100000    Time 0.024503    
2022-01-25 18:23:24,807 - Epoch: [8][  160/  211]    Overall Loss 0.091643    Objective Loss 0.091643                                        LR 0.100000    Time 0.024437    
2022-01-25 18:23:25,005 - Epoch: [8][  170/  211]    Overall Loss 0.092060    Objective Loss 0.092060                                        LR 0.100000    Time 0.024168    
2022-01-25 18:23:25,249 - Epoch: [8][  180/  211]    Overall Loss 0.090863    Objective Loss 0.090863                                        LR 0.100000    Time 0.024174    
2022-01-25 18:23:25,447 - Epoch: [8][  190/  211]    Overall Loss 0.090429    Objective Loss 0.090429                                        LR 0.100000    Time 0.023944    
2022-01-25 18:23:25,682 - Epoch: [8][  200/  211]    Overall Loss 0.089802    Objective Loss 0.089802                                        LR 0.100000    Time 0.023920    
2022-01-25 18:23:25,881 - Epoch: [8][  210/  211]    Overall Loss 0.089771    Objective Loss 0.089771    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.023725    
2022-01-25 18:23:25,923 - Epoch: [8][  211/  211]    Overall Loss 0.089605    Objective Loss 0.089605    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.023813    
2022-01-25 18:23:25,979 - --- validate (epoch=8)-----------
2022-01-25 18:23:25,980 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:26,440 - Epoch: [8][   10/   24]    Loss 0.096371    Top1 97.187500    Top5 99.960938    
2022-01-25 18:23:26,628 - Epoch: [8][   20/   24]    Loss 0.096149    Top1 97.089844    Top5 99.941406    
2022-01-25 18:23:26,713 - Epoch: [8][   24/   24]    Loss 0.092113    Top1 97.183333    Top5 99.950000    
2022-01-25 18:23:26,769 - ==> Top1: 97.183    Top5: 99.950    Loss: 0.092

2022-01-25 18:23:26,770 - ==> Confusion:
[[590   0   6   0   0   1   1   1   6   0]
 [  0 681   3   0   0   0   0   4   0   0]
 [  0   0 572   1   1   0   0   5   7   0]
 [  0   1   7 566   1   1   0   2   5   0]
 [  0   1   3   0 552   0   0   4   1   4]
 [  0   1   0  10   0 493   4   1   9   0]
 [  0   2   0   0   1   0 622   0   6   0]
 [  0   3   9   4   1   0   0 607   0   1]
 [  1   0   2   0   3   1   2   1 574   0]
 [  1   4   1   3  12   1   0   8  11 574]]

2022-01-25 18:23:26,772 - ==> Best [Top1: 97.183   Top5: 99.950   Sparsity:0.00   Params: 71148 on epoch: 8]
2022-01-25 18:23:26,773 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:23:26,781 - 

2022-01-25 18:23:26,782 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:27,482 - Epoch: [9][   10/  211]    Overall Loss 0.090482    Objective Loss 0.090482                                        LR 0.100000    Time 0.069998    
2022-01-25 18:23:27,683 - Epoch: [9][   20/  211]    Overall Loss 0.092095    Objective Loss 0.092095                                        LR 0.100000    Time 0.045007    
2022-01-25 18:23:27,918 - Epoch: [9][   30/  211]    Overall Loss 0.095012    Objective Loss 0.095012                                        LR 0.100000    Time 0.037843    
2022-01-25 18:23:28,116 - Epoch: [9][   40/  211]    Overall Loss 0.096798    Objective Loss 0.096798                                        LR 0.100000    Time 0.033333    
2022-01-25 18:23:28,353 - Epoch: [9][   50/  211]    Overall Loss 0.094647    Objective Loss 0.094647                                        LR 0.100000    Time 0.031385    
2022-01-25 18:23:28,554 - Epoch: [9][   60/  211]    Overall Loss 0.095722    Objective Loss 0.095722                                        LR 0.100000    Time 0.029503    
2022-01-25 18:23:28,805 - Epoch: [9][   70/  211]    Overall Loss 0.096167    Objective Loss 0.096167                                        LR 0.100000    Time 0.028871    
2022-01-25 18:23:29,006 - Epoch: [9][   80/  211]    Overall Loss 0.095683    Objective Loss 0.095683                                        LR 0.100000    Time 0.027771    
2022-01-25 18:23:29,239 - Epoch: [9][   90/  211]    Overall Loss 0.094630    Objective Loss 0.094630                                        LR 0.100000    Time 0.027266    
2022-01-25 18:23:29,463 - Epoch: [9][  100/  211]    Overall Loss 0.094114    Objective Loss 0.094114                                        LR 0.100000    Time 0.026777    
2022-01-25 18:23:29,701 - Epoch: [9][  110/  211]    Overall Loss 0.093376    Objective Loss 0.093376                                        LR 0.100000    Time 0.026502    
2022-01-25 18:23:30,006 - Epoch: [9][  120/  211]    Overall Loss 0.092571    Objective Loss 0.092571                                        LR 0.100000    Time 0.026836    
2022-01-25 18:23:30,239 - Epoch: [9][  130/  211]    Overall Loss 0.092517    Objective Loss 0.092517                                        LR 0.100000    Time 0.026560    
2022-01-25 18:23:30,532 - Epoch: [9][  140/  211]    Overall Loss 0.091455    Objective Loss 0.091455                                        LR 0.100000    Time 0.026756    
2022-01-25 18:23:30,770 - Epoch: [9][  150/  211]    Overall Loss 0.091311    Objective Loss 0.091311                                        LR 0.100000    Time 0.026552    
2022-01-25 18:23:31,064 - Epoch: [9][  160/  211]    Overall Loss 0.090678    Objective Loss 0.090678                                        LR 0.100000    Time 0.026734    
2022-01-25 18:23:31,309 - Epoch: [9][  170/  211]    Overall Loss 0.089593    Objective Loss 0.089593                                        LR 0.100000    Time 0.026600    
2022-01-25 18:23:31,601 - Epoch: [9][  180/  211]    Overall Loss 0.089233    Objective Loss 0.089233                                        LR 0.100000    Time 0.026738    
2022-01-25 18:23:31,798 - Epoch: [9][  190/  211]    Overall Loss 0.088344    Objective Loss 0.088344                                        LR 0.100000    Time 0.026368    
2022-01-25 18:23:32,042 - Epoch: [9][  200/  211]    Overall Loss 0.088379    Objective Loss 0.088379                                        LR 0.100000    Time 0.026269    
2022-01-25 18:23:32,240 - Epoch: [9][  210/  211]    Overall Loss 0.088024    Objective Loss 0.088024    Top1 95.703125    Top5 100.000000    LR 0.100000    Time 0.025959    
2022-01-25 18:23:32,284 - Epoch: [9][  211/  211]    Overall Loss 0.088075    Objective Loss 0.088075    Top1 96.370968    Top5 100.000000    LR 0.100000    Time 0.026043    
2022-01-25 18:23:32,360 - --- validate (epoch=9)-----------
2022-01-25 18:23:32,361 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:32,832 - Epoch: [9][   10/   24]    Loss 0.079158    Top1 97.578125    Top5 99.960938    
2022-01-25 18:23:33,040 - Epoch: [9][   20/   24]    Loss 0.080206    Top1 97.558594    Top5 99.902344    
2022-01-25 18:23:33,124 - Epoch: [9][   24/   24]    Loss 0.078534    Top1 97.650000    Top5 99.916667    
2022-01-25 18:23:33,184 - ==> Top1: 97.650    Top5: 99.917    Loss: 0.079

2022-01-25 18:23:33,186 - ==> Confusion:
[[598   0   1   0   1   2   3   0   0   0]
 [  0 685   1   0   0   1   0   1   0   0]
 [  0   6 559   4   2   1   0  11   1   2]
 [  1   1   2 573   0   1   0   4   0   1]
 [  0   1   1   0 548   0   0   4   0  11]
 [  0   0   0   1   1 515   1   0   0   0]
 [  4   2   0   0   4  12 608   0   1   0]
 [  0   3   0   1   0   1   0 620   0   0]
 [  3   0   0   2   2   8   3   1 563   2]
 [  2   2   0   4   7   1   0   6   3 590]]

2022-01-25 18:23:33,188 - ==> Best [Top1: 97.650   Top5: 99.917   Sparsity:0.00   Params: 71148 on epoch: 9]
2022-01-25 18:23:33,188 - Saving checkpoint to: logs/2022.01.25-182220/checkpoint.pth.tar
2022-01-25 18:23:33,211 - 

2022-01-25 18:23:33,211 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:33,770 - Epoch: [10][   10/  211]    Overall Loss 0.526415    Objective Loss 0.526415                                        LR 0.100000    Time 0.055782    
2022-01-25 18:23:33,980 - Epoch: [10][   20/  211]    Overall Loss 0.458261    Objective Loss 0.458261                                        LR 0.100000    Time 0.038356    
2022-01-25 18:23:34,201 - Epoch: [10][   30/  211]    Overall Loss 0.408432    Objective Loss 0.408432                                        LR 0.100000    Time 0.032950    
2022-01-25 18:23:34,414 - Epoch: [10][   40/  211]    Overall Loss 0.369351    Objective Loss 0.369351                                        LR 0.100000    Time 0.030019    
2022-01-25 18:23:34,645 - Epoch: [10][   50/  211]    Overall Loss 0.339772    Objective Loss 0.339772                                        LR 0.100000    Time 0.028625    
2022-01-25 18:23:34,852 - Epoch: [10][   60/  211]    Overall Loss 0.316299    Objective Loss 0.316299                                        LR 0.100000    Time 0.027299    
2022-01-25 18:23:35,077 - Epoch: [10][   70/  211]    Overall Loss 0.296531    Objective Loss 0.296531                                        LR 0.100000    Time 0.026619    
2022-01-25 18:23:35,295 - Epoch: [10][   80/  211]    Overall Loss 0.282159    Objective Loss 0.282159                                        LR 0.100000    Time 0.026006    
2022-01-25 18:23:35,522 - Epoch: [10][   90/  211]    Overall Loss 0.270444    Objective Loss 0.270444                                        LR 0.100000    Time 0.025638    
2022-01-25 18:23:35,733 - Epoch: [10][  100/  211]    Overall Loss 0.260770    Objective Loss 0.260770                                        LR 0.100000    Time 0.025179    
2022-01-25 18:23:35,964 - Epoch: [10][  110/  211]    Overall Loss 0.250140    Objective Loss 0.250140                                        LR 0.100000    Time 0.024988    
2022-01-25 18:23:36,174 - Epoch: [10][  120/  211]    Overall Loss 0.242021    Objective Loss 0.242021                                        LR 0.100000    Time 0.024643    
2022-01-25 18:23:36,410 - Epoch: [10][  130/  211]    Overall Loss 0.234554    Objective Loss 0.234554                                        LR 0.100000    Time 0.024564    
2022-01-25 18:23:36,624 - Epoch: [10][  140/  211]    Overall Loss 0.227865    Objective Loss 0.227865                                        LR 0.100000    Time 0.024335    
2022-01-25 18:23:36,866 - Epoch: [10][  150/  211]    Overall Loss 0.222244    Objective Loss 0.222244                                        LR 0.100000    Time 0.024326    
2022-01-25 18:23:37,077 - Epoch: [10][  160/  211]    Overall Loss 0.216424    Objective Loss 0.216424                                        LR 0.100000    Time 0.024114    
2022-01-25 18:23:37,302 - Epoch: [10][  170/  211]    Overall Loss 0.211930    Objective Loss 0.211930                                        LR 0.100000    Time 0.024019    
2022-01-25 18:23:37,520 - Epoch: [10][  180/  211]    Overall Loss 0.208494    Objective Loss 0.208494                                        LR 0.100000    Time 0.023894    
2022-01-25 18:23:37,744 - Epoch: [10][  190/  211]    Overall Loss 0.204493    Objective Loss 0.204493                                        LR 0.100000    Time 0.023816    
2022-01-25 18:23:37,960 - Epoch: [10][  200/  211]    Overall Loss 0.200812    Objective Loss 0.200812                                        LR 0.100000    Time 0.023703    
2022-01-25 18:23:38,187 - Epoch: [10][  210/  211]    Overall Loss 0.196845    Objective Loss 0.196845    Top1 96.875000    Top5 100.000000    LR 0.100000    Time 0.023653    
2022-01-25 18:23:38,207 - Epoch: [10][  211/  211]    Overall Loss 0.196470    Objective Loss 0.196470    Top1 97.177419    Top5 100.000000    LR 0.100000    Time 0.023633    
2022-01-25 18:23:38,290 - --- validate (epoch=10)-----------
2022-01-25 18:23:38,290 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:38,898 - Epoch: [10][   10/   24]    Loss 0.140142    Top1 96.796875    Top5 99.921875    
2022-01-25 18:23:39,096 - Epoch: [10][   20/   24]    Loss 0.139316    Top1 96.835938    Top5 99.921875    
2022-01-25 18:23:39,180 - Epoch: [10][   24/   24]    Loss 0.135124    Top1 96.966667    Top5 99.933333    
2022-01-25 18:23:39,236 - ==> Top1: 96.967    Top5: 99.933    Loss: 0.135

2022-01-25 18:23:39,238 - ==> Confusion:
[[583   0   6   0   0   0  11   1   3   1]
 [  0 678   6   0   0   1   1   2   0   0]
 [  1   1 569   0   0   0   0   7   7   1]
 [  0   0   9 565   0   0   0   3   4   2]
 [  0   0   2   0 550   0   3   0   1   9]
 [  2   1   0   5   0 490  10   0   5   5]
 [  4   2   0   0   1   1 622   0   1   0]
 [  0   0   6   0   4   1   0 612   1   1]
 [  0   0   1   0   2   1   7   1 570   2]
 [  1   1   1   4   8   2   2   6  11 579]]

2022-01-25 18:23:39,239 - ==> Best [Top1: 96.967   Top5: 99.933   Sparsity:0.00   Params: 71148 on epoch: 10]
2022-01-25 18:23:39,240 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:23:39,247 - 

2022-01-25 18:23:39,247 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:39,845 - Epoch: [11][   10/  211]    Overall Loss 0.124991    Objective Loss 0.124991                                        LR 0.100000    Time 0.059684    
2022-01-25 18:23:40,095 - Epoch: [11][   20/  211]    Overall Loss 0.125089    Objective Loss 0.125089                                        LR 0.100000    Time 0.042337    
2022-01-25 18:23:40,372 - Epoch: [11][   30/  211]    Overall Loss 0.125219    Objective Loss 0.125219                                        LR 0.100000    Time 0.037459    
2022-01-25 18:23:40,620 - Epoch: [11][   40/  211]    Overall Loss 0.122331    Objective Loss 0.122331                                        LR 0.100000    Time 0.034275    
2022-01-25 18:23:40,902 - Epoch: [11][   50/  211]    Overall Loss 0.120363    Objective Loss 0.120363                                        LR 0.100000    Time 0.033057    
2022-01-25 18:23:41,150 - Epoch: [11][   60/  211]    Overall Loss 0.120504    Objective Loss 0.120504                                        LR 0.100000    Time 0.031665    
2022-01-25 18:23:41,439 - Epoch: [11][   70/  211]    Overall Loss 0.122466    Objective Loss 0.122466                                        LR 0.100000    Time 0.031268    
2022-01-25 18:23:41,684 - Epoch: [11][   80/  211]    Overall Loss 0.120692    Objective Loss 0.120692                                        LR 0.100000    Time 0.030412    
2022-01-25 18:23:41,968 - Epoch: [11][   90/  211]    Overall Loss 0.119827    Objective Loss 0.119827                                        LR 0.100000    Time 0.030193    
2022-01-25 18:23:42,219 - Epoch: [11][  100/  211]    Overall Loss 0.119066    Objective Loss 0.119066                                        LR 0.100000    Time 0.029677    
2022-01-25 18:23:42,497 - Epoch: [11][  110/  211]    Overall Loss 0.118281    Objective Loss 0.118281                                        LR 0.100000    Time 0.029500    
2022-01-25 18:23:42,744 - Epoch: [11][  120/  211]    Overall Loss 0.117714    Objective Loss 0.117714                                        LR 0.100000    Time 0.029097    
2022-01-25 18:23:43,024 - Epoch: [11][  130/  211]    Overall Loss 0.117215    Objective Loss 0.117215                                        LR 0.100000    Time 0.029017    
2022-01-25 18:23:43,280 - Epoch: [11][  140/  211]    Overall Loss 0.117508    Objective Loss 0.117508                                        LR 0.100000    Time 0.028764    
2022-01-25 18:23:43,559 - Epoch: [11][  150/  211]    Overall Loss 0.118953    Objective Loss 0.118953                                        LR 0.100000    Time 0.028707    
2022-01-25 18:23:43,807 - Epoch: [11][  160/  211]    Overall Loss 0.119753    Objective Loss 0.119753                                        LR 0.100000    Time 0.028460    
2022-01-25 18:23:44,086 - Epoch: [11][  170/  211]    Overall Loss 0.119670    Objective Loss 0.119670                                        LR 0.100000    Time 0.028423    
2022-01-25 18:23:44,338 - Epoch: [11][  180/  211]    Overall Loss 0.118625    Objective Loss 0.118625                                        LR 0.100000    Time 0.028244    
2022-01-25 18:23:44,622 - Epoch: [11][  190/  211]    Overall Loss 0.117785    Objective Loss 0.117785                                        LR 0.100000    Time 0.028252    
2022-01-25 18:23:44,868 - Epoch: [11][  200/  211]    Overall Loss 0.117587    Objective Loss 0.117587                                        LR 0.100000    Time 0.028066    
2022-01-25 18:23:45,148 - Epoch: [11][  210/  211]    Overall Loss 0.116666    Objective Loss 0.116666    Top1 96.484375    Top5 100.000000    LR 0.100000    Time 0.028063    
2022-01-25 18:23:45,166 - Epoch: [11][  211/  211]    Overall Loss 0.116781    Objective Loss 0.116781    Top1 96.370968    Top5 100.000000    LR 0.100000    Time 0.028012    
2022-01-25 18:23:45,222 - --- validate (epoch=11)-----------
2022-01-25 18:23:45,222 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:45,699 - Epoch: [11][   10/   24]    Loss 0.116756    Top1 97.187500    Top5 99.882812    
2022-01-25 18:23:45,898 - Epoch: [11][   20/   24]    Loss 0.111881    Top1 97.265625    Top5 99.921875    
2022-01-25 18:23:45,979 - Epoch: [11][   24/   24]    Loss 0.110949    Top1 97.316667    Top5 99.933333    
2022-01-25 18:23:46,045 - ==> Top1: 97.317    Top5: 99.933    Loss: 0.111

2022-01-25 18:23:46,046 - ==> Confusion:
[[596   0   2   1   0   0   2   1   3   0]
 [  0 680   4   0   0   0   0   4   0   0]
 [  1   0 572   8   0   0   1   1   3   0]
 [  0   1   2 575   0   2   0   0   3   0]
 [  0   1   3   0 526   1   1   2   2  29]
 [  1   0   1   8   0 498   3   1   5   1]
 [  4   1   1   0   1   4 617   0   2   1]
 [  0   0   9   7   1   1   0 607   0   0]
 [  3   0   0   1   2   0   3   1 573   1]
 [  0   2   0   4   3   1   0   6   4 595]]

2022-01-25 18:23:46,048 - ==> Best [Top1: 97.317   Top5: 99.933   Sparsity:0.00   Params: 71148 on epoch: 11]
2022-01-25 18:23:46,048 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:23:46,055 - 

2022-01-25 18:23:46,055 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:46,758 - Epoch: [12][   10/  211]    Overall Loss 0.114986    Objective Loss 0.114986                                        LR 0.100000    Time 0.070224    
2022-01-25 18:23:46,968 - Epoch: [12][   20/  211]    Overall Loss 0.111341    Objective Loss 0.111341                                        LR 0.100000    Time 0.045594    
2022-01-25 18:23:47,194 - Epoch: [12][   30/  211]    Overall Loss 0.112564    Objective Loss 0.112564                                        LR 0.100000    Time 0.037928    
2022-01-25 18:23:47,405 - Epoch: [12][   40/  211]    Overall Loss 0.114955    Objective Loss 0.114955                                        LR 0.100000    Time 0.033719    
2022-01-25 18:23:47,629 - Epoch: [12][   50/  211]    Overall Loss 0.114499    Objective Loss 0.114499                                        LR 0.100000    Time 0.031433    
2022-01-25 18:23:47,842 - Epoch: [12][   60/  211]    Overall Loss 0.112662    Objective Loss 0.112662                                        LR 0.100000    Time 0.029737    
2022-01-25 18:23:48,072 - Epoch: [12][   70/  211]    Overall Loss 0.112186    Objective Loss 0.112186                                        LR 0.100000    Time 0.028780    
2022-01-25 18:23:48,286 - Epoch: [12][   80/  211]    Overall Loss 0.112981    Objective Loss 0.112981                                        LR 0.100000    Time 0.027843    
2022-01-25 18:23:48,514 - Epoch: [12][   90/  211]    Overall Loss 0.112214    Objective Loss 0.112214                                        LR 0.100000    Time 0.027281    
2022-01-25 18:23:48,725 - Epoch: [12][  100/  211]    Overall Loss 0.112362    Objective Loss 0.112362                                        LR 0.100000    Time 0.026660    
2022-01-25 18:23:48,958 - Epoch: [12][  110/  211]    Overall Loss 0.111463    Objective Loss 0.111463                                        LR 0.100000    Time 0.026352    
2022-01-25 18:23:49,166 - Epoch: [12][  120/  211]    Overall Loss 0.111587    Objective Loss 0.111587                                        LR 0.100000    Time 0.025891    
2022-01-25 18:23:49,391 - Epoch: [12][  130/  211]    Overall Loss 0.110576    Objective Loss 0.110576                                        LR 0.100000    Time 0.025628    
2022-01-25 18:23:49,601 - Epoch: [12][  140/  211]    Overall Loss 0.109961    Objective Loss 0.109961                                        LR 0.100000    Time 0.025295    
2022-01-25 18:23:49,831 - Epoch: [12][  150/  211]    Overall Loss 0.109814    Objective Loss 0.109814                                        LR 0.100000    Time 0.025138    
2022-01-25 18:23:50,043 - Epoch: [12][  160/  211]    Overall Loss 0.109515    Objective Loss 0.109515                                        LR 0.100000    Time 0.024891    
2022-01-25 18:23:50,273 - Epoch: [12][  170/  211]    Overall Loss 0.109346    Objective Loss 0.109346                                        LR 0.100000    Time 0.024774    
2022-01-25 18:23:50,483 - Epoch: [12][  180/  211]    Overall Loss 0.109476    Objective Loss 0.109476                                        LR 0.100000    Time 0.024562    
2022-01-25 18:23:50,708 - Epoch: [12][  190/  211]    Overall Loss 0.108505    Objective Loss 0.108505                                        LR 0.100000    Time 0.024454    
2022-01-25 18:23:50,926 - Epoch: [12][  200/  211]    Overall Loss 0.108041    Objective Loss 0.108041                                        LR 0.100000    Time 0.024319    
2022-01-25 18:23:51,148 - Epoch: [12][  210/  211]    Overall Loss 0.107203    Objective Loss 0.107203    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.024214    
2022-01-25 18:23:51,168 - Epoch: [12][  211/  211]    Overall Loss 0.107081    Objective Loss 0.107081    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.024194    
2022-01-25 18:23:51,224 - --- validate (epoch=12)-----------
2022-01-25 18:23:51,225 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:51,699 - Epoch: [12][   10/   24]    Loss 0.084966    Top1 97.890625    Top5 99.960938    
2022-01-25 18:23:51,963 - Epoch: [12][   20/   24]    Loss 0.093245    Top1 97.636719    Top5 99.960938    
2022-01-25 18:23:52,060 - Epoch: [12][   24/   24]    Loss 0.089780    Top1 97.783333    Top5 99.966667    
2022-01-25 18:23:52,123 - ==> Top1: 97.783    Top5: 99.967    Loss: 0.090

2022-01-25 18:23:52,124 - ==> Confusion:
[[601   0   2   0   0   0   1   0   0   1]
 [  0 685   2   0   0   0   0   1   0   0]
 [  0   4 570   2   0   0   0   7   2   1]
 [  0   0   4 572   0   2   0   3   2   0]
 [  0   1   1   0 544   0   2   4   0  13]
 [  0   1   0   2   0 507   3   1   3   1]
 [  2   4   0   0   2   3 618   0   2   0]
 [  0   3   3   0   0   0   0 619   0   0]
 [  1   0   1   1   0   5   7   0 563   6]
 [  0   3   1   2   5   4   1   7   3 589]]

2022-01-25 18:23:52,127 - ==> Best [Top1: 97.783   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 12]
2022-01-25 18:23:52,127 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:23:52,136 - 

2022-01-25 18:23:52,137 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:52,700 - Epoch: [13][   10/  211]    Overall Loss 0.093374    Objective Loss 0.093374                                        LR 0.100000    Time 0.056274    
2022-01-25 18:23:52,918 - Epoch: [13][   20/  211]    Overall Loss 0.093188    Objective Loss 0.093188                                        LR 0.100000    Time 0.039023    
2022-01-25 18:23:53,133 - Epoch: [13][   30/  211]    Overall Loss 0.101308    Objective Loss 0.101308                                        LR 0.100000    Time 0.033154    
2022-01-25 18:23:53,345 - Epoch: [13][   40/  211]    Overall Loss 0.102556    Objective Loss 0.102556                                        LR 0.100000    Time 0.030172    
2022-01-25 18:23:53,584 - Epoch: [13][   50/  211]    Overall Loss 0.102537    Objective Loss 0.102537                                        LR 0.100000    Time 0.028916    
2022-01-25 18:23:53,799 - Epoch: [13][   60/  211]    Overall Loss 0.101683    Objective Loss 0.101683                                        LR 0.100000    Time 0.027662    
2022-01-25 18:23:54,025 - Epoch: [13][   70/  211]    Overall Loss 0.102439    Objective Loss 0.102439                                        LR 0.100000    Time 0.026943    
2022-01-25 18:23:54,235 - Epoch: [13][   80/  211]    Overall Loss 0.101882    Objective Loss 0.101882                                        LR 0.100000    Time 0.026186    
2022-01-25 18:23:54,458 - Epoch: [13][   90/  211]    Overall Loss 0.101136    Objective Loss 0.101136                                        LR 0.100000    Time 0.025761    
2022-01-25 18:23:54,670 - Epoch: [13][  100/  211]    Overall Loss 0.099474    Objective Loss 0.099474                                        LR 0.100000    Time 0.025295    
2022-01-25 18:23:54,893 - Epoch: [13][  110/  211]    Overall Loss 0.099114    Objective Loss 0.099114                                        LR 0.100000    Time 0.025024    
2022-01-25 18:23:55,111 - Epoch: [13][  120/  211]    Overall Loss 0.098682    Objective Loss 0.098682                                        LR 0.100000    Time 0.024751    
2022-01-25 18:23:55,336 - Epoch: [13][  130/  211]    Overall Loss 0.098479    Objective Loss 0.098479                                        LR 0.100000    Time 0.024575    
2022-01-25 18:23:55,544 - Epoch: [13][  140/  211]    Overall Loss 0.097977    Objective Loss 0.097977                                        LR 0.100000    Time 0.024301    
2022-01-25 18:23:55,776 - Epoch: [13][  150/  211]    Overall Loss 0.097391    Objective Loss 0.097391                                        LR 0.100000    Time 0.024227    
2022-01-25 18:23:55,987 - Epoch: [13][  160/  211]    Overall Loss 0.096665    Objective Loss 0.096665                                        LR 0.100000    Time 0.024029    
2022-01-25 18:23:56,208 - Epoch: [13][  170/  211]    Overall Loss 0.096183    Objective Loss 0.096183                                        LR 0.100000    Time 0.023915    
2022-01-25 18:23:56,435 - Epoch: [13][  180/  211]    Overall Loss 0.095959    Objective Loss 0.095959                                        LR 0.100000    Time 0.023841    
2022-01-25 18:23:56,644 - Epoch: [13][  190/  211]    Overall Loss 0.095506    Objective Loss 0.095506                                        LR 0.100000    Time 0.023688    
2022-01-25 18:23:56,853 - Epoch: [13][  200/  211]    Overall Loss 0.095602    Objective Loss 0.095602                                        LR 0.100000    Time 0.023547    
2022-01-25 18:23:57,081 - Epoch: [13][  210/  211]    Overall Loss 0.096258    Objective Loss 0.096258    Top1 98.046875    Top5 99.609375    LR 0.100000    Time 0.023508    
2022-01-25 18:23:57,099 - Epoch: [13][  211/  211]    Overall Loss 0.096264    Objective Loss 0.096264    Top1 97.983871    Top5 99.798387    LR 0.100000    Time 0.023482    
2022-01-25 18:23:57,173 - --- validate (epoch=13)-----------
2022-01-25 18:23:57,173 - 6000 samples (256 per mini-batch)
2022-01-25 18:23:57,651 - Epoch: [13][   10/   24]    Loss 0.101830    Top1 97.382812    Top5 99.882812    
2022-01-25 18:23:57,937 - Epoch: [13][   20/   24]    Loss 0.096544    Top1 97.578125    Top5 99.921875    
2022-01-25 18:23:58,027 - Epoch: [13][   24/   24]    Loss 0.095896    Top1 97.600000    Top5 99.933333    
2022-01-25 18:23:58,084 - ==> Top1: 97.600    Top5: 99.933    Loss: 0.096

2022-01-25 18:23:58,085 - ==> Confusion:
[[594   0   3   0   0   0   5   0   3   0]
 [  0 682   4   0   0   0   0   2   0   0]
 [  0   2 576   0   2   0   1   4   1   0]
 [  1   1   6 561   1   5   0   3   4   1]
 [  0   1   3   0 551   0   2   0   0   8]
 [  1   5   2   2   0 496   5   1   5   1]
 [  1   1   1   0   2   1 624   0   1   0]
 [  0   1   3   1   1   0   0 617   0   2]
 [  0   0   3   0   4   1   4   3 568   1]
 [  1   1   1   0  15   1   0   6   2 588]]

2022-01-25 18:23:58,086 - ==> Best [Top1: 97.783   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 12]
2022-01-25 18:23:58,086 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:23:58,094 - 

2022-01-25 18:23:58,094 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:23:58,793 - Epoch: [14][   10/  211]    Overall Loss 0.116895    Objective Loss 0.116895                                        LR 0.100000    Time 0.069862    
2022-01-25 18:23:59,000 - Epoch: [14][   20/  211]    Overall Loss 0.104924    Objective Loss 0.104924                                        LR 0.100000    Time 0.045254    
2022-01-25 18:23:59,232 - Epoch: [14][   30/  211]    Overall Loss 0.103167    Objective Loss 0.103167                                        LR 0.100000    Time 0.037880    
2022-01-25 18:23:59,442 - Epoch: [14][   40/  211]    Overall Loss 0.100778    Objective Loss 0.100778                                        LR 0.100000    Time 0.033657    
2022-01-25 18:23:59,668 - Epoch: [14][   50/  211]    Overall Loss 0.101745    Objective Loss 0.101745                                        LR 0.100000    Time 0.031441    
2022-01-25 18:23:59,881 - Epoch: [14][   60/  211]    Overall Loss 0.101061    Objective Loss 0.101061                                        LR 0.100000    Time 0.029739    
2022-01-25 18:24:00,103 - Epoch: [14][   70/  211]    Overall Loss 0.098993    Objective Loss 0.098993                                        LR 0.100000    Time 0.028654    
2022-01-25 18:24:00,316 - Epoch: [14][   80/  211]    Overall Loss 0.099034    Objective Loss 0.099034                                        LR 0.100000    Time 0.027733    
2022-01-25 18:24:00,545 - Epoch: [14][   90/  211]    Overall Loss 0.098254    Objective Loss 0.098254                                        LR 0.100000    Time 0.027195    
2022-01-25 18:24:00,767 - Epoch: [14][  100/  211]    Overall Loss 0.097940    Objective Loss 0.097940                                        LR 0.100000    Time 0.026687    
2022-01-25 18:24:00,990 - Epoch: [14][  110/  211]    Overall Loss 0.096999    Objective Loss 0.096999                                        LR 0.100000    Time 0.026293    
2022-01-25 18:24:01,206 - Epoch: [14][  120/  211]    Overall Loss 0.110418    Objective Loss 0.110418                                        LR 0.100000    Time 0.025898    
2022-01-25 18:24:01,426 - Epoch: [14][  130/  211]    Overall Loss 0.119801    Objective Loss 0.119801                                        LR 0.100000    Time 0.025595    
2022-01-25 18:24:01,641 - Epoch: [14][  140/  211]    Overall Loss 0.127714    Objective Loss 0.127714                                        LR 0.100000    Time 0.025301    
2022-01-25 18:24:01,858 - Epoch: [14][  150/  211]    Overall Loss 0.133615    Objective Loss 0.133615                                        LR 0.100000    Time 0.025059    
2022-01-25 18:24:02,079 - Epoch: [14][  160/  211]    Overall Loss 0.137736    Objective Loss 0.137736                                        LR 0.100000    Time 0.024871    
2022-01-25 18:24:02,306 - Epoch: [14][  170/  211]    Overall Loss 0.140638    Objective Loss 0.140638                                        LR 0.100000    Time 0.024740    
2022-01-25 18:24:02,519 - Epoch: [14][  180/  211]    Overall Loss 0.143356    Objective Loss 0.143356                                        LR 0.100000    Time 0.024545    
2022-01-25 18:24:02,746 - Epoch: [14][  190/  211]    Overall Loss 0.145460    Objective Loss 0.145460                                        LR 0.100000    Time 0.024448    
2022-01-25 18:24:03,028 - Epoch: [14][  200/  211]    Overall Loss 0.146709    Objective Loss 0.146709                                        LR 0.100000    Time 0.024635    
2022-01-25 18:24:03,272 - Epoch: [14][  210/  211]    Overall Loss 0.147879    Objective Loss 0.147879    Top1 97.265625    Top5 99.609375    LR 0.100000    Time 0.024622    
2022-01-25 18:24:03,316 - Epoch: [14][  211/  211]    Overall Loss 0.147902    Objective Loss 0.147902    Top1 97.983871    Top5 99.798387    LR 0.100000    Time 0.024712    
2022-01-25 18:24:03,378 - --- validate (epoch=14)-----------
2022-01-25 18:24:03,378 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:03,854 - Epoch: [14][   10/   24]    Loss 0.161046    Top1 98.125000    Top5 99.960938    
2022-01-25 18:24:04,092 - Epoch: [14][   20/   24]    Loss 0.161195    Top1 98.203125    Top5 99.980469    
2022-01-25 18:24:04,181 - Epoch: [14][   24/   24]    Loss 0.164835    Top1 98.100000    Top5 99.950000    
2022-01-25 18:24:04,236 - ==> Top1: 98.100    Top5: 99.950    Loss: 0.165

2022-01-25 18:24:04,237 - ==> Confusion:
[[601   0   0   0   0   0   2   1   1   0]
 [  0 680   5   0   0   0   0   3   0   0]
 [  1   1 565   3   1   0   1   9   3   2]
 [  0   0   1 572   0   1   0   5   3   1]
 [  0   1   0   0 551   0   0   1   0  12]
 [  0   1   1   1   0 504   3   0   5   3]
 [  6   2   0   0   4   0 617   0   2   0]
 [  0   1   2   2   0   0   0 619   0   1]
 [  1   0   0   1   3   1   1   0 576   1]
 [  0   1   0   1   4   1   0   3   3 602]]

2022-01-25 18:24:04,238 - ==> Best [Top1: 98.100   Top5: 99.950   Sparsity:0.00   Params: 71148 on epoch: 14]
2022-01-25 18:24:04,238 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:04,246 - 

2022-01-25 18:24:04,246 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:04,950 - Epoch: [15][   10/  211]    Overall Loss 0.154280    Objective Loss 0.154280                                        LR 0.100000    Time 0.070329    
2022-01-25 18:24:05,162 - Epoch: [15][   20/  211]    Overall Loss 0.159710    Objective Loss 0.159710                                        LR 0.100000    Time 0.045729    
2022-01-25 18:24:05,388 - Epoch: [15][   30/  211]    Overall Loss 0.160670    Objective Loss 0.160670                                        LR 0.100000    Time 0.038010    
2022-01-25 18:24:05,596 - Epoch: [15][   40/  211]    Overall Loss 0.159130    Objective Loss 0.159130                                        LR 0.100000    Time 0.033702    
2022-01-25 18:24:05,822 - Epoch: [15][   50/  211]    Overall Loss 0.155727    Objective Loss 0.155727                                        LR 0.100000    Time 0.031478    
2022-01-25 18:24:06,033 - Epoch: [15][   60/  211]    Overall Loss 0.154233    Objective Loss 0.154233                                        LR 0.100000    Time 0.029747    
2022-01-25 18:24:06,253 - Epoch: [15][   70/  211]    Overall Loss 0.151523    Objective Loss 0.151523                                        LR 0.100000    Time 0.028632    
2022-01-25 18:24:06,474 - Epoch: [15][   80/  211]    Overall Loss 0.150419    Objective Loss 0.150419                                        LR 0.100000    Time 0.027811    
2022-01-25 18:24:06,702 - Epoch: [15][   90/  211]    Overall Loss 0.151301    Objective Loss 0.151301                                        LR 0.100000    Time 0.027254    
2022-01-25 18:24:06,912 - Epoch: [15][  100/  211]    Overall Loss 0.150772    Objective Loss 0.150772                                        LR 0.100000    Time 0.026625    
2022-01-25 18:24:07,136 - Epoch: [15][  110/  211]    Overall Loss 0.149168    Objective Loss 0.149168                                        LR 0.100000    Time 0.026234    
2022-01-25 18:24:07,350 - Epoch: [15][  120/  211]    Overall Loss 0.148154    Objective Loss 0.148154                                        LR 0.100000    Time 0.025824    
2022-01-25 18:24:07,576 - Epoch: [15][  130/  211]    Overall Loss 0.147514    Objective Loss 0.147514                                        LR 0.100000    Time 0.025574    
2022-01-25 18:24:07,799 - Epoch: [15][  140/  211]    Overall Loss 0.147011    Objective Loss 0.147011                                        LR 0.100000    Time 0.025343    
2022-01-25 18:24:08,019 - Epoch: [15][  150/  211]    Overall Loss 0.146662    Objective Loss 0.146662                                        LR 0.100000    Time 0.025119    
2022-01-25 18:24:08,233 - Epoch: [15][  160/  211]    Overall Loss 0.145336    Objective Loss 0.145336                                        LR 0.100000    Time 0.024881    
2022-01-25 18:24:08,460 - Epoch: [15][  170/  211]    Overall Loss 0.145212    Objective Loss 0.145212                                        LR 0.100000    Time 0.024752    
2022-01-25 18:24:08,673 - Epoch: [15][  180/  211]    Overall Loss 0.144601    Objective Loss 0.144601                                        LR 0.100000    Time 0.024558    
2022-01-25 18:24:08,901 - Epoch: [15][  190/  211]    Overall Loss 0.143509    Objective Loss 0.143509                                        LR 0.100000    Time 0.024465    
2022-01-25 18:24:09,115 - Epoch: [15][  200/  211]    Overall Loss 0.142606    Objective Loss 0.142606                                        LR 0.100000    Time 0.024307    
2022-01-25 18:24:09,336 - Epoch: [15][  210/  211]    Overall Loss 0.141617    Objective Loss 0.141617    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.024200    
2022-01-25 18:24:09,356 - Epoch: [15][  211/  211]    Overall Loss 0.141552    Objective Loss 0.141552    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.024180    
2022-01-25 18:24:09,440 - --- validate (epoch=15)-----------
2022-01-25 18:24:09,440 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:09,918 - Epoch: [15][   10/   24]    Loss 0.128333    Top1 97.500000    Top5 100.000000    
2022-01-25 18:24:10,120 - Epoch: [15][   20/   24]    Loss 0.119090    Top1 97.949219    Top5 99.980469    
2022-01-25 18:24:10,207 - Epoch: [15][   24/   24]    Loss 0.121060    Top1 97.933333    Top5 99.983333    
2022-01-25 18:24:10,260 - ==> Top1: 97.933    Top5: 99.983    Loss: 0.121

2022-01-25 18:24:10,261 - ==> Confusion:
[[598   0   1   0   0   1   3   1   1   0]
 [  0 678   2   0   0   0   0   8   0   0]
 [  1   0 572   5   0   0   0   6   1   1]
 [  0   0   3 569   0   4   0   5   2   0]
 [  0   1   2   0 549   0   1   2   0  10]
 [  0   1   0   1   1 510   2   1   1   1]
 [  3   4   0   0   1   0 622   0   1   0]
 [  0   2   3   1   1   0   0 617   0   1]
 [  1   1   1   1   4   2   7   0 563   4]
 [  0   1   0   4   3   3   3   2   1 598]]

2022-01-25 18:24:10,263 - ==> Best [Top1: 98.100   Top5: 99.950   Sparsity:0.00   Params: 71148 on epoch: 14]
2022-01-25 18:24:10,263 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:10,269 - 

2022-01-25 18:24:10,269 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:10,830 - Epoch: [16][   10/  211]    Overall Loss 0.119452    Objective Loss 0.119452                                        LR 0.100000    Time 0.056030    
2022-01-25 18:24:11,047 - Epoch: [16][   20/  211]    Overall Loss 0.123053    Objective Loss 0.123053                                        LR 0.100000    Time 0.038804    
2022-01-25 18:24:11,261 - Epoch: [16][   30/  211]    Overall Loss 0.125403    Objective Loss 0.125403                                        LR 0.100000    Time 0.033016    
2022-01-25 18:24:11,467 - Epoch: [16][   40/  211]    Overall Loss 0.122064    Objective Loss 0.122064                                        LR 0.100000    Time 0.029888    
2022-01-25 18:24:11,689 - Epoch: [16][   50/  211]    Overall Loss 0.124050    Objective Loss 0.124050                                        LR 0.100000    Time 0.028345    
2022-01-25 18:24:11,951 - Epoch: [16][   60/  211]    Overall Loss 0.123136    Objective Loss 0.123136                                        LR 0.100000    Time 0.027978    
2022-01-25 18:24:12,240 - Epoch: [16][   70/  211]    Overall Loss 0.123656    Objective Loss 0.123656                                        LR 0.100000    Time 0.028110    
2022-01-25 18:24:12,472 - Epoch: [16][   80/  211]    Overall Loss 0.121429    Objective Loss 0.121429                                        LR 0.100000    Time 0.027487    
2022-01-25 18:24:12,700 - Epoch: [16][   90/  211]    Overall Loss 0.120935    Objective Loss 0.120935                                        LR 0.100000    Time 0.026965    
2022-01-25 18:24:12,912 - Epoch: [16][  100/  211]    Overall Loss 0.119760    Objective Loss 0.119760                                        LR 0.100000    Time 0.026390    
2022-01-25 18:24:13,138 - Epoch: [16][  110/  211]    Overall Loss 0.119265    Objective Loss 0.119265                                        LR 0.100000    Time 0.026035    
2022-01-25 18:24:13,353 - Epoch: [16][  120/  211]    Overall Loss 0.119114    Objective Loss 0.119114                                        LR 0.100000    Time 0.025656    
2022-01-25 18:24:13,590 - Epoch: [16][  130/  211]    Overall Loss 0.118840    Objective Loss 0.118840                                        LR 0.100000    Time 0.025504    
2022-01-25 18:24:13,806 - Epoch: [16][  140/  211]    Overall Loss 0.118830    Objective Loss 0.118830                                        LR 0.100000    Time 0.025221    
2022-01-25 18:24:14,057 - Epoch: [16][  150/  211]    Overall Loss 0.118651    Objective Loss 0.118651                                        LR 0.100000    Time 0.025206    
2022-01-25 18:24:14,340 - Epoch: [16][  160/  211]    Overall Loss 0.118605    Objective Loss 0.118605                                        LR 0.100000    Time 0.025402    
2022-01-25 18:24:14,593 - Epoch: [16][  170/  211]    Overall Loss 0.117938    Objective Loss 0.117938                                        LR 0.100000    Time 0.025394    
2022-01-25 18:24:14,878 - Epoch: [16][  180/  211]    Overall Loss 0.117099    Objective Loss 0.117099                                        LR 0.100000    Time 0.025565    
2022-01-25 18:24:15,124 - Epoch: [16][  190/  211]    Overall Loss 0.116281    Objective Loss 0.116281                                        LR 0.100000    Time 0.025512    
2022-01-25 18:24:15,409 - Epoch: [16][  200/  211]    Overall Loss 0.116029    Objective Loss 0.116029                                        LR 0.100000    Time 0.025660    
2022-01-25 18:24:15,665 - Epoch: [16][  210/  211]    Overall Loss 0.114937    Objective Loss 0.114937    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.025655    
2022-01-25 18:24:15,684 - Epoch: [16][  211/  211]    Overall Loss 0.115089    Objective Loss 0.115089    Top1 97.379032    Top5 100.000000    LR 0.100000    Time 0.025622    
2022-01-25 18:24:15,741 - --- validate (epoch=16)-----------
2022-01-25 18:24:15,742 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:16,254 - Epoch: [16][   10/   24]    Loss 0.108758    Top1 97.890625    Top5 99.921875    
2022-01-25 18:24:16,484 - Epoch: [16][   20/   24]    Loss 0.108096    Top1 97.968750    Top5 99.960938    
2022-01-25 18:24:16,586 - Epoch: [16][   24/   24]    Loss 0.106472    Top1 98.050000    Top5 99.966667    
2022-01-25 18:24:16,642 - ==> Top1: 98.050    Top5: 99.967    Loss: 0.106

2022-01-25 18:24:16,643 - ==> Confusion:
[[600   0   2   0   0   0   2   0   0   1]
 [  0 681   3   1   0   0   0   3   0   0]
 [  1   0 581   1   0   1   0   0   1   1]
 [  0   0   5 571   0   2   0   2   1   2]
 [  0   0   4   0 540   0   0   1   0  20]
 [  2   0   2   2   0 508   1   0   2   1]
 [  7   1   0   0   1   1 619   0   2   0]
 [  0   2   5   0   0   0   0 617   0   1]
 [  4   0   2   1   1   1   6   0 566   3]
 [  2   0   1   0   3   3   0   4   2 600]]

2022-01-25 18:24:16,645 - ==> Best [Top1: 98.100   Top5: 99.950   Sparsity:0.00   Params: 71148 on epoch: 14]
2022-01-25 18:24:16,646 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:16,653 - 

2022-01-25 18:24:16,653 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:17,351 - Epoch: [17][   10/  211]    Overall Loss 0.098562    Objective Loss 0.098562                                        LR 0.100000    Time 0.069748    
2022-01-25 18:24:17,589 - Epoch: [17][   20/  211]    Overall Loss 0.112662    Objective Loss 0.112662                                        LR 0.100000    Time 0.046734    
2022-01-25 18:24:17,832 - Epoch: [17][   30/  211]    Overall Loss 0.112075    Objective Loss 0.112075                                        LR 0.100000    Time 0.039251    
2022-01-25 18:24:18,057 - Epoch: [17][   40/  211]    Overall Loss 0.109711    Objective Loss 0.109711                                        LR 0.100000    Time 0.035048    
2022-01-25 18:24:18,279 - Epoch: [17][   50/  211]    Overall Loss 0.109404    Objective Loss 0.109404                                        LR 0.100000    Time 0.032474    
2022-01-25 18:24:18,499 - Epoch: [17][   60/  211]    Overall Loss 0.111575    Objective Loss 0.111575                                        LR 0.100000    Time 0.030715    
2022-01-25 18:24:18,720 - Epoch: [17][   70/  211]    Overall Loss 0.110649    Objective Loss 0.110649                                        LR 0.100000    Time 0.029489    
2022-01-25 18:24:18,941 - Epoch: [17][   80/  211]    Overall Loss 0.110799    Objective Loss 0.110799                                        LR 0.100000    Time 0.028561    
2022-01-25 18:24:19,161 - Epoch: [17][   90/  211]    Overall Loss 0.109132    Objective Loss 0.109132                                        LR 0.100000    Time 0.027821    
2022-01-25 18:24:19,380 - Epoch: [17][  100/  211]    Overall Loss 0.109448    Objective Loss 0.109448                                        LR 0.100000    Time 0.027225    
2022-01-25 18:24:19,602 - Epoch: [17][  110/  211]    Overall Loss 0.109100    Objective Loss 0.109100                                        LR 0.100000    Time 0.026772    
2022-01-25 18:24:19,823 - Epoch: [17][  120/  211]    Overall Loss 0.107771    Objective Loss 0.107771                                        LR 0.100000    Time 0.026380    
2022-01-25 18:24:20,045 - Epoch: [17][  130/  211]    Overall Loss 0.107739    Objective Loss 0.107739                                        LR 0.100000    Time 0.026054    
2022-01-25 18:24:20,259 - Epoch: [17][  140/  211]    Overall Loss 0.107179    Objective Loss 0.107179                                        LR 0.100000    Time 0.025719    
2022-01-25 18:24:20,483 - Epoch: [17][  150/  211]    Overall Loss 0.106848    Objective Loss 0.106848                                        LR 0.100000    Time 0.025493    
2022-01-25 18:24:20,696 - Epoch: [17][  160/  211]    Overall Loss 0.106322    Objective Loss 0.106322                                        LR 0.100000    Time 0.025231    
2022-01-25 18:24:20,921 - Epoch: [17][  170/  211]    Overall Loss 0.106654    Objective Loss 0.106654                                        LR 0.100000    Time 0.025065    
2022-01-25 18:24:21,140 - Epoch: [17][  180/  211]    Overall Loss 0.106572    Objective Loss 0.106572                                        LR 0.100000    Time 0.024891    
2022-01-25 18:24:21,362 - Epoch: [17][  190/  211]    Overall Loss 0.105804    Objective Loss 0.105804                                        LR 0.100000    Time 0.024748    
2022-01-25 18:24:21,579 - Epoch: [17][  200/  211]    Overall Loss 0.105648    Objective Loss 0.105648                                        LR 0.100000    Time 0.024592    
2022-01-25 18:24:21,795 - Epoch: [17][  210/  211]    Overall Loss 0.105653    Objective Loss 0.105653    Top1 97.265625    Top5 99.609375    LR 0.100000    Time 0.024450    
2022-01-25 18:24:21,813 - Epoch: [17][  211/  211]    Overall Loss 0.105775    Objective Loss 0.105775    Top1 96.774194    Top5 99.596774    LR 0.100000    Time 0.024417    
2022-01-25 18:24:21,908 - --- validate (epoch=17)-----------
2022-01-25 18:24:21,909 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:22,387 - Epoch: [17][   10/   24]    Loss 0.105593    Top1 97.500000    Top5 99.921875    
2022-01-25 18:24:22,588 - Epoch: [17][   20/   24]    Loss 0.106263    Top1 97.558594    Top5 99.960938    
2022-01-25 18:24:22,671 - Epoch: [17][   24/   24]    Loss 0.104777    Top1 97.666667    Top5 99.966667    
2022-01-25 18:24:22,726 - ==> Top1: 97.667    Top5: 99.967    Loss: 0.105

2022-01-25 18:24:22,727 - ==> Confusion:
[[593   0   1   0   0   0   7   1   2   1]
 [  0 678   3   0   0   0   0   7   0   0]
 [  0   2 575   1   0   0   2   0   5   1]
 [  0   0   7 566   0   1   0   5   1   3]
 [  0   0   2   0 538   2   2   1   0  20]
 [  1   0   1   2   0 503   8   0   3   0]
 [  0   2   0   0   2   0 625   0   2   0]
 [  0   1   2   1   0   0   0 619   0   2]
 [  1   1   0   0   3   1  10   2 563   3]
 [  0   1   0   1   2   1   0   8   3 599]]

2022-01-25 18:24:22,728 - ==> Best [Top1: 98.100   Top5: 99.950   Sparsity:0.00   Params: 71148 on epoch: 14]
2022-01-25 18:24:22,728 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:22,734 - 

2022-01-25 18:24:22,734 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:23,440 - Epoch: [18][   10/  211]    Overall Loss 0.098223    Objective Loss 0.098223                                        LR 0.100000    Time 0.070574    
2022-01-25 18:24:23,657 - Epoch: [18][   20/  211]    Overall Loss 0.105190    Objective Loss 0.105190                                        LR 0.100000    Time 0.046092    
2022-01-25 18:24:23,878 - Epoch: [18][   30/  211]    Overall Loss 0.104981    Objective Loss 0.104981                                        LR 0.100000    Time 0.038084    
2022-01-25 18:24:24,092 - Epoch: [18][   40/  211]    Overall Loss 0.103934    Objective Loss 0.103934                                        LR 0.100000    Time 0.033902    
2022-01-25 18:24:24,324 - Epoch: [18][   50/  211]    Overall Loss 0.102895    Objective Loss 0.102895                                        LR 0.100000    Time 0.031768    
2022-01-25 18:24:24,541 - Epoch: [18][   60/  211]    Overall Loss 0.103058    Objective Loss 0.103058                                        LR 0.100000    Time 0.030088    
2022-01-25 18:24:24,779 - Epoch: [18][   70/  211]    Overall Loss 0.102454    Objective Loss 0.102454                                        LR 0.100000    Time 0.029172    
2022-01-25 18:24:24,990 - Epoch: [18][   80/  211]    Overall Loss 0.101437    Objective Loss 0.101437                                        LR 0.100000    Time 0.028162    
2022-01-25 18:24:25,231 - Epoch: [18][   90/  211]    Overall Loss 0.100267    Objective Loss 0.100267                                        LR 0.100000    Time 0.027710    
2022-01-25 18:24:25,452 - Epoch: [18][  100/  211]    Overall Loss 0.100613    Objective Loss 0.100613                                        LR 0.100000    Time 0.027141    
2022-01-25 18:24:25,673 - Epoch: [18][  110/  211]    Overall Loss 0.099860    Objective Loss 0.099860                                        LR 0.100000    Time 0.026684    
2022-01-25 18:24:25,881 - Epoch: [18][  120/  211]    Overall Loss 0.100014    Objective Loss 0.100014                                        LR 0.100000    Time 0.026189    
2022-01-25 18:24:26,105 - Epoch: [18][  130/  211]    Overall Loss 0.099665    Objective Loss 0.099665                                        LR 0.100000    Time 0.025895    
2022-01-25 18:24:26,317 - Epoch: [18][  140/  211]    Overall Loss 0.098935    Objective Loss 0.098935                                        LR 0.100000    Time 0.025558    
2022-01-25 18:24:26,545 - Epoch: [18][  150/  211]    Overall Loss 0.098776    Objective Loss 0.098776                                        LR 0.100000    Time 0.025370    
2022-01-25 18:24:26,764 - Epoch: [18][  160/  211]    Overall Loss 0.097978    Objective Loss 0.097978                                        LR 0.100000    Time 0.025151    
2022-01-25 18:24:26,988 - Epoch: [18][  170/  211]    Overall Loss 0.098132    Objective Loss 0.098132                                        LR 0.100000    Time 0.024991    
2022-01-25 18:24:27,199 - Epoch: [18][  180/  211]    Overall Loss 0.098225    Objective Loss 0.098225                                        LR 0.100000    Time 0.024774    
2022-01-25 18:24:27,418 - Epoch: [18][  190/  211]    Overall Loss 0.097796    Objective Loss 0.097796                                        LR 0.100000    Time 0.024618    
2022-01-25 18:24:27,631 - Epoch: [18][  200/  211]    Overall Loss 0.097592    Objective Loss 0.097592                                        LR 0.100000    Time 0.024450    
2022-01-25 18:24:27,854 - Epoch: [18][  210/  211]    Overall Loss 0.097194    Objective Loss 0.097194    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.024345    
2022-01-25 18:24:27,873 - Epoch: [18][  211/  211]    Overall Loss 0.097301    Objective Loss 0.097301    Top1 97.177419    Top5 100.000000    LR 0.100000    Time 0.024319    
2022-01-25 18:24:27,945 - --- validate (epoch=18)-----------
2022-01-25 18:24:27,945 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:28,417 - Epoch: [18][   10/   24]    Loss 0.096075    Top1 97.812500    Top5 99.921875    
2022-01-25 18:24:28,617 - Epoch: [18][   20/   24]    Loss 0.091891    Top1 97.910156    Top5 99.960938    
2022-01-25 18:24:28,700 - Epoch: [18][   24/   24]    Loss 0.094586    Top1 97.866667    Top5 99.950000    
2022-01-25 18:24:28,757 - ==> Top1: 97.867    Top5: 99.950    Loss: 0.095

2022-01-25 18:24:28,758 - ==> Confusion:
[[596   0   1   0   0   1   3   2   2   0]
 [  0 682   1   0   0   0   0   5   0   0]
 [  0   1 573   1   0   0   1   8   0   2]
 [  0   0   3 573   0   3   0   2   1   1]
 [  0   1   2   0 547   0   1   3   1  10]
 [  1   0   0   1   1 508   3   0   4   0]
 [  3   2   0   0   2   6 615   0   3   0]
 [  0   2   3   2   0   0   0 618   0   0]
 [  0   1   2   1   2   3   2   0 569   4]
 [  0   2   1   1   4   4   1   8   4 590]]

2022-01-25 18:24:28,760 - ==> Best [Top1: 98.100   Top5: 99.950   Sparsity:0.00   Params: 71148 on epoch: 14]
2022-01-25 18:24:28,760 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:28,769 - 

2022-01-25 18:24:28,769 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:29,321 - Epoch: [19][   10/  211]    Overall Loss 0.080852    Objective Loss 0.080852                                        LR 0.100000    Time 0.055060    
2022-01-25 18:24:29,529 - Epoch: [19][   20/  211]    Overall Loss 0.078021    Objective Loss 0.078021                                        LR 0.100000    Time 0.037936    
2022-01-25 18:24:29,754 - Epoch: [19][   30/  211]    Overall Loss 0.077861    Objective Loss 0.077861                                        LR 0.100000    Time 0.032775    
2022-01-25 18:24:29,959 - Epoch: [19][   40/  211]    Overall Loss 0.081318    Objective Loss 0.081318                                        LR 0.100000    Time 0.029701    
2022-01-25 18:24:30,186 - Epoch: [19][   50/  211]    Overall Loss 0.083625    Objective Loss 0.083625                                        LR 0.100000    Time 0.028298    
2022-01-25 18:24:30,400 - Epoch: [19][   60/  211]    Overall Loss 0.086534    Objective Loss 0.086534                                        LR 0.100000    Time 0.027133    
2022-01-25 18:24:30,625 - Epoch: [19][   70/  211]    Overall Loss 0.087014    Objective Loss 0.087014                                        LR 0.100000    Time 0.026474    
2022-01-25 18:24:30,846 - Epoch: [19][   80/  211]    Overall Loss 0.089235    Objective Loss 0.089235                                        LR 0.100000    Time 0.025923    
2022-01-25 18:24:31,068 - Epoch: [19][   90/  211]    Overall Loss 0.091035    Objective Loss 0.091035                                        LR 0.100000    Time 0.025502    
2022-01-25 18:24:31,278 - Epoch: [19][  100/  211]    Overall Loss 0.091465    Objective Loss 0.091465                                        LR 0.100000    Time 0.025047    
2022-01-25 18:24:31,513 - Epoch: [19][  110/  211]    Overall Loss 0.092377    Objective Loss 0.092377                                        LR 0.100000    Time 0.024900    
2022-01-25 18:24:31,723 - Epoch: [19][  120/  211]    Overall Loss 0.093118    Objective Loss 0.093118                                        LR 0.100000    Time 0.024579    
2022-01-25 18:24:31,954 - Epoch: [19][  130/  211]    Overall Loss 0.093687    Objective Loss 0.093687                                        LR 0.100000    Time 0.024461    
2022-01-25 18:24:32,168 - Epoch: [19][  140/  211]    Overall Loss 0.093583    Objective Loss 0.093583                                        LR 0.100000    Time 0.024234    
2022-01-25 18:24:32,388 - Epoch: [19][  150/  211]    Overall Loss 0.094408    Objective Loss 0.094408                                        LR 0.100000    Time 0.024086    
2022-01-25 18:24:32,605 - Epoch: [19][  160/  211]    Overall Loss 0.093958    Objective Loss 0.093958                                        LR 0.100000    Time 0.023933    
2022-01-25 18:24:32,829 - Epoch: [19][  170/  211]    Overall Loss 0.093820    Objective Loss 0.093820                                        LR 0.100000    Time 0.023841    
2022-01-25 18:24:33,049 - Epoch: [19][  180/  211]    Overall Loss 0.094196    Objective Loss 0.094196                                        LR 0.100000    Time 0.023739    
2022-01-25 18:24:33,273 - Epoch: [19][  190/  211]    Overall Loss 0.093770    Objective Loss 0.093770                                        LR 0.100000    Time 0.023663    
2022-01-25 18:24:33,488 - Epoch: [19][  200/  211]    Overall Loss 0.093147    Objective Loss 0.093147                                        LR 0.100000    Time 0.023553    
2022-01-25 18:24:33,708 - Epoch: [19][  210/  211]    Overall Loss 0.092303    Objective Loss 0.092303    Top1 97.656250    Top5 99.609375    LR 0.100000    Time 0.023480    
2022-01-25 18:24:33,728 - Epoch: [19][  211/  211]    Overall Loss 0.092309    Objective Loss 0.092309    Top1 97.782258    Top5 99.798387    LR 0.100000    Time 0.023460    
2022-01-25 18:24:33,784 - --- validate (epoch=19)-----------
2022-01-25 18:24:33,784 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:34,258 - Epoch: [19][   10/   24]    Loss 0.084904    Top1 97.812500    Top5 100.000000    
2022-01-25 18:24:34,457 - Epoch: [19][   20/   24]    Loss 0.088366    Top1 97.773438    Top5 99.980469    
2022-01-25 18:24:34,544 - Epoch: [19][   24/   24]    Loss 0.086216    Top1 97.983333    Top5 99.983333    
2022-01-25 18:24:34,603 - ==> Top1: 97.983    Top5: 99.983    Loss: 0.086

2022-01-25 18:24:34,603 - ==> Confusion:
[[598   0   2   0   0   0   2   1   1   1]
 [  0 678   4   0   0   1   1   4   0   0]
 [  0   1 574   1   0   0   0   5   4   1]
 [  0   0   0 576   0   1   0   1   1   4]
 [  0   1   2   0 542   1   0   2   0  17]
 [  0   1   1   1   0 507   3   2   2   1]
 [  2   1   0   0   2   7 618   0   1   0]
 [  0   2   4   0   1   0   0 616   1   1]
 [  2   0   4   1   1   2   7   0 566   1]
 [  0   1   0   0   4   2   0   3   1 604]]

2022-01-25 18:24:34,605 - ==> Best [Top1: 98.100   Top5: 99.950   Sparsity:0.00   Params: 71148 on epoch: 14]
2022-01-25 18:24:34,605 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:34,611 - 

2022-01-25 18:24:34,611 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:35,322 - Epoch: [20][   10/  211]    Overall Loss 0.095297    Objective Loss 0.095297                                        LR 0.100000    Time 0.071019    
2022-01-25 18:24:35,536 - Epoch: [20][   20/  211]    Overall Loss 0.092609    Objective Loss 0.092609                                        LR 0.100000    Time 0.046161    
2022-01-25 18:24:35,749 - Epoch: [20][   30/  211]    Overall Loss 0.095576    Objective Loss 0.095576                                        LR 0.100000    Time 0.037889    
2022-01-25 18:24:35,983 - Epoch: [20][   40/  211]    Overall Loss 0.093443    Objective Loss 0.093443                                        LR 0.100000    Time 0.034251    
2022-01-25 18:24:36,189 - Epoch: [20][   50/  211]    Overall Loss 0.093452    Objective Loss 0.093452                                        LR 0.100000    Time 0.031523    
2022-01-25 18:24:36,471 - Epoch: [20][   60/  211]    Overall Loss 0.093191    Objective Loss 0.093191                                        LR 0.100000    Time 0.030958    
2022-01-25 18:24:36,725 - Epoch: [20][   70/  211]    Overall Loss 0.093709    Objective Loss 0.093709                                        LR 0.100000    Time 0.030160    
2022-01-25 18:24:37,004 - Epoch: [20][   80/  211]    Overall Loss 0.093114    Objective Loss 0.093114                                        LR 0.100000    Time 0.029871    
2022-01-25 18:24:37,253 - Epoch: [20][   90/  211]    Overall Loss 0.093655    Objective Loss 0.093655                                        LR 0.100000    Time 0.029310    
2022-01-25 18:24:37,544 - Epoch: [20][  100/  211]    Overall Loss 0.093156    Objective Loss 0.093156                                        LR 0.100000    Time 0.029285    
2022-01-25 18:24:37,794 - Epoch: [20][  110/  211]    Overall Loss 0.093086    Objective Loss 0.093086                                        LR 0.100000    Time 0.028898    
2022-01-25 18:24:38,067 - Epoch: [20][  120/  211]    Overall Loss 0.092044    Objective Loss 0.092044                                        LR 0.100000    Time 0.028763    
2022-01-25 18:24:38,316 - Epoch: [20][  130/  211]    Overall Loss 0.091722    Objective Loss 0.091722                                        LR 0.100000    Time 0.028457    
2022-01-25 18:24:38,607 - Epoch: [20][  140/  211]    Overall Loss 0.091177    Objective Loss 0.091177                                        LR 0.100000    Time 0.028506    
2022-01-25 18:24:38,852 - Epoch: [20][  150/  211]    Overall Loss 0.091029    Objective Loss 0.091029                                        LR 0.100000    Time 0.028235    
2022-01-25 18:24:39,133 - Epoch: [20][  160/  211]    Overall Loss 0.090972    Objective Loss 0.090972                                        LR 0.100000    Time 0.028225    
2022-01-25 18:24:39,384 - Epoch: [20][  170/  211]    Overall Loss 0.091593    Objective Loss 0.091593                                        LR 0.100000    Time 0.028035    
2022-01-25 18:24:39,662 - Epoch: [20][  180/  211]    Overall Loss 0.091222    Objective Loss 0.091222                                        LR 0.100000    Time 0.028022    
2022-01-25 18:24:39,913 - Epoch: [20][  190/  211]    Overall Loss 0.091154    Objective Loss 0.091154                                        LR 0.100000    Time 0.027868    
2022-01-25 18:24:40,198 - Epoch: [20][  200/  211]    Overall Loss 0.090433    Objective Loss 0.090433                                        LR 0.100000    Time 0.027899    
2022-01-25 18:24:40,441 - Epoch: [20][  210/  211]    Overall Loss 0.090183    Objective Loss 0.090183    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.027724    
2022-01-25 18:24:40,485 - Epoch: [20][  211/  211]    Overall Loss 0.090201    Objective Loss 0.090201    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.027799    
2022-01-25 18:24:40,554 - --- validate (epoch=20)-----------
2022-01-25 18:24:40,555 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:41,032 - Epoch: [20][   10/   24]    Loss 0.096508    Top1 97.929688    Top5 100.000000    
2022-01-25 18:24:41,291 - Epoch: [20][   20/   24]    Loss 0.089380    Top1 98.144531    Top5 100.000000    
2022-01-25 18:24:41,390 - Epoch: [20][   24/   24]    Loss 0.087228    Top1 98.183333    Top5 100.000000    
2022-01-25 18:24:41,445 - ==> Top1: 98.183    Top5: 100.000    Loss: 0.087

2022-01-25 18:24:41,446 - ==> Confusion:
[[597   0   3   0   1   0   0   2   2   0]
 [  0 685   0   1   0   0   0   2   0   0]
 [  0   1 576   2   0   0   0   4   3   0]
 [  0   0   5 572   0   2   0   2   2   0]
 [  0   0   2   0 557   0   0   0   1   5]
 [  0   0   0   3   1 507   1   0   6   0]
 [  1   3   1   0   2   4 612   0   8   0]
 [  0   2   3   0   1   0   0 617   0   2]
 [  0   0   1   2   3   2   0   0 575   1]
 [  1   3   0   3   5   1   0   5   4 593]]

2022-01-25 18:24:41,447 - ==> Best [Top1: 98.183   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2022-01-25 18:24:41,447 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:41,454 - 

2022-01-25 18:24:41,454 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:42,064 - Epoch: [21][   10/  211]    Overall Loss 0.079330    Objective Loss 0.079330                                        LR 0.100000    Time 0.060943    
2022-01-25 18:24:42,309 - Epoch: [21][   20/  211]    Overall Loss 0.080824    Objective Loss 0.080824                                        LR 0.100000    Time 0.042714    
2022-01-25 18:24:42,590 - Epoch: [21][   30/  211]    Overall Loss 0.082204    Objective Loss 0.082204                                        LR 0.100000    Time 0.037819    
2022-01-25 18:24:42,798 - Epoch: [21][   40/  211]    Overall Loss 0.083588    Objective Loss 0.083588                                        LR 0.100000    Time 0.033560    
2022-01-25 18:24:43,030 - Epoch: [21][   50/  211]    Overall Loss 0.084393    Objective Loss 0.084393                                        LR 0.100000    Time 0.031472    
2022-01-25 18:24:43,261 - Epoch: [21][   60/  211]    Overall Loss 0.084366    Objective Loss 0.084366                                        LR 0.100000    Time 0.030077    
2022-01-25 18:24:43,510 - Epoch: [21][   70/  211]    Overall Loss 0.084100    Objective Loss 0.084100                                        LR 0.100000    Time 0.029328    
2022-01-25 18:24:43,790 - Epoch: [21][   80/  211]    Overall Loss 0.084127    Objective Loss 0.084127                                        LR 0.100000    Time 0.029161    
2022-01-25 18:24:44,034 - Epoch: [21][   90/  211]    Overall Loss 0.084629    Objective Loss 0.084629                                        LR 0.100000    Time 0.028633    
2022-01-25 18:24:44,316 - Epoch: [21][  100/  211]    Overall Loss 0.084764    Objective Loss 0.084764                                        LR 0.100000    Time 0.028582    
2022-01-25 18:24:44,567 - Epoch: [21][  110/  211]    Overall Loss 0.085454    Objective Loss 0.085454                                        LR 0.100000    Time 0.028263    
2022-01-25 18:24:44,844 - Epoch: [21][  120/  211]    Overall Loss 0.086876    Objective Loss 0.086876                                        LR 0.100000    Time 0.028208    
2022-01-25 18:24:45,088 - Epoch: [21][  130/  211]    Overall Loss 0.087033    Objective Loss 0.087033                                        LR 0.100000    Time 0.027915    
2022-01-25 18:24:45,376 - Epoch: [21][  140/  211]    Overall Loss 0.087896    Objective Loss 0.087896                                        LR 0.100000    Time 0.027975    
2022-01-25 18:24:45,622 - Epoch: [21][  150/  211]    Overall Loss 0.088408    Objective Loss 0.088408                                        LR 0.100000    Time 0.027749    
2022-01-25 18:24:45,914 - Epoch: [21][  160/  211]    Overall Loss 0.088456    Objective Loss 0.088456                                        LR 0.100000    Time 0.027840    
2022-01-25 18:24:46,158 - Epoch: [21][  170/  211]    Overall Loss 0.088537    Objective Loss 0.088537                                        LR 0.100000    Time 0.027632    
2022-01-25 18:24:46,435 - Epoch: [21][  180/  211]    Overall Loss 0.088778    Objective Loss 0.088778                                        LR 0.100000    Time 0.027637    
2022-01-25 18:24:46,684 - Epoch: [21][  190/  211]    Overall Loss 0.087900    Objective Loss 0.087900                                        LR 0.100000    Time 0.027486    
2022-01-25 18:24:46,951 - Epoch: [21][  200/  211]    Overall Loss 0.087431    Objective Loss 0.087431                                        LR 0.100000    Time 0.027446    
2022-01-25 18:24:47,160 - Epoch: [21][  210/  211]    Overall Loss 0.087032    Objective Loss 0.087032    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.027132    
2022-01-25 18:24:47,194 - Epoch: [21][  211/  211]    Overall Loss 0.087032    Objective Loss 0.087032    Top1 97.782258    Top5 99.798387    LR 0.100000    Time 0.027163    
2022-01-25 18:24:47,266 - --- validate (epoch=21)-----------
2022-01-25 18:24:47,266 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:47,742 - Epoch: [21][   10/   24]    Loss 0.097656    Top1 97.578125    Top5 99.960938    
2022-01-25 18:24:48,015 - Epoch: [21][   20/   24]    Loss 0.098967    Top1 97.519531    Top5 99.941406    
2022-01-25 18:24:48,117 - Epoch: [21][   24/   24]    Loss 0.102568    Top1 97.383333    Top5 99.950000    
2022-01-25 18:24:48,175 - ==> Top1: 97.383    Top5: 99.950    Loss: 0.103

2022-01-25 18:24:48,176 - ==> Confusion:
[[592   0   2   0   0   1   1   0   7   2]
 [  0 682   1   0   0   0   0   3   2   0]
 [  0   0 568   5   0   0   0   4   6   3]
 [  0   0   0 579   0   2   0   2   0   0]
 [  0   1   2   0 521   3   2   3   6  27]
 [  1   0   0   4   0 508   2   0   3   0]
 [  3   3   0   0   1  11 609   0   4   0]
 [  1   2   2   3   0   0   0 615   0   2]
 [  0   0   0   2   1   3   2   0 576   0]
 [  0   1   0   1   0   5   0   5   9 594]]

2022-01-25 18:24:48,177 - ==> Best [Top1: 98.183   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2022-01-25 18:24:48,177 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:48,184 - 

2022-01-25 18:24:48,184 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:48,937 - Epoch: [22][   10/  211]    Overall Loss 0.091979    Objective Loss 0.091979                                        LR 0.100000    Time 0.075231    
2022-01-25 18:24:49,199 - Epoch: [22][   20/  211]    Overall Loss 0.087606    Objective Loss 0.087606                                        LR 0.100000    Time 0.050693    
2022-01-25 18:24:49,464 - Epoch: [22][   30/  211]    Overall Loss 0.088567    Objective Loss 0.088567                                        LR 0.100000    Time 0.042601    
2022-01-25 18:24:49,707 - Epoch: [22][   40/  211]    Overall Loss 0.088191    Objective Loss 0.088191                                        LR 0.100000    Time 0.038030    
2022-01-25 18:24:49,999 - Epoch: [22][   50/  211]    Overall Loss 0.090042    Objective Loss 0.090042                                        LR 0.100000    Time 0.036254    
2022-01-25 18:24:50,245 - Epoch: [22][   60/  211]    Overall Loss 0.089536    Objective Loss 0.089536                                        LR 0.100000    Time 0.034303    
2022-01-25 18:24:50,523 - Epoch: [22][   70/  211]    Overall Loss 0.089864    Objective Loss 0.089864                                        LR 0.100000    Time 0.033367    
2022-01-25 18:24:50,772 - Epoch: [22][   80/  211]    Overall Loss 0.089313    Objective Loss 0.089313                                        LR 0.100000    Time 0.032304    
2022-01-25 18:24:51,058 - Epoch: [22][   90/  211]    Overall Loss 0.088905    Objective Loss 0.088905                                        LR 0.100000    Time 0.031893    
2022-01-25 18:24:51,308 - Epoch: [22][  100/  211]    Overall Loss 0.087891    Objective Loss 0.087891                                        LR 0.100000    Time 0.031196    
2022-01-25 18:24:51,532 - Epoch: [22][  110/  211]    Overall Loss 0.087006    Objective Loss 0.087006                                        LR 0.100000    Time 0.030395    
2022-01-25 18:24:51,752 - Epoch: [22][  120/  211]    Overall Loss 0.085838    Objective Loss 0.085838                                        LR 0.100000    Time 0.029692    
2022-01-25 18:24:51,975 - Epoch: [22][  130/  211]    Overall Loss 0.085883    Objective Loss 0.085883                                        LR 0.100000    Time 0.029120    
2022-01-25 18:24:52,197 - Epoch: [22][  140/  211]    Overall Loss 0.085644    Objective Loss 0.085644                                        LR 0.100000    Time 0.028623    
2022-01-25 18:24:52,419 - Epoch: [22][  150/  211]    Overall Loss 0.085534    Objective Loss 0.085534                                        LR 0.100000    Time 0.028195    
2022-01-25 18:24:52,628 - Epoch: [22][  160/  211]    Overall Loss 0.085435    Objective Loss 0.085435                                        LR 0.100000    Time 0.027736    
2022-01-25 18:24:52,857 - Epoch: [22][  170/  211]    Overall Loss 0.085781    Objective Loss 0.085781                                        LR 0.100000    Time 0.027447    
2022-01-25 18:24:53,075 - Epoch: [22][  180/  211]    Overall Loss 0.085374    Objective Loss 0.085374                                        LR 0.100000    Time 0.027131    
2022-01-25 18:24:53,295 - Epoch: [22][  190/  211]    Overall Loss 0.084977    Objective Loss 0.084977                                        LR 0.100000    Time 0.026861    
2022-01-25 18:24:53,518 - Epoch: [22][  200/  211]    Overall Loss 0.085522    Objective Loss 0.085522                                        LR 0.100000    Time 0.026632    
2022-01-25 18:24:53,735 - Epoch: [22][  210/  211]    Overall Loss 0.085068    Objective Loss 0.085068    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.026394    
2022-01-25 18:24:53,754 - Epoch: [22][  211/  211]    Overall Loss 0.085168    Objective Loss 0.085168    Top1 97.782258    Top5 100.000000    LR 0.100000    Time 0.026357    
2022-01-25 18:24:53,809 - --- validate (epoch=22)-----------
2022-01-25 18:24:53,810 - 6000 samples (256 per mini-batch)
2022-01-25 18:24:54,284 - Epoch: [22][   10/   24]    Loss 0.075585    Top1 98.359375    Top5 100.000000    
2022-01-25 18:24:54,543 - Epoch: [22][   20/   24]    Loss 0.081321    Top1 98.007812    Top5 100.000000    
2022-01-25 18:24:54,645 - Epoch: [22][   24/   24]    Loss 0.079172    Top1 98.066667    Top5 100.000000    
2022-01-25 18:24:54,710 - ==> Top1: 98.067    Top5: 100.000    Loss: 0.079

2022-01-25 18:24:54,711 - ==> Confusion:
[[598   0   2   0   0   0   4   1   0   0]
 [  0 680   2   0   0   1   0   5   0   0]
 [  0   0 577   0   0   0   0   4   4   1]
 [  0   0   1 576   0   2   0   3   1   0]
 [  1   1   2   0 540   0   1   3   0  17]
 [  0   0   0   0   1 505   4   0   3   5]
 [  1   1   0   0   1   2 625   0   1   0]
 [  0   3   3   0   0   0   0 619   0   0]
 [  2   0   1   3   4   1   8   1 560   4]
 [  0   1   0   1   1   1   0   5   2 604]]

2022-01-25 18:24:54,713 - ==> Best [Top1: 98.183   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2022-01-25 18:24:54,713 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:24:54,721 - 

2022-01-25 18:24:54,721 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:24:55,463 - Epoch: [23][   10/  211]    Overall Loss 0.083946    Objective Loss 0.083946                                        LR 0.100000    Time 0.074113    
2022-01-25 18:24:55,709 - Epoch: [23][   20/  211]    Overall Loss 0.091052    Objective Loss 0.091052                                        LR 0.100000    Time 0.049336    
2022-01-25 18:24:55,988 - Epoch: [23][   30/  211]    Overall Loss 0.093705    Objective Loss 0.093705                                        LR 0.100000    Time 0.042189    
2022-01-25 18:24:56,234 - Epoch: [23][   40/  211]    Overall Loss 0.091858    Objective Loss 0.091858                                        LR 0.100000    Time 0.037764    
2022-01-25 18:24:56,523 - Epoch: [23][   50/  211]    Overall Loss 0.090520    Objective Loss 0.090520                                        LR 0.100000    Time 0.035987    
2022-01-25 18:24:56,768 - Epoch: [23][   60/  211]    Overall Loss 0.087582    Objective Loss 0.087582                                        LR 0.100000    Time 0.034064    
2022-01-25 18:24:57,052 - Epoch: [23][   70/  211]    Overall Loss 0.087325    Objective Loss 0.087325                                        LR 0.100000    Time 0.033256    
2022-01-25 18:24:57,300 - Epoch: [23][   80/  211]    Overall Loss 0.087546    Objective Loss 0.087546                                        LR 0.100000    Time 0.032190    
2022-01-25 18:24:57,582 - Epoch: [23][   90/  211]    Overall Loss 0.087268    Objective Loss 0.087268                                        LR 0.100000    Time 0.031746    
2022-01-25 18:24:57,830 - Epoch: [23][  100/  211]    Overall Loss 0.087651    Objective Loss 0.087651                                        LR 0.100000    Time 0.031047    
2022-01-25 18:24:58,114 - Epoch: [23][  110/  211]    Overall Loss 0.087951    Objective Loss 0.087951                                        LR 0.100000    Time 0.030801    
2022-01-25 18:24:58,359 - Epoch: [23][  120/  211]    Overall Loss 0.088168    Objective Loss 0.088168                                        LR 0.100000    Time 0.030275    
2022-01-25 18:24:58,648 - Epoch: [23][  130/  211]    Overall Loss 0.087975    Objective Loss 0.087975                                        LR 0.100000    Time 0.030164    
2022-01-25 18:24:58,892 - Epoch: [23][  140/  211]    Overall Loss 0.087270    Objective Loss 0.087270                                        LR 0.100000    Time 0.029755    
2022-01-25 18:24:59,177 - Epoch: [23][  150/  211]    Overall Loss 0.086594    Objective Loss 0.086594                                        LR 0.100000    Time 0.029670    
2022-01-25 18:24:59,430 - Epoch: [23][  160/  211]    Overall Loss 0.086637    Objective Loss 0.086637                                        LR 0.100000    Time 0.029395    
2022-01-25 18:24:59,711 - Epoch: [23][  170/  211]    Overall Loss 0.085986    Objective Loss 0.085986                                        LR 0.100000    Time 0.029316    
2022-01-25 18:24:59,959 - Epoch: [23][  180/  211]    Overall Loss 0.086136    Objective Loss 0.086136                                        LR 0.100000    Time 0.029060    
2022-01-25 18:25:00,235 - Epoch: [23][  190/  211]    Overall Loss 0.085677    Objective Loss 0.085677                                        LR 0.100000    Time 0.028982    
2022-01-25 18:25:00,481 - Epoch: [23][  200/  211]    Overall Loss 0.085368    Objective Loss 0.085368                                        LR 0.100000    Time 0.028760    
2022-01-25 18:25:00,767 - Epoch: [23][  210/  211]    Overall Loss 0.085617    Objective Loss 0.085617    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.028752    
2022-01-25 18:25:00,786 - Epoch: [23][  211/  211]    Overall Loss 0.085512    Objective Loss 0.085512    Top1 97.782258    Top5 100.000000    LR 0.100000    Time 0.028706    
2022-01-25 18:25:00,843 - --- validate (epoch=23)-----------
2022-01-25 18:25:00,844 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:01,354 - Epoch: [23][   10/   24]    Loss 0.079512    Top1 98.281250    Top5 99.960938    
2022-01-25 18:25:01,554 - Epoch: [23][   20/   24]    Loss 0.080033    Top1 98.203125    Top5 99.980469    
2022-01-25 18:25:01,638 - Epoch: [23][   24/   24]    Loss 0.082857    Top1 98.083333    Top5 99.966667    
2022-01-25 18:25:01,698 - ==> Top1: 98.083    Top5: 99.967    Loss: 0.083

2022-01-25 18:25:01,699 - ==> Confusion:
[[605   0   0   0   0   0   0   0   0   0]
 [  1 680   2   0   0   0   0   5   0   0]
 [  1   2 571   1   0   0   1   7   0   3]
 [  1   1   6 566   0   4   0   4   1   0]
 [  1   1   0   0 553   0   0   4   0   6]
 [  1   1   0   1   1 508   5   1   0   0]
 [  2   2   0   0   1   4 621   0   1   0]
 [  0   3   3   0   0   0   0 619   0   0]
 [  7   1   1   2   5   1   5   0 560   2]
 [  0   1   0   1   3   1   1   4   2 602]]

2022-01-25 18:25:01,700 - ==> Best [Top1: 98.183   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2022-01-25 18:25:01,700 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:01,707 - 

2022-01-25 18:25:01,707 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:02,303 - Epoch: [24][   10/  211]    Overall Loss 0.085284    Objective Loss 0.085284                                        LR 0.100000    Time 0.059584    
2022-01-25 18:25:02,519 - Epoch: [24][   20/  211]    Overall Loss 0.081910    Objective Loss 0.081910                                        LR 0.100000    Time 0.040552    
2022-01-25 18:25:02,740 - Epoch: [24][   30/  211]    Overall Loss 0.080965    Objective Loss 0.080965                                        LR 0.100000    Time 0.034379    
2022-01-25 18:25:02,951 - Epoch: [24][   40/  211]    Overall Loss 0.081194    Objective Loss 0.081194                                        LR 0.100000    Time 0.031051    
2022-01-25 18:25:03,175 - Epoch: [24][   50/  211]    Overall Loss 0.079770    Objective Loss 0.079770                                        LR 0.100000    Time 0.029317    
2022-01-25 18:25:03,386 - Epoch: [24][   60/  211]    Overall Loss 0.080884    Objective Loss 0.080884                                        LR 0.100000    Time 0.027944    
2022-01-25 18:25:03,610 - Epoch: [24][   70/  211]    Overall Loss 0.081893    Objective Loss 0.081893                                        LR 0.100000    Time 0.027153    
2022-01-25 18:25:03,826 - Epoch: [24][   80/  211]    Overall Loss 0.080770    Objective Loss 0.080770                                        LR 0.100000    Time 0.026455    
2022-01-25 18:25:04,060 - Epoch: [24][   90/  211]    Overall Loss 0.079088    Objective Loss 0.079088                                        LR 0.100000    Time 0.026104    
2022-01-25 18:25:04,277 - Epoch: [24][  100/  211]    Overall Loss 0.079138    Objective Loss 0.079138                                        LR 0.100000    Time 0.025664    
2022-01-25 18:25:04,498 - Epoch: [24][  110/  211]    Overall Loss 0.079149    Objective Loss 0.079149                                        LR 0.100000    Time 0.025339    
2022-01-25 18:25:04,710 - Epoch: [24][  120/  211]    Overall Loss 0.078905    Objective Loss 0.078905                                        LR 0.100000    Time 0.024990    
2022-01-25 18:25:04,936 - Epoch: [24][  130/  211]    Overall Loss 0.079483    Objective Loss 0.079483                                        LR 0.100000    Time 0.024804    
2022-01-25 18:25:05,154 - Epoch: [24][  140/  211]    Overall Loss 0.079098    Objective Loss 0.079098                                        LR 0.100000    Time 0.024588    
2022-01-25 18:25:05,377 - Epoch: [24][  150/  211]    Overall Loss 0.078613    Objective Loss 0.078613                                        LR 0.100000    Time 0.024433    
2022-01-25 18:25:05,587 - Epoch: [24][  160/  211]    Overall Loss 0.078797    Objective Loss 0.078797                                        LR 0.100000    Time 0.024212    
2022-01-25 18:25:05,820 - Epoch: [24][  170/  211]    Overall Loss 0.078696    Objective Loss 0.078696                                        LR 0.100000    Time 0.024156    
2022-01-25 18:25:06,034 - Epoch: [24][  180/  211]    Overall Loss 0.079576    Objective Loss 0.079576                                        LR 0.100000    Time 0.024005    
2022-01-25 18:25:06,256 - Epoch: [24][  190/  211]    Overall Loss 0.080402    Objective Loss 0.080402                                        LR 0.100000    Time 0.023903    
2022-01-25 18:25:06,466 - Epoch: [24][  200/  211]    Overall Loss 0.081031    Objective Loss 0.081031                                        LR 0.100000    Time 0.023758    
2022-01-25 18:25:06,693 - Epoch: [24][  210/  211]    Overall Loss 0.081070    Objective Loss 0.081070    Top1 95.703125    Top5 100.000000    LR 0.100000    Time 0.023709    
2022-01-25 18:25:06,734 - Epoch: [24][  211/  211]    Overall Loss 0.081099    Objective Loss 0.081099    Top1 96.774194    Top5 100.000000    LR 0.100000    Time 0.023790    
2022-01-25 18:25:06,791 - --- validate (epoch=24)-----------
2022-01-25 18:25:06,792 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:07,282 - Epoch: [24][   10/   24]    Loss 0.086177    Top1 97.929688    Top5 100.000000    
2022-01-25 18:25:07,525 - Epoch: [24][   20/   24]    Loss 0.087118    Top1 97.832031    Top5 99.980469    
2022-01-25 18:25:07,628 - Epoch: [24][   24/   24]    Loss 0.086785    Top1 97.883333    Top5 99.983333    
2022-01-25 18:25:07,688 - ==> Top1: 97.883    Top5: 99.983    Loss: 0.087

2022-01-25 18:25:07,689 - ==> Confusion:
[[589   0   1   0   1   0   2   1  10   1]
 [  0 679   2   0   0   0   0   7   0   0]
 [  0   0 563   7   0   0   1   5   9   1]
 [  0   0   1 580   0   1   0   0   1   0]
 [  0   1   0   0 551   0   0   1   2  10]
 [  0   0   0   5   0 501   4   0   8   0]
 [  1   0   0   0   4   0 622   0   4   0]
 [  0   0   0   4   3   1   0 615   0   2]
 [  0   0   1   3   2   1   2   0 575   0]
 [  0   1   0   2   4   4   0   2   4 598]]

2022-01-25 18:25:07,690 - ==> Best [Top1: 98.183   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2022-01-25 18:25:07,691 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:07,697 - 

2022-01-25 18:25:07,697 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:08,392 - Epoch: [25][   10/  211]    Overall Loss 0.087738    Objective Loss 0.087738                                        LR 0.100000    Time 0.069469    
2022-01-25 18:25:08,599 - Epoch: [25][   20/  211]    Overall Loss 0.082424    Objective Loss 0.082424                                        LR 0.100000    Time 0.045035    
2022-01-25 18:25:08,826 - Epoch: [25][   30/  211]    Overall Loss 0.081728    Objective Loss 0.081728                                        LR 0.100000    Time 0.037595    
2022-01-25 18:25:09,031 - Epoch: [25][   40/  211]    Overall Loss 0.079596    Objective Loss 0.079596                                        LR 0.100000    Time 0.033309    
2022-01-25 18:25:09,247 - Epoch: [25][   50/  211]    Overall Loss 0.079326    Objective Loss 0.079326                                        LR 0.100000    Time 0.030965    
2022-01-25 18:25:09,466 - Epoch: [25][   60/  211]    Overall Loss 0.077032    Objective Loss 0.077032                                        LR 0.100000    Time 0.029448    
2022-01-25 18:25:09,686 - Epoch: [25][   70/  211]    Overall Loss 0.077518    Objective Loss 0.077518                                        LR 0.100000    Time 0.028370    
2022-01-25 18:25:09,943 - Epoch: [25][   80/  211]    Overall Loss 0.077451    Objective Loss 0.077451                                        LR 0.100000    Time 0.028036    
2022-01-25 18:25:10,187 - Epoch: [25][   90/  211]    Overall Loss 0.077515    Objective Loss 0.077515                                        LR 0.100000    Time 0.027630    
2022-01-25 18:25:10,465 - Epoch: [25][  100/  211]    Overall Loss 0.077813    Objective Loss 0.077813                                        LR 0.100000    Time 0.027639    
2022-01-25 18:25:10,680 - Epoch: [25][  110/  211]    Overall Loss 0.077611    Objective Loss 0.077611                                        LR 0.100000    Time 0.027079    
2022-01-25 18:25:10,914 - Epoch: [25][  120/  211]    Overall Loss 0.077530    Objective Loss 0.077530                                        LR 0.100000    Time 0.026767    
2022-01-25 18:25:11,130 - Epoch: [25][  130/  211]    Overall Loss 0.078150    Objective Loss 0.078150                                        LR 0.100000    Time 0.026371    
2022-01-25 18:25:11,357 - Epoch: [25][  140/  211]    Overall Loss 0.077404    Objective Loss 0.077404                                        LR 0.100000    Time 0.026108    
2022-01-25 18:25:11,573 - Epoch: [25][  150/  211]    Overall Loss 0.077633    Objective Loss 0.077633                                        LR 0.100000    Time 0.025804    
2022-01-25 18:25:11,800 - Epoch: [25][  160/  211]    Overall Loss 0.077812    Objective Loss 0.077812                                        LR 0.100000    Time 0.025607    
2022-01-25 18:25:12,075 - Epoch: [25][  170/  211]    Overall Loss 0.077763    Objective Loss 0.077763                                        LR 0.100000    Time 0.025716    
2022-01-25 18:25:12,325 - Epoch: [25][  180/  211]    Overall Loss 0.077945    Objective Loss 0.077945                                        LR 0.100000    Time 0.025677    
2022-01-25 18:25:12,605 - Epoch: [25][  190/  211]    Overall Loss 0.078547    Objective Loss 0.078547                                        LR 0.100000    Time 0.025794    
2022-01-25 18:25:12,859 - Epoch: [25][  200/  211]    Overall Loss 0.078418    Objective Loss 0.078418                                        LR 0.100000    Time 0.025776    
2022-01-25 18:25:13,140 - Epoch: [25][  210/  211]    Overall Loss 0.077942    Objective Loss 0.077942    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.025882    
2022-01-25 18:25:13,160 - Epoch: [25][  211/  211]    Overall Loss 0.077828    Objective Loss 0.077828    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.025853    
2022-01-25 18:25:13,243 - --- validate (epoch=25)-----------
2022-01-25 18:25:13,243 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:13,776 - Epoch: [25][   10/   24]    Loss 0.071112    Top1 98.164062    Top5 100.000000    
2022-01-25 18:25:14,036 - Epoch: [25][   20/   24]    Loss 0.073719    Top1 98.183594    Top5 100.000000    
2022-01-25 18:25:14,136 - Epoch: [25][   24/   24]    Loss 0.073563    Top1 98.133333    Top5 100.000000    
2022-01-25 18:25:14,192 - ==> Top1: 98.133    Top5: 100.000    Loss: 0.074

2022-01-25 18:25:14,193 - ==> Confusion:
[[600   0   1   1   0   0   1   1   1   0]
 [  0 682   1   0   0   1   2   2   0   0]
 [  0   1 580   0   1   0   1   2   1   0]
 [  0   0   0 574   0   2   0   5   1   1]
 [  0   1   1   0 550   1   3   1   2   6]
 [  2   0   0   1   0 509   5   0   1   0]
 [  4   0   0   0   1   4 620   0   2   0]
 [  0  10   6   3   1   0   0 603   0   2]
 [  3   0   0   2   2   0   3   0 574   0]
 [  2   2   0   0   5   2   2   2   3 597]]

2022-01-25 18:25:14,195 - ==> Best [Top1: 98.183   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2022-01-25 18:25:14,196 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:14,205 - 

2022-01-25 18:25:14,205 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:14,909 - Epoch: [26][   10/  211]    Overall Loss 0.062964    Objective Loss 0.062964                                        LR 0.100000    Time 0.070361    
2022-01-25 18:25:15,111 - Epoch: [26][   20/  211]    Overall Loss 0.068646    Objective Loss 0.068646                                        LR 0.100000    Time 0.045245    
2022-01-25 18:25:15,337 - Epoch: [26][   30/  211]    Overall Loss 0.074390    Objective Loss 0.074390                                        LR 0.100000    Time 0.037673    
2022-01-25 18:25:15,550 - Epoch: [26][   40/  211]    Overall Loss 0.073809    Objective Loss 0.073809                                        LR 0.100000    Time 0.033570    
2022-01-25 18:25:15,778 - Epoch: [26][   50/  211]    Overall Loss 0.072886    Objective Loss 0.072886                                        LR 0.100000    Time 0.031419    
2022-01-25 18:25:15,994 - Epoch: [26][   60/  211]    Overall Loss 0.072736    Objective Loss 0.072736                                        LR 0.100000    Time 0.029776    
2022-01-25 18:25:16,220 - Epoch: [26][   70/  211]    Overall Loss 0.073245    Objective Loss 0.073245                                        LR 0.100000    Time 0.028740    
2022-01-25 18:25:16,481 - Epoch: [26][   80/  211]    Overall Loss 0.075489    Objective Loss 0.075489                                        LR 0.100000    Time 0.028410    
2022-01-25 18:25:16,731 - Epoch: [26][   90/  211]    Overall Loss 0.075186    Objective Loss 0.075186                                        LR 0.100000    Time 0.028028    
2022-01-25 18:25:17,025 - Epoch: [26][  100/  211]    Overall Loss 0.075543    Objective Loss 0.075543                                        LR 0.100000    Time 0.028162    
2022-01-25 18:25:17,269 - Epoch: [26][  110/  211]    Overall Loss 0.076840    Objective Loss 0.076840                                        LR 0.100000    Time 0.027813    
2022-01-25 18:25:17,553 - Epoch: [26][  120/  211]    Overall Loss 0.077612    Objective Loss 0.077612                                        LR 0.100000    Time 0.027865    
2022-01-25 18:25:17,800 - Epoch: [26][  130/  211]    Overall Loss 0.078267    Objective Loss 0.078267                                        LR 0.100000    Time 0.027618    
2022-01-25 18:25:18,089 - Epoch: [26][  140/  211]    Overall Loss 0.078187    Objective Loss 0.078187                                        LR 0.100000    Time 0.027709    
2022-01-25 18:25:18,337 - Epoch: [26][  150/  211]    Overall Loss 0.078044    Objective Loss 0.078044                                        LR 0.100000    Time 0.027513    
2022-01-25 18:25:18,602 - Epoch: [26][  160/  211]    Overall Loss 0.077830    Objective Loss 0.077830                                        LR 0.100000    Time 0.027443    
2022-01-25 18:25:18,816 - Epoch: [26][  170/  211]    Overall Loss 0.078427    Objective Loss 0.078427                                        LR 0.100000    Time 0.027084    
2022-01-25 18:25:19,052 - Epoch: [26][  180/  211]    Overall Loss 0.077941    Objective Loss 0.077941                                        LR 0.100000    Time 0.026889    
2022-01-25 18:25:19,267 - Epoch: [26][  190/  211]    Overall Loss 0.078581    Objective Loss 0.078581                                        LR 0.100000    Time 0.026607    
2022-01-25 18:25:19,485 - Epoch: [26][  200/  211]    Overall Loss 0.078746    Objective Loss 0.078746                                        LR 0.100000    Time 0.026364    
2022-01-25 18:25:19,702 - Epoch: [26][  210/  211]    Overall Loss 0.078709    Objective Loss 0.078709    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.026139    
2022-01-25 18:25:19,723 - Epoch: [26][  211/  211]    Overall Loss 0.078615    Objective Loss 0.078615    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.026116    
2022-01-25 18:25:19,780 - --- validate (epoch=26)-----------
2022-01-25 18:25:19,781 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:20,356 - Epoch: [26][   10/   24]    Loss 0.082905    Top1 97.617188    Top5 100.000000    
2022-01-25 18:25:20,564 - Epoch: [26][   20/   24]    Loss 0.080240    Top1 97.832031    Top5 99.980469    
2022-01-25 18:25:20,647 - Epoch: [26][   24/   24]    Loss 0.079192    Top1 97.916667    Top5 99.950000    
2022-01-25 18:25:20,705 - ==> Top1: 97.917    Top5: 99.950    Loss: 0.079

2022-01-25 18:25:20,706 - ==> Confusion:
[[597   0   0   0   1   1   4   0   0   2]
 [  0 685   1   0   0   0   0   2   0   0]
 [  2   4 554   1   1   0   0  15   4   5]
 [  1   0   3 574   0   1   0   1   2   1]
 [  0   1   1   0 554   0   0   1   1   7]
 [  2   0   0   2   0 509   3   0   2   0]
 [  2   1   0   0   4   2 621   0   0   1]
 [  0   5   2   1   1   1   0 613   0   2]
 [  3   0   0   1   2   2   7   0 565   4]
 [  0   3   0   0   1   2   0   4   2 603]]

2022-01-25 18:25:20,707 - ==> Best [Top1: 98.183   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2022-01-25 18:25:20,707 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:20,713 - 

2022-01-25 18:25:20,713 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:21,301 - Epoch: [27][   10/  211]    Overall Loss 0.068318    Objective Loss 0.068318                                        LR 0.100000    Time 0.058740    
2022-01-25 18:25:21,550 - Epoch: [27][   20/  211]    Overall Loss 0.075638    Objective Loss 0.075638                                        LR 0.100000    Time 0.041809    
2022-01-25 18:25:21,826 - Epoch: [27][   30/  211]    Overall Loss 0.078005    Objective Loss 0.078005                                        LR 0.100000    Time 0.037062    
2022-01-25 18:25:22,071 - Epoch: [27][   40/  211]    Overall Loss 0.077470    Objective Loss 0.077470                                        LR 0.100000    Time 0.033900    
2022-01-25 18:25:22,306 - Epoch: [27][   50/  211]    Overall Loss 0.077459    Objective Loss 0.077459                                        LR 0.100000    Time 0.031815    
2022-01-25 18:25:22,549 - Epoch: [27][   60/  211]    Overall Loss 0.076130    Objective Loss 0.076130                                        LR 0.100000    Time 0.030559    
2022-01-25 18:25:22,828 - Epoch: [27][   70/  211]    Overall Loss 0.075467    Objective Loss 0.075467                                        LR 0.100000    Time 0.030172    
2022-01-25 18:25:23,084 - Epoch: [27][   80/  211]    Overall Loss 0.077271    Objective Loss 0.077271                                        LR 0.100000    Time 0.029601    
2022-01-25 18:25:23,362 - Epoch: [27][   90/  211]    Overall Loss 0.076748    Objective Loss 0.076748                                        LR 0.100000    Time 0.029402    
2022-01-25 18:25:23,609 - Epoch: [27][  100/  211]    Overall Loss 0.077632    Objective Loss 0.077632                                        LR 0.100000    Time 0.028919    
2022-01-25 18:25:23,887 - Epoch: [27][  110/  211]    Overall Loss 0.078535    Objective Loss 0.078535                                        LR 0.100000    Time 0.028817    
2022-01-25 18:25:24,145 - Epoch: [27][  120/  211]    Overall Loss 0.078000    Objective Loss 0.078000                                        LR 0.100000    Time 0.028560    
2022-01-25 18:25:24,420 - Epoch: [27][  130/  211]    Overall Loss 0.077233    Objective Loss 0.077233                                        LR 0.100000    Time 0.028476    
2022-01-25 18:25:24,668 - Epoch: [27][  140/  211]    Overall Loss 0.077498    Objective Loss 0.077498                                        LR 0.100000    Time 0.028214    
2022-01-25 18:25:24,947 - Epoch: [27][  150/  211]    Overall Loss 0.077438    Objective Loss 0.077438                                        LR 0.100000    Time 0.028192    
2022-01-25 18:25:25,191 - Epoch: [27][  160/  211]    Overall Loss 0.077591    Objective Loss 0.077591                                        LR 0.100000    Time 0.027948    
2022-01-25 18:25:25,480 - Epoch: [27][  170/  211]    Overall Loss 0.077127    Objective Loss 0.077127                                        LR 0.100000    Time 0.028005    
2022-01-25 18:25:25,722 - Epoch: [27][  180/  211]    Overall Loss 0.077656    Objective Loss 0.077656                                        LR 0.100000    Time 0.027790    
2022-01-25 18:25:26,002 - Epoch: [27][  190/  211]    Overall Loss 0.077220    Objective Loss 0.077220                                        LR 0.100000    Time 0.027800    
2022-01-25 18:25:26,245 - Epoch: [27][  200/  211]    Overall Loss 0.077417    Objective Loss 0.077417                                        LR 0.100000    Time 0.027623    
2022-01-25 18:25:26,526 - Epoch: [27][  210/  211]    Overall Loss 0.077218    Objective Loss 0.077218    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.027647    
2022-01-25 18:25:26,545 - Epoch: [27][  211/  211]    Overall Loss 0.077123    Objective Loss 0.077123    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.027604    
2022-01-25 18:25:26,601 - --- validate (epoch=27)-----------
2022-01-25 18:25:26,602 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:27,120 - Epoch: [27][   10/   24]    Loss 0.071579    Top1 98.359375    Top5 100.000000    
2022-01-25 18:25:27,363 - Epoch: [27][   20/   24]    Loss 0.073075    Top1 98.300781    Top5 100.000000    
2022-01-25 18:25:27,460 - Epoch: [27][   24/   24]    Loss 0.071883    Top1 98.283333    Top5 100.000000    
2022-01-25 18:25:27,515 - ==> Top1: 98.283    Top5: 100.000    Loss: 0.072

2022-01-25 18:25:27,515 - ==> Confusion:
[[599   0   1   0   0   0   2   0   2   1]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   2 578   0   0   0   0   3   3   0]
 [  0   1   3 573   0   3   0   2   1   0]
 [  0   0   0   0 552   0   0   3   1   9]
 [  0   1   0   1   0 514   1   0   1   0]
 [  2   2   0   0   3   6 616   0   2   0]
 [  0   4   4   2   1   0   0 614   0   0]
 [  1   0   0   1   3   2   1   0 574   2]
 [  1   2   0   0  10   4   0   4   3 591]]

2022-01-25 18:25:27,517 - ==> Best [Top1: 98.283   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 27]
2022-01-25 18:25:27,517 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:27,524 - 

2022-01-25 18:25:27,525 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:28,222 - Epoch: [28][   10/  211]    Overall Loss 0.073402    Objective Loss 0.073402                                        LR 0.100000    Time 0.069687    
2022-01-25 18:25:28,473 - Epoch: [28][   20/  211]    Overall Loss 0.071608    Objective Loss 0.071608                                        LR 0.100000    Time 0.047346    
2022-01-25 18:25:28,708 - Epoch: [28][   30/  211]    Overall Loss 0.073406    Objective Loss 0.073406                                        LR 0.100000    Time 0.039398    
2022-01-25 18:25:28,934 - Epoch: [28][   40/  211]    Overall Loss 0.075027    Objective Loss 0.075027                                        LR 0.100000    Time 0.035201    
2022-01-25 18:25:29,141 - Epoch: [28][   50/  211]    Overall Loss 0.078919    Objective Loss 0.078919                                        LR 0.100000    Time 0.032291    
2022-01-25 18:25:29,369 - Epoch: [28][   60/  211]    Overall Loss 0.078299    Objective Loss 0.078299                                        LR 0.100000    Time 0.030697    
2022-01-25 18:25:29,625 - Epoch: [28][   70/  211]    Overall Loss 0.077375    Objective Loss 0.077375                                        LR 0.100000    Time 0.029963    
2022-01-25 18:25:29,877 - Epoch: [28][   80/  211]    Overall Loss 0.076768    Objective Loss 0.076768                                        LR 0.100000    Time 0.029372    
2022-01-25 18:25:30,161 - Epoch: [28][   90/  211]    Overall Loss 0.077982    Objective Loss 0.077982                                        LR 0.100000    Time 0.029251    
2022-01-25 18:25:30,408 - Epoch: [28][  100/  211]    Overall Loss 0.077685    Objective Loss 0.077685                                        LR 0.100000    Time 0.028794    
2022-01-25 18:25:30,692 - Epoch: [28][  110/  211]    Overall Loss 0.077192    Objective Loss 0.077192                                        LR 0.100000    Time 0.028762    
2022-01-25 18:25:30,950 - Epoch: [28][  120/  211]    Overall Loss 0.077331    Objective Loss 0.077331                                        LR 0.100000    Time 0.028504    
2022-01-25 18:25:31,232 - Epoch: [28][  130/  211]    Overall Loss 0.077582    Objective Loss 0.077582                                        LR 0.100000    Time 0.028479    
2022-01-25 18:25:31,485 - Epoch: [28][  140/  211]    Overall Loss 0.077747    Objective Loss 0.077747                                        LR 0.100000    Time 0.028247    
2022-01-25 18:25:31,765 - Epoch: [28][  150/  211]    Overall Loss 0.077665    Objective Loss 0.077665                                        LR 0.100000    Time 0.028229    
2022-01-25 18:25:32,018 - Epoch: [28][  160/  211]    Overall Loss 0.077286    Objective Loss 0.077286                                        LR 0.100000    Time 0.028042    
2022-01-25 18:25:32,298 - Epoch: [28][  170/  211]    Overall Loss 0.077354    Objective Loss 0.077354                                        LR 0.100000    Time 0.028039    
2022-01-25 18:25:32,549 - Epoch: [28][  180/  211]    Overall Loss 0.077458    Objective Loss 0.077458                                        LR 0.100000    Time 0.027876    
2022-01-25 18:25:32,831 - Epoch: [28][  190/  211]    Overall Loss 0.076951    Objective Loss 0.076951                                        LR 0.100000    Time 0.027887    
2022-01-25 18:25:33,085 - Epoch: [28][  200/  211]    Overall Loss 0.077432    Objective Loss 0.077432                                        LR 0.100000    Time 0.027761    
2022-01-25 18:25:33,358 - Epoch: [28][  210/  211]    Overall Loss 0.077336    Objective Loss 0.077336    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.027742    
2022-01-25 18:25:33,377 - Epoch: [28][  211/  211]    Overall Loss 0.077447    Objective Loss 0.077447    Top1 97.580645    Top5 100.000000    LR 0.100000    Time 0.027696    
2022-01-25 18:25:33,440 - --- validate (epoch=28)-----------
2022-01-25 18:25:33,440 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:33,917 - Epoch: [28][   10/   24]    Loss 0.068480    Top1 98.320312    Top5 100.000000    
2022-01-25 18:25:34,110 - Epoch: [28][   20/   24]    Loss 0.077473    Top1 98.144531    Top5 99.960938    
2022-01-25 18:25:34,194 - Epoch: [28][   24/   24]    Loss 0.077003    Top1 98.166667    Top5 99.966667    
2022-01-25 18:25:34,251 - ==> Top1: 98.167    Top5: 99.967    Loss: 0.077

2022-01-25 18:25:34,252 - ==> Confusion:
[[598   0   3   0   0   1   2   0   1   0]
 [  0 682   2   0   0   1   0   3   0   0]
 [  0   1 584   1   0   0   0   0   0   0]
 [  1   0   8 566   0   6   1   1   0   0]
 [  0   1   2   0 545   0   0   3   1  13]
 [  0   0   2   1   0 512   2   0   1   0]
 [  1   2   0   0   3   2 623   0   0   0]
 [  0   4   3   0   0   0   0 617   0   1]
 [  2   2   1   1   3   3   3   0 568   1]
 [  0   2   2   1   6   2   0   5   2 595]]

2022-01-25 18:25:34,255 - ==> Best [Top1: 98.283   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 27]
2022-01-25 18:25:34,255 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:34,261 - 

2022-01-25 18:25:34,261 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:34,853 - Epoch: [29][   10/  211]    Overall Loss 0.079648    Objective Loss 0.079648                                        LR 0.100000    Time 0.059154    
2022-01-25 18:25:35,061 - Epoch: [29][   20/  211]    Overall Loss 0.075179    Objective Loss 0.075179                                        LR 0.100000    Time 0.039963    
2022-01-25 18:25:35,283 - Epoch: [29][   30/  211]    Overall Loss 0.074890    Objective Loss 0.074890                                        LR 0.100000    Time 0.034009    
2022-01-25 18:25:35,485 - Epoch: [29][   40/  211]    Overall Loss 0.074940    Objective Loss 0.074940                                        LR 0.100000    Time 0.030559    
2022-01-25 18:25:35,708 - Epoch: [29][   50/  211]    Overall Loss 0.074281    Objective Loss 0.074281                                        LR 0.100000    Time 0.028906    
2022-01-25 18:25:35,915 - Epoch: [29][   60/  211]    Overall Loss 0.075029    Objective Loss 0.075029                                        LR 0.100000    Time 0.027532    
2022-01-25 18:25:36,148 - Epoch: [29][   70/  211]    Overall Loss 0.075767    Objective Loss 0.075767                                        LR 0.100000    Time 0.026915    
2022-01-25 18:25:36,357 - Epoch: [29][   80/  211]    Overall Loss 0.075880    Objective Loss 0.075880                                        LR 0.100000    Time 0.026152    
2022-01-25 18:25:36,578 - Epoch: [29][   90/  211]    Overall Loss 0.077344    Objective Loss 0.077344                                        LR 0.100000    Time 0.025702    
2022-01-25 18:25:36,784 - Epoch: [29][  100/  211]    Overall Loss 0.079152    Objective Loss 0.079152                                        LR 0.100000    Time 0.025192    
2022-01-25 18:25:37,008 - Epoch: [29][  110/  211]    Overall Loss 0.079338    Objective Loss 0.079338                                        LR 0.100000    Time 0.024927    
2022-01-25 18:25:37,213 - Epoch: [29][  120/  211]    Overall Loss 0.078886    Objective Loss 0.078886                                        LR 0.100000    Time 0.024563    
2022-01-25 18:25:37,444 - Epoch: [29][  130/  211]    Overall Loss 0.078476    Objective Loss 0.078476                                        LR 0.100000    Time 0.024446    
2022-01-25 18:25:37,652 - Epoch: [29][  140/  211]    Overall Loss 0.078020    Objective Loss 0.078020                                        LR 0.100000    Time 0.024184    
2022-01-25 18:25:37,871 - Epoch: [29][  150/  211]    Overall Loss 0.078064    Objective Loss 0.078064                                        LR 0.100000    Time 0.024028    
2022-01-25 18:25:38,088 - Epoch: [29][  160/  211]    Overall Loss 0.077526    Objective Loss 0.077526                                        LR 0.100000    Time 0.023880    
2022-01-25 18:25:38,312 - Epoch: [29][  170/  211]    Overall Loss 0.077917    Objective Loss 0.077917                                        LR 0.100000    Time 0.023791    
2022-01-25 18:25:38,529 - Epoch: [29][  180/  211]    Overall Loss 0.078362    Objective Loss 0.078362                                        LR 0.100000    Time 0.023675    
2022-01-25 18:25:38,754 - Epoch: [29][  190/  211]    Overall Loss 0.077916    Objective Loss 0.077916                                        LR 0.100000    Time 0.023610    
2022-01-25 18:25:38,968 - Epoch: [29][  200/  211]    Overall Loss 0.077742    Objective Loss 0.077742                                        LR 0.100000    Time 0.023495    
2022-01-25 18:25:39,195 - Epoch: [29][  210/  211]    Overall Loss 0.077732    Objective Loss 0.077732    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.023459    
2022-01-25 18:25:39,216 - Epoch: [29][  211/  211]    Overall Loss 0.077910    Objective Loss 0.077910    Top1 97.580645    Top5 100.000000    LR 0.100000    Time 0.023443    
2022-01-25 18:25:39,288 - --- validate (epoch=29)-----------
2022-01-25 18:25:39,289 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:39,938 - Epoch: [29][   10/   24]    Loss 0.090832    Top1 97.617188    Top5 99.960938    
2022-01-25 18:25:40,184 - Epoch: [29][   20/   24]    Loss 0.088873    Top1 97.792969    Top5 99.960938    
2022-01-25 18:25:40,275 - Epoch: [29][   24/   24]    Loss 0.089072    Top1 97.800000    Top5 99.966667    
2022-01-25 18:25:40,330 - ==> Top1: 97.800    Top5: 99.967    Loss: 0.089

2022-01-25 18:25:40,331 - ==> Confusion:
[[593   0   1   0   0   1   3   0   5   2]
 [  0 678   3   0   2   1   1   1   2   0]
 [  0   1 569   2   1   0   1   1   9   2]
 [  0   0   1 576   0   1   0   1   4   0]
 [  0   0   0   0 548   1   1   0   3  12]
 [  1   0   0   3   0 501   2   0   6   5]
 [  1   1   0   0   1   2 620   0   6   0]
 [  1   3   8   3   8   0   0 596   0   6]
 [  0   0   0   0   1   0   1   0 581   1]
 [  0   1   0   0   3   0   0   1   4 606]]

2022-01-25 18:25:40,334 - ==> Best [Top1: 98.283   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 27]
2022-01-25 18:25:40,334 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:40,344 - 

2022-01-25 18:25:40,344 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:40,898 - Epoch: [30][   10/  211]    Overall Loss 0.078247    Objective Loss 0.078247                                        LR 0.100000    Time 0.055319    
2022-01-25 18:25:41,105 - Epoch: [30][   20/  211]    Overall Loss 0.081490    Objective Loss 0.081490                                        LR 0.100000    Time 0.037998    
2022-01-25 18:25:41,330 - Epoch: [30][   30/  211]    Overall Loss 0.079867    Objective Loss 0.079867                                        LR 0.100000    Time 0.032831    
2022-01-25 18:25:41,543 - Epoch: [30][   40/  211]    Overall Loss 0.078499    Objective Loss 0.078499                                        LR 0.100000    Time 0.029941    
2022-01-25 18:25:41,778 - Epoch: [30][   50/  211]    Overall Loss 0.075035    Objective Loss 0.075035                                        LR 0.100000    Time 0.028633    
2022-01-25 18:25:41,986 - Epoch: [30][   60/  211]    Overall Loss 0.074036    Objective Loss 0.074036                                        LR 0.100000    Time 0.027329    
2022-01-25 18:25:42,217 - Epoch: [30][   70/  211]    Overall Loss 0.074260    Objective Loss 0.074260                                        LR 0.100000    Time 0.026720    
2022-01-25 18:25:42,431 - Epoch: [30][   80/  211]    Overall Loss 0.073076    Objective Loss 0.073076                                        LR 0.100000    Time 0.026046    
2022-01-25 18:25:42,658 - Epoch: [30][   90/  211]    Overall Loss 0.072691    Objective Loss 0.072691                                        LR 0.100000    Time 0.025674    
2022-01-25 18:25:42,871 - Epoch: [30][  100/  211]    Overall Loss 0.073210    Objective Loss 0.073210                                        LR 0.100000    Time 0.025234    
2022-01-25 18:25:43,103 - Epoch: [30][  110/  211]    Overall Loss 0.073028    Objective Loss 0.073028                                        LR 0.100000    Time 0.025046    
2022-01-25 18:25:43,320 - Epoch: [30][  120/  211]    Overall Loss 0.072512    Objective Loss 0.072512                                        LR 0.100000    Time 0.024762    
2022-01-25 18:25:43,582 - Epoch: [30][  130/  211]    Overall Loss 0.072224    Objective Loss 0.072224                                        LR 0.100000    Time 0.024872    
2022-01-25 18:25:43,828 - Epoch: [30][  140/  211]    Overall Loss 0.072018    Objective Loss 0.072018                                        LR 0.100000    Time 0.024847    
2022-01-25 18:25:44,115 - Epoch: [30][  150/  211]    Overall Loss 0.071810    Objective Loss 0.071810                                        LR 0.100000    Time 0.025105    
2022-01-25 18:25:44,362 - Epoch: [30][  160/  211]    Overall Loss 0.072053    Objective Loss 0.072053                                        LR 0.100000    Time 0.025075    
2022-01-25 18:25:44,641 - Epoch: [30][  170/  211]    Overall Loss 0.073037    Objective Loss 0.073037                                        LR 0.100000    Time 0.025239    
2022-01-25 18:25:44,890 - Epoch: [30][  180/  211]    Overall Loss 0.073036    Objective Loss 0.073036                                        LR 0.100000    Time 0.025222    
2022-01-25 18:25:45,177 - Epoch: [30][  190/  211]    Overall Loss 0.072857    Objective Loss 0.072857                                        LR 0.100000    Time 0.025401    
2022-01-25 18:25:45,441 - Epoch: [30][  200/  211]    Overall Loss 0.072714    Objective Loss 0.072714                                        LR 0.100000    Time 0.025448    
2022-01-25 18:25:45,706 - Epoch: [30][  210/  211]    Overall Loss 0.073377    Objective Loss 0.073377    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.025500    
2022-01-25 18:25:45,725 - Epoch: [30][  211/  211]    Overall Loss 0.073295    Objective Loss 0.073295    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.025467    
2022-01-25 18:25:45,828 - --- validate (epoch=30)-----------
2022-01-25 18:25:45,829 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:46,314 - Epoch: [30][   10/   24]    Loss 0.067304    Top1 98.593750    Top5 100.000000    
2022-01-25 18:25:46,515 - Epoch: [30][   20/   24]    Loss 0.071763    Top1 98.320312    Top5 99.980469    
2022-01-25 18:25:46,603 - Epoch: [30][   24/   24]    Loss 0.070010    Top1 98.366667    Top5 99.983333    
2022-01-25 18:25:46,659 - ==> Top1: 98.367    Top5: 99.983    Loss: 0.070

2022-01-25 18:25:46,659 - ==> Confusion:
[[603   0   0   0   0   0   0   0   2   0]
 [  0 685   1   0   0   0   0   2   0   0]
 [  1   1 570   2   2   0   0   5   4   1]
 [  0   0   0 576   0   2   0   0   5   0]
 [  1   1   0   0 560   0   0   0   0   3]
 [  1   1   0   3   2 499   5   0   6   1]
 [  2   3   0   0   1   1 618   0   6   0]
 [  0   2   1   2   2   0   0 616   1   1]
 [  1   0   0   1   4   0   1   0 577   0]
 [  1   2   0   1   6   1   0   2   2 600]]

2022-01-25 18:25:46,661 - ==> Best [Top1: 98.367   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 30]
2022-01-25 18:25:46,661 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:46,667 - 

2022-01-25 18:25:46,668 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:47,407 - Epoch: [31][   10/  211]    Overall Loss 0.073593    Objective Loss 0.073593                                        LR 0.100000    Time 0.073908    
2022-01-25 18:25:47,651 - Epoch: [31][   20/  211]    Overall Loss 0.066828    Objective Loss 0.066828                                        LR 0.100000    Time 0.049134    
2022-01-25 18:25:47,933 - Epoch: [31][   30/  211]    Overall Loss 0.069018    Objective Loss 0.069018                                        LR 0.100000    Time 0.042130    
2022-01-25 18:25:48,174 - Epoch: [31][   40/  211]    Overall Loss 0.071067    Objective Loss 0.071067                                        LR 0.100000    Time 0.037612    
2022-01-25 18:25:48,463 - Epoch: [31][   50/  211]    Overall Loss 0.072260    Objective Loss 0.072260                                        LR 0.100000    Time 0.035851    
2022-01-25 18:25:48,712 - Epoch: [31][   60/  211]    Overall Loss 0.073197    Objective Loss 0.073197                                        LR 0.100000    Time 0.034027    
2022-01-25 18:25:48,992 - Epoch: [31][   70/  211]    Overall Loss 0.073870    Objective Loss 0.073870                                        LR 0.100000    Time 0.033159    
2022-01-25 18:25:49,240 - Epoch: [31][   80/  211]    Overall Loss 0.073110    Objective Loss 0.073110                                        LR 0.100000    Time 0.032118    
2022-01-25 18:25:49,528 - Epoch: [31][   90/  211]    Overall Loss 0.072877    Objective Loss 0.072877                                        LR 0.100000    Time 0.031742    
2022-01-25 18:25:49,776 - Epoch: [31][  100/  211]    Overall Loss 0.072858    Objective Loss 0.072858                                        LR 0.100000    Time 0.031045    
2022-01-25 18:25:50,055 - Epoch: [31][  110/  211]    Overall Loss 0.072948    Objective Loss 0.072948                                        LR 0.100000    Time 0.030750    
2022-01-25 18:25:50,300 - Epoch: [31][  120/  211]    Overall Loss 0.072701    Objective Loss 0.072701                                        LR 0.100000    Time 0.030232    
2022-01-25 18:25:50,590 - Epoch: [31][  130/  211]    Overall Loss 0.072524    Objective Loss 0.072524                                        LR 0.100000    Time 0.030130    
2022-01-25 18:25:50,835 - Epoch: [31][  140/  211]    Overall Loss 0.072266    Objective Loss 0.072266                                        LR 0.100000    Time 0.029727    
2022-01-25 18:25:51,117 - Epoch: [31][  150/  211]    Overall Loss 0.072397    Objective Loss 0.072397                                        LR 0.100000    Time 0.029626    
2022-01-25 18:25:51,364 - Epoch: [31][  160/  211]    Overall Loss 0.072532    Objective Loss 0.072532                                        LR 0.100000    Time 0.029313    
2022-01-25 18:25:51,646 - Epoch: [31][  170/  211]    Overall Loss 0.072893    Objective Loss 0.072893                                        LR 0.100000    Time 0.029246    
2022-01-25 18:25:51,894 - Epoch: [31][  180/  211]    Overall Loss 0.072955    Objective Loss 0.072955                                        LR 0.100000    Time 0.028997    
2022-01-25 18:25:52,181 - Epoch: [31][  190/  211]    Overall Loss 0.072919    Objective Loss 0.072919                                        LR 0.100000    Time 0.028982    
2022-01-25 18:25:52,429 - Epoch: [31][  200/  211]    Overall Loss 0.073053    Objective Loss 0.073053                                        LR 0.100000    Time 0.028768    
2022-01-25 18:25:52,706 - Epoch: [31][  210/  211]    Overall Loss 0.072939    Objective Loss 0.072939    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.028719    
2022-01-25 18:25:52,726 - Epoch: [31][  211/  211]    Overall Loss 0.072964    Objective Loss 0.072964    Top1 97.177419    Top5 100.000000    LR 0.100000    Time 0.028673    
2022-01-25 18:25:52,789 - --- validate (epoch=31)-----------
2022-01-25 18:25:52,789 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:53,282 - Epoch: [31][   10/   24]    Loss 0.075041    Top1 98.320312    Top5 99.960938    
2022-01-25 18:25:53,475 - Epoch: [31][   20/   24]    Loss 0.076308    Top1 98.242188    Top5 99.960938    
2022-01-25 18:25:53,558 - Epoch: [31][   24/   24]    Loss 0.080368    Top1 98.066667    Top5 99.950000    
2022-01-25 18:25:53,613 - ==> Top1: 98.067    Top5: 99.950    Loss: 0.080

2022-01-25 18:25:53,614 - ==> Confusion:
[[593   0   0   1   0   1   2   0   3   5]
 [  0 679   2   2   0   1   0   3   0   1]
 [  0   1 580   1   0   0   0   1   3   0]
 [  0   0   1 577   0   0   0   1   2   2]
 [  0   0   1   1 545   0   0   1   2  15]
 [  0   0   0   4   0 509   1   0   2   2]
 [  1   2   0   0   2   5 614   0   7   0]
 [  0   1   6   3   0   0   0 611   1   3]
 [  0   0   0   3   0   2   0   1 578   0]
 [  0   1   1   4   2   2   0   0   7 598]]

2022-01-25 18:25:53,615 - ==> Best [Top1: 98.367   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 30]
2022-01-25 18:25:53,615 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:53,621 - 

2022-01-25 18:25:53,621 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:25:54,180 - Epoch: [32][   10/  211]    Overall Loss 0.073465    Objective Loss 0.073465                                        LR 0.100000    Time 0.055832    
2022-01-25 18:25:54,386 - Epoch: [32][   20/  211]    Overall Loss 0.072277    Objective Loss 0.072277                                        LR 0.100000    Time 0.038202    
2022-01-25 18:25:54,612 - Epoch: [32][   30/  211]    Overall Loss 0.070874    Objective Loss 0.070874                                        LR 0.100000    Time 0.033006    
2022-01-25 18:25:54,831 - Epoch: [32][   40/  211]    Overall Loss 0.070175    Objective Loss 0.070175                                        LR 0.100000    Time 0.030210    
2022-01-25 18:25:55,054 - Epoch: [32][   50/  211]    Overall Loss 0.069289    Objective Loss 0.069289                                        LR 0.100000    Time 0.028620    
2022-01-25 18:25:55,269 - Epoch: [32][   60/  211]    Overall Loss 0.069296    Objective Loss 0.069296                                        LR 0.100000    Time 0.027421    
2022-01-25 18:25:55,491 - Epoch: [32][   70/  211]    Overall Loss 0.070341    Objective Loss 0.070341                                        LR 0.100000    Time 0.026672    
2022-01-25 18:25:55,704 - Epoch: [32][   80/  211]    Overall Loss 0.070235    Objective Loss 0.070235                                        LR 0.100000    Time 0.026005    
2022-01-25 18:25:55,940 - Epoch: [32][   90/  211]    Overall Loss 0.069928    Objective Loss 0.069928                                        LR 0.100000    Time 0.025734    
2022-01-25 18:25:56,151 - Epoch: [32][  100/  211]    Overall Loss 0.071982    Objective Loss 0.071982                                        LR 0.100000    Time 0.025267    
2022-01-25 18:25:56,377 - Epoch: [32][  110/  211]    Overall Loss 0.072259    Objective Loss 0.072259                                        LR 0.100000    Time 0.025021    
2022-01-25 18:25:56,588 - Epoch: [32][  120/  211]    Overall Loss 0.072455    Objective Loss 0.072455                                        LR 0.100000    Time 0.024686    
2022-01-25 18:25:56,816 - Epoch: [32][  130/  211]    Overall Loss 0.072331    Objective Loss 0.072331                                        LR 0.100000    Time 0.024544    
2022-01-25 18:25:57,034 - Epoch: [32][  140/  211]    Overall Loss 0.072848    Objective Loss 0.072848                                        LR 0.100000    Time 0.024344    
2022-01-25 18:25:57,258 - Epoch: [32][  150/  211]    Overall Loss 0.073274    Objective Loss 0.073274                                        LR 0.100000    Time 0.024211    
2022-01-25 18:25:57,470 - Epoch: [32][  160/  211]    Overall Loss 0.073589    Objective Loss 0.073589                                        LR 0.100000    Time 0.024021    
2022-01-25 18:25:57,694 - Epoch: [32][  170/  211]    Overall Loss 0.074109    Objective Loss 0.074109                                        LR 0.100000    Time 0.023922    
2022-01-25 18:25:57,904 - Epoch: [32][  180/  211]    Overall Loss 0.074542    Objective Loss 0.074542                                        LR 0.100000    Time 0.023759    
2022-01-25 18:25:58,132 - Epoch: [32][  190/  211]    Overall Loss 0.074502    Objective Loss 0.074502                                        LR 0.100000    Time 0.023708    
2022-01-25 18:25:58,350 - Epoch: [32][  200/  211]    Overall Loss 0.074470    Objective Loss 0.074470                                        LR 0.100000    Time 0.023610    
2022-01-25 18:25:58,574 - Epoch: [32][  210/  211]    Overall Loss 0.074609    Objective Loss 0.074609    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.023548    
2022-01-25 18:25:58,592 - Epoch: [32][  211/  211]    Overall Loss 0.074492    Objective Loss 0.074492    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.023523    
2022-01-25 18:25:58,666 - --- validate (epoch=32)-----------
2022-01-25 18:25:58,667 - 6000 samples (256 per mini-batch)
2022-01-25 18:25:59,225 - Epoch: [32][   10/   24]    Loss 0.061092    Top1 98.515625    Top5 100.000000    
2022-01-25 18:25:59,471 - Epoch: [32][   20/   24]    Loss 0.062740    Top1 98.417969    Top5 100.000000    
2022-01-25 18:25:59,527 - Epoch: [32][   24/   24]    Loss 0.064355    Top1 98.416667    Top5 99.983333    
2022-01-25 18:25:59,584 - ==> Top1: 98.417    Top5: 99.983    Loss: 0.064

2022-01-25 18:25:59,585 - ==> Confusion:
[[602   0   0   0   0   0   3   0   0   0]
 [  0 680   3   0   1   1   0   3   0   0]
 [  0   1 572   3   0   0   0   3   4   3]
 [  0   0   0 579   0   1   1   2   0   0]
 [  0   1   1   0 550   0   0   0   1  12]
 [  1   0   0   3   0 509   3   0   1   1]
 [  4   0   0   0   2   2 622   0   1   0]
 [  0   4   2   1   1   1   0 616   0   0]
 [  2   0   0   1   1   0   5   0 573   2]
 [  0   3   0   1   1   1   0   3   4 602]]

2022-01-25 18:25:59,586 - ==> Best [Top1: 98.417   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 32]
2022-01-25 18:25:59,587 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:25:59,593 - 

2022-01-25 18:25:59,594 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:00,142 - Epoch: [33][   10/  211]    Overall Loss 0.058314    Objective Loss 0.058314                                        LR 0.100000    Time 0.054780    
2022-01-25 18:26:00,357 - Epoch: [33][   20/  211]    Overall Loss 0.070116    Objective Loss 0.070116                                        LR 0.100000    Time 0.038109    
2022-01-25 18:26:00,574 - Epoch: [33][   30/  211]    Overall Loss 0.068428    Objective Loss 0.068428                                        LR 0.100000    Time 0.032612    
2022-01-25 18:26:00,778 - Epoch: [33][   40/  211]    Overall Loss 0.068277    Objective Loss 0.068277                                        LR 0.100000    Time 0.029558    
2022-01-25 18:26:01,006 - Epoch: [33][   50/  211]    Overall Loss 0.068714    Objective Loss 0.068714                                        LR 0.100000    Time 0.028195    
2022-01-25 18:26:01,215 - Epoch: [33][   60/  211]    Overall Loss 0.067318    Objective Loss 0.067318                                        LR 0.100000    Time 0.026977    
2022-01-25 18:26:01,446 - Epoch: [33][   70/  211]    Overall Loss 0.067113    Objective Loss 0.067113                                        LR 0.100000    Time 0.026425    
2022-01-25 18:26:01,656 - Epoch: [33][   80/  211]    Overall Loss 0.067698    Objective Loss 0.067698                                        LR 0.100000    Time 0.025741    
2022-01-25 18:26:01,882 - Epoch: [33][   90/  211]    Overall Loss 0.068279    Objective Loss 0.068279                                        LR 0.100000    Time 0.025391    
2022-01-25 18:26:02,093 - Epoch: [33][  100/  211]    Overall Loss 0.069039    Objective Loss 0.069039                                        LR 0.100000    Time 0.024949    
2022-01-25 18:26:02,320 - Epoch: [33][  110/  211]    Overall Loss 0.069774    Objective Loss 0.069774                                        LR 0.100000    Time 0.024751    
2022-01-25 18:26:02,534 - Epoch: [33][  120/  211]    Overall Loss 0.070966    Objective Loss 0.070966                                        LR 0.100000    Time 0.024464    
2022-01-25 18:26:02,769 - Epoch: [33][  130/  211]    Overall Loss 0.071256    Objective Loss 0.071256                                        LR 0.100000    Time 0.024386    
2022-01-25 18:26:02,975 - Epoch: [33][  140/  211]    Overall Loss 0.071096    Objective Loss 0.071096                                        LR 0.100000    Time 0.024114    
2022-01-25 18:26:03,201 - Epoch: [33][  150/  211]    Overall Loss 0.070419    Objective Loss 0.070419                                        LR 0.100000    Time 0.024012    
2022-01-25 18:26:03,416 - Epoch: [33][  160/  211]    Overall Loss 0.070380    Objective Loss 0.070380                                        LR 0.100000    Time 0.023853    
2022-01-25 18:26:03,671 - Epoch: [33][  170/  211]    Overall Loss 0.070335    Objective Loss 0.070335                                        LR 0.100000    Time 0.023950    
2022-01-25 18:26:03,968 - Epoch: [33][  180/  211]    Overall Loss 0.070778    Objective Loss 0.070778                                        LR 0.100000    Time 0.024266    
2022-01-25 18:26:04,215 - Epoch: [33][  190/  211]    Overall Loss 0.071134    Objective Loss 0.071134                                        LR 0.100000    Time 0.024284    
2022-01-25 18:26:04,494 - Epoch: [33][  200/  211]    Overall Loss 0.071629    Objective Loss 0.071629                                        LR 0.100000    Time 0.024464    
2022-01-25 18:26:04,739 - Epoch: [33][  210/  211]    Overall Loss 0.071725    Objective Loss 0.071725    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.024467    
2022-01-25 18:26:04,758 - Epoch: [33][  211/  211]    Overall Loss 0.071711    Objective Loss 0.071711    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.024437    
2022-01-25 18:26:04,814 - --- validate (epoch=33)-----------
2022-01-25 18:26:04,814 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:05,296 - Epoch: [33][   10/   24]    Loss 0.079341    Top1 98.046875    Top5 100.000000    
2022-01-25 18:26:05,516 - Epoch: [33][   20/   24]    Loss 0.072143    Top1 98.164062    Top5 100.000000    
2022-01-25 18:26:05,576 - Epoch: [33][   24/   24]    Loss 0.070595    Top1 98.216667    Top5 100.000000    
2022-01-25 18:26:05,651 - ==> Top1: 98.217    Top5: 100.000    Loss: 0.071

2022-01-25 18:26:05,652 - ==> Confusion:
[[601   0   1   0   0   0   1   1   1   0]
 [  0 679   1   1   1   0   0   6   0   0]
 [  2   1 561   5   0   0   1   7   4   5]
 [  1   0   1 576   0   1   0   3   1   0]
 [  0   1   0   0 554   1   0   0   0   9]
 [  1   0   0   0   0 511   6   0   0   0]
 [  0   2   0   0   2   4 622   0   1   0]
 [  0   3   1   2   1   0   0 618   0   0]
 [  2   1   1   1   2   1   4   0 571   1]
 [  0   2   0   0   4   4   0   3   3 599]]

2022-01-25 18:26:05,654 - ==> Best [Top1: 98.417   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 32]
2022-01-25 18:26:05,654 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:05,662 - 

2022-01-25 18:26:05,662 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:06,361 - Epoch: [34][   10/  211]    Overall Loss 0.083221    Objective Loss 0.083221                                        LR 0.100000    Time 0.069840    
2022-01-25 18:26:06,573 - Epoch: [34][   20/  211]    Overall Loss 0.072500    Objective Loss 0.072500                                        LR 0.100000    Time 0.045470    
2022-01-25 18:26:06,808 - Epoch: [34][   30/  211]    Overall Loss 0.075431    Objective Loss 0.075431                                        LR 0.100000    Time 0.038145    
2022-01-25 18:26:07,024 - Epoch: [34][   40/  211]    Overall Loss 0.076963    Objective Loss 0.076963                                        LR 0.100000    Time 0.033999    
2022-01-25 18:26:07,264 - Epoch: [34][   50/  211]    Overall Loss 0.074085    Objective Loss 0.074085                                        LR 0.100000    Time 0.032003    
2022-01-25 18:26:07,482 - Epoch: [34][   60/  211]    Overall Loss 0.072036    Objective Loss 0.072036                                        LR 0.100000    Time 0.030297    
2022-01-25 18:26:07,724 - Epoch: [34][   70/  211]    Overall Loss 0.070407    Objective Loss 0.070407                                        LR 0.100000    Time 0.029420    
2022-01-25 18:26:07,946 - Epoch: [34][   80/  211]    Overall Loss 0.069545    Objective Loss 0.069545                                        LR 0.100000    Time 0.028510    
2022-01-25 18:26:08,177 - Epoch: [34][   90/  211]    Overall Loss 0.069806    Objective Loss 0.069806                                        LR 0.100000    Time 0.027903    
2022-01-25 18:26:08,398 - Epoch: [34][  100/  211]    Overall Loss 0.069733    Objective Loss 0.069733                                        LR 0.100000    Time 0.027319    
2022-01-25 18:26:08,636 - Epoch: [34][  110/  211]    Overall Loss 0.069331    Objective Loss 0.069331                                        LR 0.100000    Time 0.027000    
2022-01-25 18:26:08,882 - Epoch: [34][  120/  211]    Overall Loss 0.069450    Objective Loss 0.069450                                        LR 0.100000    Time 0.026793    
2022-01-25 18:26:09,114 - Epoch: [34][  130/  211]    Overall Loss 0.069618    Objective Loss 0.069618                                        LR 0.100000    Time 0.026518    
2022-01-25 18:26:09,385 - Epoch: [34][  140/  211]    Overall Loss 0.069419    Objective Loss 0.069419                                        LR 0.100000    Time 0.026554    
2022-01-25 18:26:09,633 - Epoch: [34][  150/  211]    Overall Loss 0.069540    Objective Loss 0.069540                                        LR 0.100000    Time 0.026438    
2022-01-25 18:26:09,914 - Epoch: [34][  160/  211]    Overall Loss 0.069576    Objective Loss 0.069576                                        LR 0.100000    Time 0.026539    
2022-01-25 18:26:10,167 - Epoch: [34][  170/  211]    Overall Loss 0.069503    Objective Loss 0.069503                                        LR 0.100000    Time 0.026464    
2022-01-25 18:26:10,447 - Epoch: [34][  180/  211]    Overall Loss 0.070038    Objective Loss 0.070038                                        LR 0.100000    Time 0.026543    
2022-01-25 18:26:10,692 - Epoch: [34][  190/  211]    Overall Loss 0.070030    Objective Loss 0.070030                                        LR 0.100000    Time 0.026435    
2022-01-25 18:26:10,978 - Epoch: [34][  200/  211]    Overall Loss 0.070322    Objective Loss 0.070322                                        LR 0.100000    Time 0.026543    
2022-01-25 18:26:11,227 - Epoch: [34][  210/  211]    Overall Loss 0.070811    Objective Loss 0.070811    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.026465    
2022-01-25 18:26:11,271 - Epoch: [34][  211/  211]    Overall Loss 0.070689    Objective Loss 0.070689    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.026546    
2022-01-25 18:26:11,327 - --- validate (epoch=34)-----------
2022-01-25 18:26:11,328 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:11,844 - Epoch: [34][   10/   24]    Loss 0.078557    Top1 97.968750    Top5 100.000000    
2022-01-25 18:26:12,081 - Epoch: [34][   20/   24]    Loss 0.078236    Top1 98.105469    Top5 99.960938    
2022-01-25 18:26:12,182 - Epoch: [34][   24/   24]    Loss 0.077795    Top1 98.033333    Top5 99.966667    
2022-01-25 18:26:12,238 - ==> Top1: 98.033    Top5: 99.967    Loss: 0.078

2022-01-25 18:26:12,239 - ==> Confusion:
[[594   0   1   1   0   0   3   0   6   0]
 [  0 677   5   1   0   1   1   3   0   0]
 [  0   0 573   3   0   0   1   2   5   2]
 [  0   0   2 571   0   2   0   2   6   0]
 [  0   0   1   0 554   1   0   0   0   9]
 [  1   0   0   3   0 501   6   0   7   0]
 [  2   0   0   0   2   0 622   0   5   0]
 [  0   1   4   1   1   0   0 616   1   1]
 [  0   0   0   1   0   1   3   0 578   1]
 [  3   0   0   1   1   1   0   4   9 596]]

2022-01-25 18:26:12,241 - ==> Best [Top1: 98.417   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 32]
2022-01-25 18:26:12,241 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:12,249 - 

2022-01-25 18:26:12,249 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:12,833 - Epoch: [35][   10/  211]    Overall Loss 0.076223    Objective Loss 0.076223                                        LR 0.100000    Time 0.058336    
2022-01-25 18:26:13,081 - Epoch: [35][   20/  211]    Overall Loss 0.066169    Objective Loss 0.066169                                        LR 0.100000    Time 0.041554    
2022-01-25 18:26:13,327 - Epoch: [35][   30/  211]    Overall Loss 0.070854    Objective Loss 0.070854                                        LR 0.100000    Time 0.035888    
2022-01-25 18:26:13,540 - Epoch: [35][   40/  211]    Overall Loss 0.070594    Objective Loss 0.070594                                        LR 0.100000    Time 0.032223    
2022-01-25 18:26:13,763 - Epoch: [35][   50/  211]    Overall Loss 0.070717    Objective Loss 0.070717                                        LR 0.100000    Time 0.030234    
2022-01-25 18:26:13,990 - Epoch: [35][   60/  211]    Overall Loss 0.070147    Objective Loss 0.070147                                        LR 0.100000    Time 0.028985    
2022-01-25 18:26:14,209 - Epoch: [35][   70/  211]    Overall Loss 0.069396    Objective Loss 0.069396                                        LR 0.100000    Time 0.027950    
2022-01-25 18:26:14,418 - Epoch: [35][   80/  211]    Overall Loss 0.068690    Objective Loss 0.068690                                        LR 0.100000    Time 0.027064    
2022-01-25 18:26:14,644 - Epoch: [35][   90/  211]    Overall Loss 0.068935    Objective Loss 0.068935                                        LR 0.100000    Time 0.026566    
2022-01-25 18:26:14,861 - Epoch: [35][  100/  211]    Overall Loss 0.069606    Objective Loss 0.069606                                        LR 0.100000    Time 0.026081    
2022-01-25 18:26:15,082 - Epoch: [35][  110/  211]    Overall Loss 0.069084    Objective Loss 0.069084                                        LR 0.100000    Time 0.025710    
2022-01-25 18:26:15,295 - Epoch: [35][  120/  211]    Overall Loss 0.070027    Objective Loss 0.070027                                        LR 0.100000    Time 0.025343    
2022-01-25 18:26:15,526 - Epoch: [35][  130/  211]    Overall Loss 0.070804    Objective Loss 0.070804                                        LR 0.100000    Time 0.025171    
2022-01-25 18:26:15,736 - Epoch: [35][  140/  211]    Overall Loss 0.070521    Objective Loss 0.070521                                        LR 0.100000    Time 0.024866    
2022-01-25 18:26:15,958 - Epoch: [35][  150/  211]    Overall Loss 0.070029    Objective Loss 0.070029                                        LR 0.100000    Time 0.024687    
2022-01-25 18:26:16,168 - Epoch: [35][  160/  211]    Overall Loss 0.070279    Objective Loss 0.070279                                        LR 0.100000    Time 0.024456    
2022-01-25 18:26:16,394 - Epoch: [35][  170/  211]    Overall Loss 0.070893    Objective Loss 0.070893                                        LR 0.100000    Time 0.024344    
2022-01-25 18:26:16,605 - Epoch: [35][  180/  211]    Overall Loss 0.071424    Objective Loss 0.071424                                        LR 0.100000    Time 0.024163    
2022-01-25 18:26:16,827 - Epoch: [35][  190/  211]    Overall Loss 0.070922    Objective Loss 0.070922                                        LR 0.100000    Time 0.024057    
2022-01-25 18:26:17,046 - Epoch: [35][  200/  211]    Overall Loss 0.070802    Objective Loss 0.070802                                        LR 0.100000    Time 0.023944    
2022-01-25 18:26:17,267 - Epoch: [35][  210/  211]    Overall Loss 0.070698    Objective Loss 0.070698    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.023856    
2022-01-25 18:26:17,285 - Epoch: [35][  211/  211]    Overall Loss 0.070891    Objective Loss 0.070891    Top1 97.379032    Top5 100.000000    LR 0.100000    Time 0.023829    
2022-01-25 18:26:17,359 - --- validate (epoch=35)-----------
2022-01-25 18:26:17,360 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:17,833 - Epoch: [35][   10/   24]    Loss 0.073342    Top1 98.242188    Top5 99.960938    
2022-01-25 18:26:18,029 - Epoch: [35][   20/   24]    Loss 0.071754    Top1 98.300781    Top5 99.980469    
2022-01-25 18:26:18,113 - Epoch: [35][   24/   24]    Loss 0.069558    Top1 98.333333    Top5 99.983333    
2022-01-25 18:26:18,183 - ==> Top1: 98.333    Top5: 99.983    Loss: 0.070

2022-01-25 18:26:18,184 - ==> Confusion:
[[599   0   0   0   0   0   1   3   1   1]
 [  0 682   0   0   0   0   1   5   0   0]
 [  0   2 573   0   0   0   0  10   0   1]
 [  0   0   2 579   0   1   0   0   1   0]
 [  0   2   1   0 552   0   0   4   0   6]
 [  0   0   0   1   0 512   2   0   2   1]
 [  1   2   0   0   3   8 614   0   3   0]
 [  0   0   2   1   0   0   0 622   0   0]
 [  2   0   0   1   4   3   1   1 570   2]
 [  0   2   0   2   5   1   0   6   2 597]]

2022-01-25 18:26:18,186 - ==> Best [Top1: 98.417   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 32]
2022-01-25 18:26:18,186 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:18,193 - 

2022-01-25 18:26:18,193 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:18,889 - Epoch: [36][   10/  211]    Overall Loss 0.066143    Objective Loss 0.066143                                        LR 0.100000    Time 0.069471    
2022-01-25 18:26:19,138 - Epoch: [36][   20/  211]    Overall Loss 0.071449    Objective Loss 0.071449                                        LR 0.100000    Time 0.047159    
2022-01-25 18:26:19,385 - Epoch: [36][   30/  211]    Overall Loss 0.076733    Objective Loss 0.076733                                        LR 0.100000    Time 0.039669    
2022-01-25 18:26:19,662 - Epoch: [36][   40/  211]    Overall Loss 0.075755    Objective Loss 0.075755                                        LR 0.100000    Time 0.036680    
2022-01-25 18:26:19,914 - Epoch: [36][   50/  211]    Overall Loss 0.075456    Objective Loss 0.075456                                        LR 0.100000    Time 0.034364    
2022-01-25 18:26:20,193 - Epoch: [36][   60/  211]    Overall Loss 0.074400    Objective Loss 0.074400                                        LR 0.100000    Time 0.033296    
2022-01-25 18:26:20,440 - Epoch: [36][   70/  211]    Overall Loss 0.074124    Objective Loss 0.074124                                        LR 0.100000    Time 0.032057    
2022-01-25 18:26:20,723 - Epoch: [36][   80/  211]    Overall Loss 0.072359    Objective Loss 0.072359                                        LR 0.100000    Time 0.031585    
2022-01-25 18:26:20,979 - Epoch: [36][   90/  211]    Overall Loss 0.072511    Objective Loss 0.072511                                        LR 0.100000    Time 0.030909    
2022-01-25 18:26:21,257 - Epoch: [36][  100/  211]    Overall Loss 0.072519    Objective Loss 0.072519                                        LR 0.100000    Time 0.030596    
2022-01-25 18:26:21,504 - Epoch: [36][  110/  211]    Overall Loss 0.073561    Objective Loss 0.073561                                        LR 0.100000    Time 0.030060    
2022-01-25 18:26:21,783 - Epoch: [36][  120/  211]    Overall Loss 0.073974    Objective Loss 0.073974                                        LR 0.100000    Time 0.029873    
2022-01-25 18:26:22,034 - Epoch: [36][  130/  211]    Overall Loss 0.073750    Objective Loss 0.073750                                        LR 0.100000    Time 0.029507    
2022-01-25 18:26:22,320 - Epoch: [36][  140/  211]    Overall Loss 0.074025    Objective Loss 0.074025                                        LR 0.100000    Time 0.029442    
2022-01-25 18:26:22,567 - Epoch: [36][  150/  211]    Overall Loss 0.073842    Objective Loss 0.073842                                        LR 0.100000    Time 0.029118    
2022-01-25 18:26:22,851 - Epoch: [36][  160/  211]    Overall Loss 0.074291    Objective Loss 0.074291                                        LR 0.100000    Time 0.029072    
2022-01-25 18:26:23,096 - Epoch: [36][  170/  211]    Overall Loss 0.074379    Objective Loss 0.074379                                        LR 0.100000    Time 0.028801    
2022-01-25 18:26:23,377 - Epoch: [36][  180/  211]    Overall Loss 0.075084    Objective Loss 0.075084                                        LR 0.100000    Time 0.028763    
2022-01-25 18:26:23,628 - Epoch: [36][  190/  211]    Overall Loss 0.074794    Objective Loss 0.074794                                        LR 0.100000    Time 0.028566    
2022-01-25 18:26:23,861 - Epoch: [36][  200/  211]    Overall Loss 0.074327    Objective Loss 0.074327                                        LR 0.100000    Time 0.028300    
2022-01-25 18:26:24,082 - Epoch: [36][  210/  211]    Overall Loss 0.074251    Objective Loss 0.074251    Top1 96.875000    Top5 100.000000    LR 0.100000    Time 0.028005    
2022-01-25 18:26:24,101 - Epoch: [36][  211/  211]    Overall Loss 0.074039    Objective Loss 0.074039    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.027963    
2022-01-25 18:26:24,161 - --- validate (epoch=36)-----------
2022-01-25 18:26:24,162 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:24,642 - Epoch: [36][   10/   24]    Loss 0.073535    Top1 97.617188    Top5 100.000000    
2022-01-25 18:26:24,898 - Epoch: [36][   20/   24]    Loss 0.071035    Top1 98.007812    Top5 99.980469    
2022-01-25 18:26:24,943 - Epoch: [36][   24/   24]    Loss 0.070605    Top1 98.083333    Top5 99.983333    
2022-01-25 18:26:25,005 - ==> Top1: 98.083    Top5: 99.983    Loss: 0.071

2022-01-25 18:26:25,006 - ==> Confusion:
[[597   0   0   0   0   0   2   0   2   4]
 [  0 682   0   1   1   0   1   3   0   0]
 [  0   1 566   4   1   1   0   8   3   2]
 [  0   0   0 574   1   1   0   3   2   2]
 [  0   1   0   0 557   0   0   0   1   6]
 [  0   1   0   6   1 504   3   0   3   0]
 [  2   2   0   0   2   3 619   0   3   0]
 [  0   5   0   2   2   0   0 614   0   2]
 [  0   0   0   2   5   1   3   0 572   1]
 [  0   1   0   1   5   2   0   3   3 600]]

2022-01-25 18:26:25,009 - ==> Best [Top1: 98.417   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 32]
2022-01-25 18:26:25,009 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:25,016 - 

2022-01-25 18:26:25,017 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:25,727 - Epoch: [37][   10/  211]    Overall Loss 0.064455    Objective Loss 0.064455                                        LR 0.100000    Time 0.071002    
2022-01-25 18:26:25,978 - Epoch: [37][   20/  211]    Overall Loss 0.060581    Objective Loss 0.060581                                        LR 0.100000    Time 0.047996    
2022-01-25 18:26:26,224 - Epoch: [37][   30/  211]    Overall Loss 0.063420    Objective Loss 0.063420                                        LR 0.100000    Time 0.040211    
2022-01-25 18:26:26,502 - Epoch: [37][   40/  211]    Overall Loss 0.066255    Objective Loss 0.066255                                        LR 0.100000    Time 0.037103    
2022-01-25 18:26:26,750 - Epoch: [37][   50/  211]    Overall Loss 0.066520    Objective Loss 0.066520                                        LR 0.100000    Time 0.034618    
2022-01-25 18:26:27,030 - Epoch: [37][   60/  211]    Overall Loss 0.068795    Objective Loss 0.068795                                        LR 0.100000    Time 0.033523    
2022-01-25 18:26:27,278 - Epoch: [37][   70/  211]    Overall Loss 0.068553    Objective Loss 0.068553                                        LR 0.100000    Time 0.032267    
2022-01-25 18:26:27,561 - Epoch: [37][   80/  211]    Overall Loss 0.068846    Objective Loss 0.068846                                        LR 0.100000    Time 0.031762    
2022-01-25 18:26:27,812 - Epoch: [37][   90/  211]    Overall Loss 0.069939    Objective Loss 0.069939                                        LR 0.100000    Time 0.031022    
2022-01-25 18:26:28,094 - Epoch: [37][  100/  211]    Overall Loss 0.071145    Objective Loss 0.071145                                        LR 0.100000    Time 0.030739    
2022-01-25 18:26:28,342 - Epoch: [37][  110/  211]    Overall Loss 0.072071    Objective Loss 0.072071                                        LR 0.100000    Time 0.030190    
2022-01-25 18:26:28,619 - Epoch: [37][  120/  211]    Overall Loss 0.073597    Objective Loss 0.073597                                        LR 0.100000    Time 0.029986    
2022-01-25 18:26:28,875 - Epoch: [37][  130/  211]    Overall Loss 0.074387    Objective Loss 0.074387                                        LR 0.100000    Time 0.029641    
2022-01-25 18:26:29,155 - Epoch: [37][  140/  211]    Overall Loss 0.074483    Objective Loss 0.074483                                        LR 0.100000    Time 0.029523    
2022-01-25 18:26:29,399 - Epoch: [37][  150/  211]    Overall Loss 0.074427    Objective Loss 0.074427                                        LR 0.100000    Time 0.029181    
2022-01-25 18:26:29,679 - Epoch: [37][  160/  211]    Overall Loss 0.074983    Objective Loss 0.074983                                        LR 0.100000    Time 0.029106    
2022-01-25 18:26:29,926 - Epoch: [37][  170/  211]    Overall Loss 0.074545    Objective Loss 0.074545                                        LR 0.100000    Time 0.028844    
2022-01-25 18:26:30,206 - Epoch: [37][  180/  211]    Overall Loss 0.073952    Objective Loss 0.073952                                        LR 0.100000    Time 0.028795    
2022-01-25 18:26:30,454 - Epoch: [37][  190/  211]    Overall Loss 0.073271    Objective Loss 0.073271                                        LR 0.100000    Time 0.028581    
2022-01-25 18:26:30,741 - Epoch: [37][  200/  211]    Overall Loss 0.073493    Objective Loss 0.073493                                        LR 0.100000    Time 0.028585    
2022-01-25 18:26:30,984 - Epoch: [37][  210/  211]    Overall Loss 0.073036    Objective Loss 0.073036    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.028382    
2022-01-25 18:26:31,003 - Epoch: [37][  211/  211]    Overall Loss 0.072991    Objective Loss 0.072991    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.028333    
2022-01-25 18:26:31,059 - --- validate (epoch=37)-----------
2022-01-25 18:26:31,060 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:31,581 - Epoch: [37][   10/   24]    Loss 0.066915    Top1 98.242188    Top5 100.000000    
2022-01-25 18:26:31,820 - Epoch: [37][   20/   24]    Loss 0.065448    Top1 98.300781    Top5 100.000000    
2022-01-25 18:26:31,922 - Epoch: [37][   24/   24]    Loss 0.061964    Top1 98.433333    Top5 100.000000    
2022-01-25 18:26:31,983 - ==> Top1: 98.433    Top5: 100.000    Loss: 0.062

2022-01-25 18:26:31,984 - ==> Confusion:
[[598   0   1   0   0   0   5   0   0   1]
 [  0 683   2   0   0   1   0   2   0   0]
 [  0   0 584   0   0   1   0   1   0   0]
 [  0   0   5 568   0   4   0   4   2   0]
 [  1   1   3   0 556   0   0   0   0   4]
 [  0   1   0   1   0 511   3   0   1   1]
 [  1   0   0   0   1   2 627   0   0   0]
 [  1   2   3   0   0   0   0 619   0   0]
 [  0   0   2   2   0   2   7   0 570   1]
 [  2   2   0   0   8   2   1   6   4 590]]

2022-01-25 18:26:31,986 - ==> Best [Top1: 98.433   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 37]
2022-01-25 18:26:31,986 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:31,992 - 

2022-01-25 18:26:31,992 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:32,546 - Epoch: [38][   10/  211]    Overall Loss 0.067255    Objective Loss 0.067255                                        LR 0.100000    Time 0.055311    
2022-01-25 18:26:32,807 - Epoch: [38][   20/  211]    Overall Loss 0.067597    Objective Loss 0.067597                                        LR 0.100000    Time 0.040700    
2022-01-25 18:26:33,056 - Epoch: [38][   30/  211]    Overall Loss 0.070522    Objective Loss 0.070522                                        LR 0.100000    Time 0.035395    
2022-01-25 18:26:33,328 - Epoch: [38][   40/  211]    Overall Loss 0.070338    Objective Loss 0.070338                                        LR 0.100000    Time 0.033358    
2022-01-25 18:26:33,578 - Epoch: [38][   50/  211]    Overall Loss 0.069999    Objective Loss 0.069999                                        LR 0.100000    Time 0.031681    
2022-01-25 18:26:33,858 - Epoch: [38][   60/  211]    Overall Loss 0.069765    Objective Loss 0.069765                                        LR 0.100000    Time 0.031048    
2022-01-25 18:26:34,112 - Epoch: [38][   70/  211]    Overall Loss 0.069405    Objective Loss 0.069405                                        LR 0.100000    Time 0.030244    
2022-01-25 18:26:34,391 - Epoch: [38][   80/  211]    Overall Loss 0.067483    Objective Loss 0.067483                                        LR 0.100000    Time 0.029946    
2022-01-25 18:26:34,636 - Epoch: [38][   90/  211]    Overall Loss 0.066969    Objective Loss 0.066969                                        LR 0.100000    Time 0.029337    
2022-01-25 18:26:34,920 - Epoch: [38][  100/  211]    Overall Loss 0.067504    Objective Loss 0.067504                                        LR 0.100000    Time 0.029241    
2022-01-25 18:26:35,172 - Epoch: [38][  110/  211]    Overall Loss 0.067715    Objective Loss 0.067715                                        LR 0.100000    Time 0.028868    
2022-01-25 18:26:35,450 - Epoch: [38][  120/  211]    Overall Loss 0.067342    Objective Loss 0.067342                                        LR 0.100000    Time 0.028775    
2022-01-25 18:26:35,697 - Epoch: [38][  130/  211]    Overall Loss 0.067560    Objective Loss 0.067560                                        LR 0.100000    Time 0.028461    
2022-01-25 18:26:35,975 - Epoch: [38][  140/  211]    Overall Loss 0.067110    Objective Loss 0.067110                                        LR 0.100000    Time 0.028413    
2022-01-25 18:26:36,222 - Epoch: [38][  150/  211]    Overall Loss 0.067003    Objective Loss 0.067003                                        LR 0.100000    Time 0.028160    
2022-01-25 18:26:36,509 - Epoch: [38][  160/  211]    Overall Loss 0.067013    Objective Loss 0.067013                                        LR 0.100000    Time 0.028193    
2022-01-25 18:26:36,757 - Epoch: [38][  170/  211]    Overall Loss 0.066427    Objective Loss 0.066427                                        LR 0.100000    Time 0.027987    
2022-01-25 18:26:37,033 - Epoch: [38][  180/  211]    Overall Loss 0.066474    Objective Loss 0.066474                                        LR 0.100000    Time 0.027965    
2022-01-25 18:26:37,280 - Epoch: [38][  190/  211]    Overall Loss 0.066289    Objective Loss 0.066289                                        LR 0.100000    Time 0.027795    
2022-01-25 18:26:37,558 - Epoch: [38][  200/  211]    Overall Loss 0.066141    Objective Loss 0.066141                                        LR 0.100000    Time 0.027789    
2022-01-25 18:26:37,805 - Epoch: [38][  210/  211]    Overall Loss 0.066256    Objective Loss 0.066256    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.027642    
2022-01-25 18:26:37,845 - Epoch: [38][  211/  211]    Overall Loss 0.066224    Objective Loss 0.066224    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.027701    
2022-01-25 18:26:37,901 - --- validate (epoch=38)-----------
2022-01-25 18:26:37,901 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:38,415 - Epoch: [38][   10/   24]    Loss 0.070194    Top1 98.125000    Top5 99.882812    
2022-01-25 18:26:38,651 - Epoch: [38][   20/   24]    Loss 0.071524    Top1 98.183594    Top5 99.941406    
2022-01-25 18:26:38,755 - Epoch: [38][   24/   24]    Loss 0.072231    Top1 98.166667    Top5 99.950000    
2022-01-25 18:26:38,810 - ==> Top1: 98.167    Top5: 99.950    Loss: 0.072

2022-01-25 18:26:38,810 - ==> Confusion:
[[596   0   2   0   0   0   4   0   3   0]
 [  0 683   2   0   1   0   1   1   0   0]
 [  0   0 576   0   0   0   1   4   5   0]
 [  0   0   2 575   0   2   0   1   3   0]
 [  0   1   2   0 547   0   2   1   5   7]
 [  0   0   0   2   1 508   2   0   5   0]
 [  2   1   0   0   2   2 622   0   2   0]
 [  0   2   3   1   0   0   0 618   0   1]
 [  0   0   0   1   1   0   1   0 580   1]
 [  0   0   0   3   8   3   1   5  11 584]]

2022-01-25 18:26:38,812 - ==> Best [Top1: 98.433   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 37]
2022-01-25 18:26:38,812 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:38,817 - 

2022-01-25 18:26:38,818 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:39,512 - Epoch: [39][   10/  211]    Overall Loss 0.063471    Objective Loss 0.063471                                        LR 0.100000    Time 0.069407    
2022-01-25 18:26:39,759 - Epoch: [39][   20/  211]    Overall Loss 0.070004    Objective Loss 0.070004                                        LR 0.100000    Time 0.047021    
2022-01-25 18:26:39,994 - Epoch: [39][   30/  211]    Overall Loss 0.071141    Objective Loss 0.071141                                        LR 0.100000    Time 0.039168    
2022-01-25 18:26:40,220 - Epoch: [39][   40/  211]    Overall Loss 0.073015    Objective Loss 0.073015                                        LR 0.100000    Time 0.035013    
2022-01-25 18:26:40,432 - Epoch: [39][   50/  211]    Overall Loss 0.073377    Objective Loss 0.073377                                        LR 0.100000    Time 0.032237    
2022-01-25 18:26:40,654 - Epoch: [39][   60/  211]    Overall Loss 0.074154    Objective Loss 0.074154                                        LR 0.100000    Time 0.030563    
2022-01-25 18:26:40,876 - Epoch: [39][   70/  211]    Overall Loss 0.072242    Objective Loss 0.072242                                        LR 0.100000    Time 0.029369    
2022-01-25 18:26:41,140 - Epoch: [39][   80/  211]    Overall Loss 0.072020    Objective Loss 0.072020                                        LR 0.100000    Time 0.028988    
2022-01-25 18:26:41,385 - Epoch: [39][   90/  211]    Overall Loss 0.070663    Objective Loss 0.070663                                        LR 0.100000    Time 0.028479    
2022-01-25 18:26:41,676 - Epoch: [39][  100/  211]    Overall Loss 0.070497    Objective Loss 0.070497                                        LR 0.100000    Time 0.028540    
2022-01-25 18:26:41,920 - Epoch: [39][  110/  211]    Overall Loss 0.070422    Objective Loss 0.070422                                        LR 0.100000    Time 0.028159    
2022-01-25 18:26:42,207 - Epoch: [39][  120/  211]    Overall Loss 0.069655    Objective Loss 0.069655                                        LR 0.100000    Time 0.028201    
2022-01-25 18:26:42,452 - Epoch: [39][  130/  211]    Overall Loss 0.070209    Objective Loss 0.070209                                        LR 0.100000    Time 0.027915    
2022-01-25 18:26:42,738 - Epoch: [39][  140/  211]    Overall Loss 0.069506    Objective Loss 0.069506                                        LR 0.100000    Time 0.027963    
2022-01-25 18:26:42,986 - Epoch: [39][  150/  211]    Overall Loss 0.068932    Objective Loss 0.068932                                        LR 0.100000    Time 0.027751    
2022-01-25 18:26:43,261 - Epoch: [39][  160/  211]    Overall Loss 0.068682    Objective Loss 0.068682                                        LR 0.100000    Time 0.027734    
2022-01-25 18:26:43,515 - Epoch: [39][  170/  211]    Overall Loss 0.068727    Objective Loss 0.068727                                        LR 0.100000    Time 0.027596    
2022-01-25 18:26:43,790 - Epoch: [39][  180/  211]    Overall Loss 0.068657    Objective Loss 0.068657                                        LR 0.100000    Time 0.027585    
2022-01-25 18:26:44,045 - Epoch: [39][  190/  211]    Overall Loss 0.068463    Objective Loss 0.068463                                        LR 0.100000    Time 0.027474    
2022-01-25 18:26:44,324 - Epoch: [39][  200/  211]    Overall Loss 0.068914    Objective Loss 0.068914                                        LR 0.100000    Time 0.027495    
2022-01-25 18:26:44,570 - Epoch: [39][  210/  211]    Overall Loss 0.068694    Objective Loss 0.068694    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.027355    
2022-01-25 18:26:44,615 - Epoch: [39][  211/  211]    Overall Loss 0.068808    Objective Loss 0.068808    Top1 97.580645    Top5 100.000000    LR 0.100000    Time 0.027438    
2022-01-25 18:26:44,729 - --- validate (epoch=39)-----------
2022-01-25 18:26:44,729 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:45,260 - Epoch: [39][   10/   24]    Loss 0.060068    Top1 98.671875    Top5 100.000000    
2022-01-25 18:26:45,518 - Epoch: [39][   20/   24]    Loss 0.063069    Top1 98.515625    Top5 100.000000    
2022-01-25 18:26:45,618 - Epoch: [39][   24/   24]    Loss 0.062279    Top1 98.550000    Top5 100.000000    
2022-01-25 18:26:45,691 - ==> Top1: 98.550    Top5: 100.000    Loss: 0.062

2022-01-25 18:26:45,692 - ==> Confusion:
[[598   0   3   0   0   0   1   1   0   2]
 [  0 686   1   0   0   0   1   0   0   0]
 [  0   1 576   3   0   0   0   4   2   0]
 [  0   0   6 570   0   3   0   2   2   0]
 [  0   1   2   0 551   0   1   0   0  10]
 [  3   0   0   1   0 503   3   3   2   3]
 [  1   0   0   0   1   0 628   0   1   0]
 [  0   0   2   0   1   0   0 622   0   0]
 [  3   0   1   0   0   1   2   1 576   0]
 [  0   2   0   2   4   0   0   2   3 602]]

2022-01-25 18:26:45,693 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:26:45,693 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:45,700 - 

2022-01-25 18:26:45,701 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:46,440 - Epoch: [40][   10/  211]    Overall Loss 0.071935    Objective Loss 0.071935                                        LR 0.100000    Time 0.073910    
2022-01-25 18:26:46,675 - Epoch: [40][   20/  211]    Overall Loss 0.065752    Objective Loss 0.065752                                        LR 0.100000    Time 0.048696    
2022-01-25 18:26:46,900 - Epoch: [40][   30/  211]    Overall Loss 0.066101    Objective Loss 0.066101                                        LR 0.100000    Time 0.039923    
2022-01-25 18:26:47,113 - Epoch: [40][   40/  211]    Overall Loss 0.067712    Objective Loss 0.067712                                        LR 0.100000    Time 0.035268    
2022-01-25 18:26:47,335 - Epoch: [40][   50/  211]    Overall Loss 0.066288    Objective Loss 0.066288                                        LR 0.100000    Time 0.032654    
2022-01-25 18:26:47,552 - Epoch: [40][   60/  211]    Overall Loss 0.066577    Objective Loss 0.066577                                        LR 0.100000    Time 0.030812    
2022-01-25 18:26:47,783 - Epoch: [40][   70/  211]    Overall Loss 0.066349    Objective Loss 0.066349                                        LR 0.100000    Time 0.029717    
2022-01-25 18:26:47,993 - Epoch: [40][   80/  211]    Overall Loss 0.068461    Objective Loss 0.068461                                        LR 0.100000    Time 0.028617    
2022-01-25 18:26:48,218 - Epoch: [40][   90/  211]    Overall Loss 0.069110    Objective Loss 0.069110                                        LR 0.100000    Time 0.027934    
2022-01-25 18:26:48,430 - Epoch: [40][  100/  211]    Overall Loss 0.069658    Objective Loss 0.069658                                        LR 0.100000    Time 0.027257    
2022-01-25 18:26:48,661 - Epoch: [40][  110/  211]    Overall Loss 0.070094    Objective Loss 0.070094                                        LR 0.100000    Time 0.026876    
2022-01-25 18:26:48,871 - Epoch: [40][  120/  211]    Overall Loss 0.070100    Objective Loss 0.070100                                        LR 0.100000    Time 0.026386    
2022-01-25 18:26:49,101 - Epoch: [40][  130/  211]    Overall Loss 0.070189    Objective Loss 0.070189                                        LR 0.100000    Time 0.026121    
2022-01-25 18:26:49,318 - Epoch: [40][  140/  211]    Overall Loss 0.069656    Objective Loss 0.069656                                        LR 0.100000    Time 0.025804    
2022-01-25 18:26:49,557 - Epoch: [40][  150/  211]    Overall Loss 0.069544    Objective Loss 0.069544                                        LR 0.100000    Time 0.025675    
2022-01-25 18:26:49,847 - Epoch: [40][  160/  211]    Overall Loss 0.068851    Objective Loss 0.068851                                        LR 0.100000    Time 0.025882    
2022-01-25 18:26:50,097 - Epoch: [40][  170/  211]    Overall Loss 0.069129    Objective Loss 0.069129                                        LR 0.100000    Time 0.025826    
2022-01-25 18:26:50,379 - Epoch: [40][  180/  211]    Overall Loss 0.068696    Objective Loss 0.068696                                        LR 0.100000    Time 0.025957    
2022-01-25 18:26:50,628 - Epoch: [40][  190/  211]    Overall Loss 0.068240    Objective Loss 0.068240                                        LR 0.100000    Time 0.025898    
2022-01-25 18:26:50,907 - Epoch: [40][  200/  211]    Overall Loss 0.067715    Objective Loss 0.067715                                        LR 0.100000    Time 0.025995    
2022-01-25 18:26:51,153 - Epoch: [40][  210/  211]    Overall Loss 0.067762    Objective Loss 0.067762    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.025929    
2022-01-25 18:26:51,173 - Epoch: [40][  211/  211]    Overall Loss 0.067951    Objective Loss 0.067951    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.025898    
2022-01-25 18:26:51,247 - --- validate (epoch=40)-----------
2022-01-25 18:26:51,247 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:51,716 - Epoch: [40][   10/   24]    Loss 0.070954    Top1 98.203125    Top5 99.960938    
2022-01-25 18:26:51,915 - Epoch: [40][   20/   24]    Loss 0.074764    Top1 97.929688    Top5 99.960938    
2022-01-25 18:26:51,999 - Epoch: [40][   24/   24]    Loss 0.077669    Top1 97.883333    Top5 99.950000    
2022-01-25 18:26:52,055 - ==> Top1: 97.883    Top5: 99.950    Loss: 0.078

2022-01-25 18:26:52,055 - ==> Confusion:
[[597   0   2   0   0   0   3   2   0   1]
 [  0 684   1   0   0   0   0   3   0   0]
 [  0   1 579   0   1   0   0   3   1   1]
 [  0   0   6 560   1   3   0   6   5   2]
 [  0   3   1   0 553   0   2   1   0   5]
 [  1   2   0   1   1 499   9   2   1   2]
 [  0   3   0   0   3   0 624   0   1   0]
 [  0   0   4   0   1   0   0 620   0   0]
 [  1   0   1   0   7   1   6   0 567   1]
 [  0   3   0   0  14   1   0   4   3 590]]

2022-01-25 18:26:52,057 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:26:52,057 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:52,062 - 

2022-01-25 18:26:52,063 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:52,608 - Epoch: [41][   10/  211]    Overall Loss 0.067667    Objective Loss 0.067667                                        LR 0.100000    Time 0.054383    
2022-01-25 18:26:52,814 - Epoch: [41][   20/  211]    Overall Loss 0.066438    Objective Loss 0.066438                                        LR 0.100000    Time 0.037483    
2022-01-25 18:26:53,052 - Epoch: [41][   30/  211]    Overall Loss 0.064305    Objective Loss 0.064305                                        LR 0.100000    Time 0.032916    
2022-01-25 18:26:53,330 - Epoch: [41][   40/  211]    Overall Loss 0.062383    Objective Loss 0.062383                                        LR 0.100000    Time 0.031631    
2022-01-25 18:26:53,582 - Epoch: [41][   50/  211]    Overall Loss 0.062066    Objective Loss 0.062066                                        LR 0.100000    Time 0.030336    
2022-01-25 18:26:53,865 - Epoch: [41][   60/  211]    Overall Loss 0.062466    Objective Loss 0.062466                                        LR 0.100000    Time 0.029990    
2022-01-25 18:26:54,110 - Epoch: [41][   70/  211]    Overall Loss 0.062103    Objective Loss 0.062103                                        LR 0.100000    Time 0.029208    
2022-01-25 18:26:54,395 - Epoch: [41][   80/  211]    Overall Loss 0.062191    Objective Loss 0.062191                                        LR 0.100000    Time 0.029108    
2022-01-25 18:26:54,650 - Epoch: [41][   90/  211]    Overall Loss 0.061321    Objective Loss 0.061321                                        LR 0.100000    Time 0.028706    
2022-01-25 18:26:54,931 - Epoch: [41][  100/  211]    Overall Loss 0.061199    Objective Loss 0.061199                                        LR 0.100000    Time 0.028640    
2022-01-25 18:26:55,174 - Epoch: [41][  110/  211]    Overall Loss 0.060400    Objective Loss 0.060400                                        LR 0.100000    Time 0.028244    
2022-01-25 18:26:55,462 - Epoch: [41][  120/  211]    Overall Loss 0.059664    Objective Loss 0.059664                                        LR 0.100000    Time 0.028288    
2022-01-25 18:26:55,702 - Epoch: [41][  130/  211]    Overall Loss 0.060117    Objective Loss 0.060117                                        LR 0.100000    Time 0.027957    
2022-01-25 18:26:55,989 - Epoch: [41][  140/  211]    Overall Loss 0.060992    Objective Loss 0.060992                                        LR 0.100000    Time 0.028007    
2022-01-25 18:26:56,235 - Epoch: [41][  150/  211]    Overall Loss 0.061396    Objective Loss 0.061396                                        LR 0.100000    Time 0.027774    
2022-01-25 18:26:56,513 - Epoch: [41][  160/  211]    Overall Loss 0.062197    Objective Loss 0.062197                                        LR 0.100000    Time 0.027777    
2022-01-25 18:26:56,760 - Epoch: [41][  170/  211]    Overall Loss 0.063062    Objective Loss 0.063062                                        LR 0.100000    Time 0.027591    
2022-01-25 18:26:57,043 - Epoch: [41][  180/  211]    Overall Loss 0.063126    Objective Loss 0.063126                                        LR 0.100000    Time 0.027631    
2022-01-25 18:26:57,287 - Epoch: [41][  190/  211]    Overall Loss 0.063543    Objective Loss 0.063543                                        LR 0.100000    Time 0.027453    
2022-01-25 18:26:57,573 - Epoch: [41][  200/  211]    Overall Loss 0.064205    Objective Loss 0.064205                                        LR 0.100000    Time 0.027512    
2022-01-25 18:26:57,823 - Epoch: [41][  210/  211]    Overall Loss 0.064272    Objective Loss 0.064272    Top1 98.046875    Top5 99.609375    LR 0.100000    Time 0.027392    
2022-01-25 18:26:57,865 - Epoch: [41][  211/  211]    Overall Loss 0.064399    Objective Loss 0.064399    Top1 97.580645    Top5 99.596774    LR 0.100000    Time 0.027457    
2022-01-25 18:26:57,921 - --- validate (epoch=41)-----------
2022-01-25 18:26:57,921 - 6000 samples (256 per mini-batch)
2022-01-25 18:26:58,429 - Epoch: [41][   10/   24]    Loss 0.068749    Top1 98.671875    Top5 100.000000    
2022-01-25 18:26:58,672 - Epoch: [41][   20/   24]    Loss 0.068696    Top1 98.457031    Top5 100.000000    
2022-01-25 18:26:58,761 - Epoch: [41][   24/   24]    Loss 0.065653    Top1 98.533333    Top5 100.000000    
2022-01-25 18:26:58,823 - ==> Top1: 98.533    Top5: 100.000    Loss: 0.066

2022-01-25 18:26:58,824 - ==> Confusion:
[[600   0   2   1   0   0   1   0   0   1]
 [  0 680   1   2   0   0   3   2   0   0]
 [  1   0 578   3   0   0   1   2   0   1]
 [  0   0   0 580   0   1   0   1   1   0]
 [  0   1   2   0 551   0   1   1   0   9]
 [  0   0   0   4   0 507   4   1   1   1]
 [  2   0   0   0   1   1 627   0   0   0]
 [  0   0   6   1   1   0   0 616   0   1]
 [  0   1   1   1   0   0   7   0 572   2]
 [  0   2   0   1   3   1   0   3   4 601]]

2022-01-25 18:26:58,827 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:26:58,827 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:26:58,834 - 

2022-01-25 18:26:58,834 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:26:59,536 - Epoch: [42][   10/  211]    Overall Loss 0.059169    Objective Loss 0.059169                                        LR 0.100000    Time 0.070105    
2022-01-25 18:26:59,777 - Epoch: [42][   20/  211]    Overall Loss 0.062179    Objective Loss 0.062179                                        LR 0.100000    Time 0.047099    
2022-01-25 18:26:59,990 - Epoch: [42][   30/  211]    Overall Loss 0.062900    Objective Loss 0.062900                                        LR 0.100000    Time 0.038490    
2022-01-25 18:27:00,208 - Epoch: [42][   40/  211]    Overall Loss 0.062041    Objective Loss 0.062041                                        LR 0.100000    Time 0.034306    
2022-01-25 18:27:00,421 - Epoch: [42][   50/  211]    Overall Loss 0.062807    Objective Loss 0.062807                                        LR 0.100000    Time 0.031707    
2022-01-25 18:27:00,648 - Epoch: [42][   60/  211]    Overall Loss 0.064482    Objective Loss 0.064482                                        LR 0.100000    Time 0.030195    
2022-01-25 18:27:00,925 - Epoch: [42][   70/  211]    Overall Loss 0.063811    Objective Loss 0.063811                                        LR 0.100000    Time 0.029835    
2022-01-25 18:27:01,180 - Epoch: [42][   80/  211]    Overall Loss 0.064037    Objective Loss 0.064037                                        LR 0.100000    Time 0.029292    
2022-01-25 18:27:01,461 - Epoch: [42][   90/  211]    Overall Loss 0.063098    Objective Loss 0.063098                                        LR 0.100000    Time 0.029150    
2022-01-25 18:27:01,708 - Epoch: [42][  100/  211]    Overall Loss 0.063436    Objective Loss 0.063436                                        LR 0.100000    Time 0.028709    
2022-01-25 18:27:01,991 - Epoch: [42][  110/  211]    Overall Loss 0.063844    Objective Loss 0.063844                                        LR 0.100000    Time 0.028665    
2022-01-25 18:27:02,248 - Epoch: [42][  120/  211]    Overall Loss 0.063560    Objective Loss 0.063560                                        LR 0.100000    Time 0.028417    
2022-01-25 18:27:02,527 - Epoch: [42][  130/  211]    Overall Loss 0.064638    Objective Loss 0.064638                                        LR 0.100000    Time 0.028370    
2022-01-25 18:27:02,774 - Epoch: [42][  140/  211]    Overall Loss 0.064817    Objective Loss 0.064817                                        LR 0.100000    Time 0.028107    
2022-01-25 18:27:03,053 - Epoch: [42][  150/  211]    Overall Loss 0.065233    Objective Loss 0.065233                                        LR 0.100000    Time 0.028092    
2022-01-25 18:27:03,302 - Epoch: [42][  160/  211]    Overall Loss 0.065330    Objective Loss 0.065330                                        LR 0.100000    Time 0.027889    
2022-01-25 18:27:03,589 - Epoch: [42][  170/  211]    Overall Loss 0.065425    Objective Loss 0.065425                                        LR 0.100000    Time 0.027936    
2022-01-25 18:27:03,836 - Epoch: [42][  180/  211]    Overall Loss 0.065972    Objective Loss 0.065972                                        LR 0.100000    Time 0.027754    
2022-01-25 18:27:04,115 - Epoch: [42][  190/  211]    Overall Loss 0.065552    Objective Loss 0.065552                                        LR 0.100000    Time 0.027762    
2022-01-25 18:27:04,366 - Epoch: [42][  200/  211]    Overall Loss 0.065359    Objective Loss 0.065359                                        LR 0.100000    Time 0.027626    
2022-01-25 18:27:04,643 - Epoch: [42][  210/  211]    Overall Loss 0.065857    Objective Loss 0.065857    Top1 96.484375    Top5 100.000000    LR 0.100000    Time 0.027629    
2022-01-25 18:27:04,662 - Epoch: [42][  211/  211]    Overall Loss 0.065874    Objective Loss 0.065874    Top1 97.177419    Top5 100.000000    LR 0.100000    Time 0.027587    
2022-01-25 18:27:04,727 - --- validate (epoch=42)-----------
2022-01-25 18:27:04,728 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:05,206 - Epoch: [42][   10/   24]    Loss 0.060214    Top1 98.750000    Top5 100.000000    
2022-01-25 18:27:05,405 - Epoch: [42][   20/   24]    Loss 0.062979    Top1 98.574219    Top5 99.980469    
2022-01-25 18:27:05,491 - Epoch: [42][   24/   24]    Loss 0.064230    Top1 98.516667    Top5 99.966667    
2022-01-25 18:27:05,549 - ==> Top1: 98.517    Top5: 99.967    Loss: 0.064

2022-01-25 18:27:05,551 - ==> Confusion:
[[598   0   2   0   0   0   2   0   1   2]
 [  0 684   2   1   0   0   0   1   0   0]
 [  0   1 581   2   0   0   1   1   0   0]
 [  0   0   3 577   0   2   0   0   1   0]
 [  0   1   2   0 551   1   2   1   0   7]
 [  0   1   0   1   0 508   6   0   1   1]
 [  0   1   0   0   3   0 626   0   0   1]
 [  0   2   5   1   3   0   0 614   0   0]
 [  1   0   1   3   1   2   7   0 568   1]
 [  1   1   0   1   1   2   0   2   3 604]]

2022-01-25 18:27:05,553 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:27:05,553 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:05,562 - 

2022-01-25 18:27:05,563 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:06,113 - Epoch: [43][   10/  211]    Overall Loss 0.070266    Objective Loss 0.070266                                        LR 0.100000    Time 0.054995    
2022-01-25 18:27:06,321 - Epoch: [43][   20/  211]    Overall Loss 0.071681    Objective Loss 0.071681                                        LR 0.100000    Time 0.037856    
2022-01-25 18:27:06,547 - Epoch: [43][   30/  211]    Overall Loss 0.072247    Objective Loss 0.072247                                        LR 0.100000    Time 0.032764    
2022-01-25 18:27:06,757 - Epoch: [43][   40/  211]    Overall Loss 0.071470    Objective Loss 0.071470                                        LR 0.100000    Time 0.029823    
2022-01-25 18:27:06,981 - Epoch: [43][   50/  211]    Overall Loss 0.069826    Objective Loss 0.069826                                        LR 0.100000    Time 0.028323    
2022-01-25 18:27:07,229 - Epoch: [43][   60/  211]    Overall Loss 0.072987    Objective Loss 0.072987                                        LR 0.100000    Time 0.027736    
2022-01-25 18:27:07,476 - Epoch: [43][   70/  211]    Overall Loss 0.074361    Objective Loss 0.074361                                        LR 0.100000    Time 0.027298    
2022-01-25 18:27:07,762 - Epoch: [43][   80/  211]    Overall Loss 0.076069    Objective Loss 0.076069                                        LR 0.100000    Time 0.027448    
2022-01-25 18:27:08,007 - Epoch: [43][   90/  211]    Overall Loss 0.075556    Objective Loss 0.075556                                        LR 0.100000    Time 0.027126    
2022-01-25 18:27:08,289 - Epoch: [43][  100/  211]    Overall Loss 0.075074    Objective Loss 0.075074                                        LR 0.100000    Time 0.027221    
2022-01-25 18:27:08,536 - Epoch: [43][  110/  211]    Overall Loss 0.074605    Objective Loss 0.074605                                        LR 0.100000    Time 0.026994    
2022-01-25 18:27:08,825 - Epoch: [43][  120/  211]    Overall Loss 0.074061    Objective Loss 0.074061                                        LR 0.100000    Time 0.027146    
2022-01-25 18:27:09,074 - Epoch: [43][  130/  211]    Overall Loss 0.073719    Objective Loss 0.073719                                        LR 0.100000    Time 0.026973    
2022-01-25 18:27:09,353 - Epoch: [43][  140/  211]    Overall Loss 0.073394    Objective Loss 0.073394                                        LR 0.100000    Time 0.027040    
2022-01-25 18:27:09,602 - Epoch: [43][  150/  211]    Overall Loss 0.072757    Objective Loss 0.072757                                        LR 0.100000    Time 0.026890    
2022-01-25 18:27:09,889 - Epoch: [43][  160/  211]    Overall Loss 0.072144    Objective Loss 0.072144                                        LR 0.100000    Time 0.027003    
2022-01-25 18:27:10,136 - Epoch: [43][  170/  211]    Overall Loss 0.071662    Objective Loss 0.071662                                        LR 0.100000    Time 0.026866    
2022-01-25 18:27:10,417 - Epoch: [43][  180/  211]    Overall Loss 0.070733    Objective Loss 0.070733                                        LR 0.100000    Time 0.026932    
2022-01-25 18:27:10,661 - Epoch: [43][  190/  211]    Overall Loss 0.069666    Objective Loss 0.069666                                        LR 0.100000    Time 0.026797    
2022-01-25 18:27:10,909 - Epoch: [43][  200/  211]    Overall Loss 0.069162    Objective Loss 0.069162                                        LR 0.100000    Time 0.026696    
2022-01-25 18:27:11,121 - Epoch: [43][  210/  211]    Overall Loss 0.069191    Objective Loss 0.069191    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.026431    
2022-01-25 18:27:11,140 - Epoch: [43][  211/  211]    Overall Loss 0.069143    Objective Loss 0.069143    Top1 97.580645    Top5 100.000000    LR 0.100000    Time 0.026394    
2022-01-25 18:27:11,195 - --- validate (epoch=43)-----------
2022-01-25 18:27:11,195 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:11,665 - Epoch: [43][   10/   24]    Loss 0.054824    Top1 98.828125    Top5 100.000000    
2022-01-25 18:27:11,863 - Epoch: [43][   20/   24]    Loss 0.056355    Top1 98.652344    Top5 99.980469    
2022-01-25 18:27:11,947 - Epoch: [43][   24/   24]    Loss 0.062262    Top1 98.450000    Top5 99.983333    
2022-01-25 18:27:12,002 - ==> Top1: 98.450    Top5: 99.983    Loss: 0.062

2022-01-25 18:27:12,003 - ==> Confusion:
[[597   1   0   0   0   1   1   0   2   3]
 [  0 687   0   0   0   1   0   0   0   0]
 [  0   2 573   2   0   0   1   7   0   1]
 [  0   1   1 578   0   0   0   1   1   1]
 [  0   1   0   0 552   0   1   1   0  10]
 [  0   1   0   2   0 508   3   1   3   0]
 [  2   2   0   0   2   1 624   0   0   0]
 [  0   3   6   0   0   0   0 615   0   1]
 [  0   0   0   3   1   2   4   0 572   2]
 [  3   2   0   1   2   1   0   4   1 601]]

2022-01-25 18:27:12,004 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:27:12,005 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:12,011 - 

2022-01-25 18:27:12,011 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:12,702 - Epoch: [44][   10/  211]    Overall Loss 0.067310    Objective Loss 0.067310                                        LR 0.100000    Time 0.069060    
2022-01-25 18:27:12,914 - Epoch: [44][   20/  211]    Overall Loss 0.066971    Objective Loss 0.066971                                        LR 0.100000    Time 0.045079    
2022-01-25 18:27:13,141 - Epoch: [44][   30/  211]    Overall Loss 0.064032    Objective Loss 0.064032                                        LR 0.100000    Time 0.037610    
2022-01-25 18:27:13,450 - Epoch: [44][   40/  211]    Overall Loss 0.063850    Objective Loss 0.063850                                        LR 0.100000    Time 0.035938    
2022-01-25 18:27:13,757 - Epoch: [44][   50/  211]    Overall Loss 0.063432    Objective Loss 0.063432                                        LR 0.100000    Time 0.034874    
2022-01-25 18:27:13,982 - Epoch: [44][   60/  211]    Overall Loss 0.063132    Objective Loss 0.063132                                        LR 0.100000    Time 0.032803    
2022-01-25 18:27:14,308 - Epoch: [44][   70/  211]    Overall Loss 0.064186    Objective Loss 0.064186                                        LR 0.100000    Time 0.032759    
2022-01-25 18:27:14,521 - Epoch: [44][   80/  211]    Overall Loss 0.064631    Objective Loss 0.064631                                        LR 0.100000    Time 0.031326    
2022-01-25 18:27:14,751 - Epoch: [44][   90/  211]    Overall Loss 0.064125    Objective Loss 0.064125                                        LR 0.100000    Time 0.030396    
2022-01-25 18:27:14,963 - Epoch: [44][  100/  211]    Overall Loss 0.063991    Objective Loss 0.063991                                        LR 0.100000    Time 0.029480    
2022-01-25 18:27:15,188 - Epoch: [44][  110/  211]    Overall Loss 0.063585    Objective Loss 0.063585                                        LR 0.100000    Time 0.028839    
2022-01-25 18:27:15,410 - Epoch: [44][  120/  211]    Overall Loss 0.063484    Objective Loss 0.063484                                        LR 0.100000    Time 0.028281    
2022-01-25 18:27:15,637 - Epoch: [44][  130/  211]    Overall Loss 0.064308    Objective Loss 0.064308                                        LR 0.100000    Time 0.027853    
2022-01-25 18:27:15,849 - Epoch: [44][  140/  211]    Overall Loss 0.064518    Objective Loss 0.064518                                        LR 0.100000    Time 0.027371    
2022-01-25 18:27:16,074 - Epoch: [44][  150/  211]    Overall Loss 0.064740    Objective Loss 0.064740                                        LR 0.100000    Time 0.027047    
2022-01-25 18:27:16,290 - Epoch: [44][  160/  211]    Overall Loss 0.064929    Objective Loss 0.064929                                        LR 0.100000    Time 0.026703    
2022-01-25 18:27:16,516 - Epoch: [44][  170/  211]    Overall Loss 0.065886    Objective Loss 0.065886                                        LR 0.100000    Time 0.026462    
2022-01-25 18:27:16,737 - Epoch: [44][  180/  211]    Overall Loss 0.066391    Objective Loss 0.066391                                        LR 0.100000    Time 0.026214    
2022-01-25 18:27:16,961 - Epoch: [44][  190/  211]    Overall Loss 0.066639    Objective Loss 0.066639                                        LR 0.100000    Time 0.026013    
2022-01-25 18:27:17,172 - Epoch: [44][  200/  211]    Overall Loss 0.066657    Objective Loss 0.066657                                        LR 0.100000    Time 0.025764    
2022-01-25 18:27:17,460 - Epoch: [44][  210/  211]    Overall Loss 0.066460    Objective Loss 0.066460    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.025907    
2022-01-25 18:27:17,479 - Epoch: [44][  211/  211]    Overall Loss 0.066424    Objective Loss 0.066424    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.025876    
2022-01-25 18:27:17,558 - --- validate (epoch=44)-----------
2022-01-25 18:27:17,558 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:18,030 - Epoch: [44][   10/   24]    Loss 0.066103    Top1 98.320312    Top5 100.000000    
2022-01-25 18:27:18,230 - Epoch: [44][   20/   24]    Loss 0.061659    Top1 98.515625    Top5 100.000000    
2022-01-25 18:27:18,316 - Epoch: [44][   24/   24]    Loss 0.061152    Top1 98.516667    Top5 100.000000    
2022-01-25 18:27:18,376 - ==> Top1: 98.517    Top5: 100.000    Loss: 0.061

2022-01-25 18:27:18,376 - ==> Confusion:
[[602   0   1   0   0   0   1   1   0   0]
 [  0 684   2   0   1   0   0   1   0   0]
 [  1   0 578   0   0   0   1   2   3   1]
 [  0   1   2 572   0   3   0   2   2   1]
 [  0   1   2   0 550   0   2   0   2   8]
 [  1   0   0   2   0 509   2   0   3   1]
 [  0   1   0   0   2   3 623   0   2   0]
 [  0   5   3   1   1   0   0 612   0   3]
 [  1   0   0   0   0   1   2   0 578   2]
 [  0   1   1   1   1   1   0   3   4 603]]

2022-01-25 18:27:18,378 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:27:18,378 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:18,384 - 

2022-01-25 18:27:18,385 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:19,096 - Epoch: [45][   10/  211]    Overall Loss 0.063077    Objective Loss 0.063077                                        LR 0.100000    Time 0.071040    
2022-01-25 18:27:19,327 - Epoch: [45][   20/  211]    Overall Loss 0.061132    Objective Loss 0.061132                                        LR 0.100000    Time 0.047077    
2022-01-25 18:27:19,571 - Epoch: [45][   30/  211]    Overall Loss 0.063944    Objective Loss 0.063944                                        LR 0.100000    Time 0.039498    
2022-01-25 18:27:19,853 - Epoch: [45][   40/  211]    Overall Loss 0.063639    Objective Loss 0.063639                                        LR 0.100000    Time 0.036671    
2022-01-25 18:27:20,100 - Epoch: [45][   50/  211]    Overall Loss 0.064432    Objective Loss 0.064432                                        LR 0.100000    Time 0.034254    
2022-01-25 18:27:20,381 - Epoch: [45][   60/  211]    Overall Loss 0.063896    Objective Loss 0.063896                                        LR 0.100000    Time 0.033234    
2022-01-25 18:27:20,627 - Epoch: [45][   70/  211]    Overall Loss 0.065312    Objective Loss 0.065312                                        LR 0.100000    Time 0.031992    
2022-01-25 18:27:20,912 - Epoch: [45][   80/  211]    Overall Loss 0.064896    Objective Loss 0.064896                                        LR 0.100000    Time 0.031555    
2022-01-25 18:27:21,157 - Epoch: [45][   90/  211]    Overall Loss 0.066221    Objective Loss 0.066221                                        LR 0.100000    Time 0.030766    
2022-01-25 18:27:21,445 - Epoch: [45][  100/  211]    Overall Loss 0.067160    Objective Loss 0.067160                                        LR 0.100000    Time 0.030565    
2022-01-25 18:27:21,691 - Epoch: [45][  110/  211]    Overall Loss 0.066953    Objective Loss 0.066953                                        LR 0.100000    Time 0.030020    
2022-01-25 18:27:21,975 - Epoch: [45][  120/  211]    Overall Loss 0.066361    Objective Loss 0.066361                                        LR 0.100000    Time 0.029878    
2022-01-25 18:27:22,230 - Epoch: [45][  130/  211]    Overall Loss 0.066745    Objective Loss 0.066745                                        LR 0.100000    Time 0.029539    
2022-01-25 18:27:22,506 - Epoch: [45][  140/  211]    Overall Loss 0.066986    Objective Loss 0.066986                                        LR 0.100000    Time 0.029399    
2022-01-25 18:27:22,751 - Epoch: [45][  150/  211]    Overall Loss 0.066583    Objective Loss 0.066583                                        LR 0.100000    Time 0.029069    
2022-01-25 18:27:23,033 - Epoch: [45][  160/  211]    Overall Loss 0.066217    Objective Loss 0.066217                                        LR 0.100000    Time 0.029011    
2022-01-25 18:27:23,276 - Epoch: [45][  170/  211]    Overall Loss 0.066487    Objective Loss 0.066487                                        LR 0.100000    Time 0.028736    
2022-01-25 18:27:23,555 - Epoch: [45][  180/  211]    Overall Loss 0.066105    Objective Loss 0.066105                                        LR 0.100000    Time 0.028686    
2022-01-25 18:27:23,801 - Epoch: [45][  190/  211]    Overall Loss 0.066699    Objective Loss 0.066699                                        LR 0.100000    Time 0.028470    
2022-01-25 18:27:24,088 - Epoch: [45][  200/  211]    Overall Loss 0.066056    Objective Loss 0.066056                                        LR 0.100000    Time 0.028480    
2022-01-25 18:27:24,332 - Epoch: [45][  210/  211]    Overall Loss 0.065720    Objective Loss 0.065720    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.028282    
2022-01-25 18:27:24,376 - Epoch: [45][  211/  211]    Overall Loss 0.065575    Objective Loss 0.065575    Top1 99.395161    Top5 100.000000    LR 0.100000    Time 0.028357    
2022-01-25 18:27:24,445 - --- validate (epoch=45)-----------
2022-01-25 18:27:24,445 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:24,919 - Epoch: [45][   10/   24]    Loss 0.070371    Top1 98.281250    Top5 100.000000    
2022-01-25 18:27:25,122 - Epoch: [45][   20/   24]    Loss 0.067187    Top1 98.339844    Top5 100.000000    
2022-01-25 18:27:25,206 - Epoch: [45][   24/   24]    Loss 0.065328    Top1 98.433333    Top5 100.000000    
2022-01-25 18:27:25,274 - ==> Top1: 98.433    Top5: 100.000    Loss: 0.065

2022-01-25 18:27:25,275 - ==> Confusion:
[[601   0   1   0   0   0   3   0   0   0]
 [  0 681   0   0   0   0   1   6   0   0]
 [  1   0 574   0   0   1   1   5   4   0]
 [  0   0   0 577   0   3   0   2   1   0]
 [  1   0   1   0 554   1   1   1   0   6]
 [  0   0   0   2   0 509   6   0   1   0]
 [  1   0   0   0   1   0 629   0   0   0]
 [  0   1   3   4   0   0   0 617   0   0]
 [  2   0   0   2   2   0   5   0 573   0]
 [  1   2   1   4   7   2   1   2   4 591]]

2022-01-25 18:27:25,278 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:27:25,278 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:25,286 - 

2022-01-25 18:27:25,286 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:25,848 - Epoch: [46][   10/  211]    Overall Loss 0.061946    Objective Loss 0.061946                                        LR 0.100000    Time 0.056141    
2022-01-25 18:27:26,102 - Epoch: [46][   20/  211]    Overall Loss 0.056802    Objective Loss 0.056802                                        LR 0.100000    Time 0.040735    
2022-01-25 18:27:26,378 - Epoch: [46][   30/  211]    Overall Loss 0.065630    Objective Loss 0.065630                                        LR 0.100000    Time 0.036341    
2022-01-25 18:27:26,625 - Epoch: [46][   40/  211]    Overall Loss 0.065336    Objective Loss 0.065336                                        LR 0.100000    Time 0.033429    
2022-01-25 18:27:26,888 - Epoch: [46][   50/  211]    Overall Loss 0.065013    Objective Loss 0.065013                                        LR 0.100000    Time 0.031991    
2022-01-25 18:27:27,100 - Epoch: [46][   60/  211]    Overall Loss 0.065122    Objective Loss 0.065122                                        LR 0.100000    Time 0.030190    
2022-01-25 18:27:27,336 - Epoch: [46][   70/  211]    Overall Loss 0.065289    Objective Loss 0.065289                                        LR 0.100000    Time 0.029249    
2022-01-25 18:27:27,550 - Epoch: [46][   80/  211]    Overall Loss 0.064565    Objective Loss 0.064565                                        LR 0.100000    Time 0.028266    
2022-01-25 18:27:27,774 - Epoch: [46][   90/  211]    Overall Loss 0.064183    Objective Loss 0.064183                                        LR 0.100000    Time 0.027608    
2022-01-25 18:27:27,986 - Epoch: [46][  100/  211]    Overall Loss 0.063679    Objective Loss 0.063679                                        LR 0.100000    Time 0.026959    
2022-01-25 18:27:28,208 - Epoch: [46][  110/  211]    Overall Loss 0.063094    Objective Loss 0.063094                                        LR 0.100000    Time 0.026530    
2022-01-25 18:27:28,429 - Epoch: [46][  120/  211]    Overall Loss 0.064050    Objective Loss 0.064050                                        LR 0.100000    Time 0.026151    
2022-01-25 18:27:28,656 - Epoch: [46][  130/  211]    Overall Loss 0.065018    Objective Loss 0.065018                                        LR 0.100000    Time 0.025888    
2022-01-25 18:27:28,865 - Epoch: [46][  140/  211]    Overall Loss 0.065069    Objective Loss 0.065069                                        LR 0.100000    Time 0.025529    
2022-01-25 18:27:29,090 - Epoch: [46][  150/  211]    Overall Loss 0.065094    Objective Loss 0.065094                                        LR 0.100000    Time 0.025321    
2022-01-25 18:27:29,302 - Epoch: [46][  160/  211]    Overall Loss 0.065006    Objective Loss 0.065006                                        LR 0.100000    Time 0.025062    
2022-01-25 18:27:29,524 - Epoch: [46][  170/  211]    Overall Loss 0.064995    Objective Loss 0.064995                                        LR 0.100000    Time 0.024892    
2022-01-25 18:27:29,732 - Epoch: [46][  180/  211]    Overall Loss 0.064618    Objective Loss 0.064618                                        LR 0.100000    Time 0.024664    
2022-01-25 18:27:29,961 - Epoch: [46][  190/  211]    Overall Loss 0.064783    Objective Loss 0.064783                                        LR 0.100000    Time 0.024571    
2022-01-25 18:27:30,227 - Epoch: [46][  200/  211]    Overall Loss 0.064739    Objective Loss 0.064739                                        LR 0.100000    Time 0.024671    
2022-01-25 18:27:30,474 - Epoch: [46][  210/  211]    Overall Loss 0.064746    Objective Loss 0.064746    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.024667    
2022-01-25 18:27:30,519 - Epoch: [46][  211/  211]    Overall Loss 0.064664    Objective Loss 0.064664    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.024764    
2022-01-25 18:27:30,575 - --- validate (epoch=46)-----------
2022-01-25 18:27:30,576 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:31,046 - Epoch: [46][   10/   24]    Loss 0.055164    Top1 98.671875    Top5 100.000000    
2022-01-25 18:27:31,288 - Epoch: [46][   20/   24]    Loss 0.066055    Top1 98.417969    Top5 99.980469    
2022-01-25 18:27:31,390 - Epoch: [46][   24/   24]    Loss 0.067889    Top1 98.333333    Top5 99.983333    
2022-01-25 18:27:31,445 - ==> Top1: 98.333    Top5: 99.983    Loss: 0.068

2022-01-25 18:27:31,446 - ==> Confusion:
[[601   0   0   0   0   0   2   1   0   1]
 [  0 683   0   0   0   0   0   5   0   0]
 [  0   2 563   0   0   0   2  12   5   2]
 [  0   0   2 577   1   0   0   2   1   0]
 [  3   1   0   0 549   0   1   2   2   7]
 [  0   0   0   2   0 509   2   2   2   1]
 [  1   2   0   0   2   1 623   0   2   0]
 [  0   3   2   0   2   0   0 618   0   0]
 [  0   0   0   1   2   2   2   1 575   1]
 [  0   2   0   1   4   0   0   3   3 602]]

2022-01-25 18:27:31,448 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:27:31,448 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:31,454 - 

2022-01-25 18:27:31,455 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:32,150 - Epoch: [47][   10/  211]    Overall Loss 0.069432    Objective Loss 0.069432                                        LR 0.100000    Time 0.069497    
2022-01-25 18:27:32,363 - Epoch: [47][   20/  211]    Overall Loss 0.064472    Objective Loss 0.064472                                        LR 0.100000    Time 0.045382    
2022-01-25 18:27:32,590 - Epoch: [47][   30/  211]    Overall Loss 0.059792    Objective Loss 0.059792                                        LR 0.100000    Time 0.037802    
2022-01-25 18:27:32,801 - Epoch: [47][   40/  211]    Overall Loss 0.062438    Objective Loss 0.062438                                        LR 0.100000    Time 0.033610    
2022-01-25 18:27:33,027 - Epoch: [47][   50/  211]    Overall Loss 0.065024    Objective Loss 0.065024                                        LR 0.100000    Time 0.031415    
2022-01-25 18:27:33,240 - Epoch: [47][   60/  211]    Overall Loss 0.063623    Objective Loss 0.063623                                        LR 0.100000    Time 0.029713    
2022-01-25 18:27:33,468 - Epoch: [47][   70/  211]    Overall Loss 0.064087    Objective Loss 0.064087                                        LR 0.100000    Time 0.028727    
2022-01-25 18:27:33,686 - Epoch: [47][   80/  211]    Overall Loss 0.062822    Objective Loss 0.062822                                        LR 0.100000    Time 0.027856    
2022-01-25 18:27:33,922 - Epoch: [47][   90/  211]    Overall Loss 0.063115    Objective Loss 0.063115                                        LR 0.100000    Time 0.027381    
2022-01-25 18:27:34,142 - Epoch: [47][  100/  211]    Overall Loss 0.062451    Objective Loss 0.062451                                        LR 0.100000    Time 0.026833    
2022-01-25 18:27:34,385 - Epoch: [47][  110/  211]    Overall Loss 0.062348    Objective Loss 0.062348                                        LR 0.100000    Time 0.026604    
2022-01-25 18:27:34,623 - Epoch: [47][  120/  211]    Overall Loss 0.062769    Objective Loss 0.062769                                        LR 0.100000    Time 0.026368    
2022-01-25 18:27:34,836 - Epoch: [47][  130/  211]    Overall Loss 0.062738    Objective Loss 0.062738                                        LR 0.100000    Time 0.025972    
2022-01-25 18:27:35,062 - Epoch: [47][  140/  211]    Overall Loss 0.063273    Objective Loss 0.063273                                        LR 0.100000    Time 0.025732    
2022-01-25 18:27:35,279 - Epoch: [47][  150/  211]    Overall Loss 0.064372    Objective Loss 0.064372                                        LR 0.100000    Time 0.025457    
2022-01-25 18:27:35,504 - Epoch: [47][  160/  211]    Overall Loss 0.065514    Objective Loss 0.065514                                        LR 0.100000    Time 0.025271    
2022-01-25 18:27:35,720 - Epoch: [47][  170/  211]    Overall Loss 0.065639    Objective Loss 0.065639                                        LR 0.100000    Time 0.025054    
2022-01-25 18:27:35,946 - Epoch: [47][  180/  211]    Overall Loss 0.066078    Objective Loss 0.066078                                        LR 0.100000    Time 0.024913    
2022-01-25 18:27:36,156 - Epoch: [47][  190/  211]    Overall Loss 0.066926    Objective Loss 0.066926                                        LR 0.100000    Time 0.024708    
2022-01-25 18:27:36,381 - Epoch: [47][  200/  211]    Overall Loss 0.067147    Objective Loss 0.067147                                        LR 0.100000    Time 0.024593    
2022-01-25 18:27:36,600 - Epoch: [47][  210/  211]    Overall Loss 0.067412    Objective Loss 0.067412    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.024465    
2022-01-25 18:27:36,619 - Epoch: [47][  211/  211]    Overall Loss 0.067455    Objective Loss 0.067455    Top1 97.379032    Top5 100.000000    LR 0.100000    Time 0.024440    
2022-01-25 18:27:36,701 - --- validate (epoch=47)-----------
2022-01-25 18:27:36,702 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:37,221 - Epoch: [47][   10/   24]    Loss 0.062365    Top1 98.359375    Top5 100.000000    
2022-01-25 18:27:37,445 - Epoch: [47][   20/   24]    Loss 0.072314    Top1 98.105469    Top5 99.980469    
2022-01-25 18:27:37,527 - Epoch: [47][   24/   24]    Loss 0.070936    Top1 98.150000    Top5 99.983333    
2022-01-25 18:27:37,601 - ==> Top1: 98.150    Top5: 99.983    Loss: 0.071

2022-01-25 18:27:37,602 - ==> Confusion:
[[596   0   1   1   0   4   1   0   1   1]
 [  0 682   1   0   0   1   0   4   0   0]
 [  0   1 571   6   0   0   1   4   3   0]
 [  0   0   3 576   1   1   0   1   1   0]
 [  0   0   1   0 546   1   0   2   1  14]
 [  0   0   0   1   0 513   1   0   3   0]
 [  1   0   0   0   0   9 618   0   3   0]
 [  1   2   4   1   0   0   0 615   1   1]
 [  1   0   0   2   0   3   3   0 574   1]
 [  1   2   0   1   3   3   0   2   5 598]]

2022-01-25 18:27:37,605 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:27:37,605 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:37,613 - 

2022-01-25 18:27:37,613 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:38,328 - Epoch: [48][   10/  211]    Overall Loss 0.073216    Objective Loss 0.073216                                        LR 0.100000    Time 0.071474    
2022-01-25 18:27:38,538 - Epoch: [48][   20/  211]    Overall Loss 0.068305    Objective Loss 0.068305                                        LR 0.100000    Time 0.046184    
2022-01-25 18:27:38,756 - Epoch: [48][   30/  211]    Overall Loss 0.068659    Objective Loss 0.068659                                        LR 0.100000    Time 0.038062    
2022-01-25 18:27:38,962 - Epoch: [48][   40/  211]    Overall Loss 0.067821    Objective Loss 0.067821                                        LR 0.100000    Time 0.033674    
2022-01-25 18:27:39,188 - Epoch: [48][   50/  211]    Overall Loss 0.067155    Objective Loss 0.067155                                        LR 0.100000    Time 0.031472    
2022-01-25 18:27:39,408 - Epoch: [48][   60/  211]    Overall Loss 0.065757    Objective Loss 0.065757                                        LR 0.100000    Time 0.029879    
2022-01-25 18:27:39,656 - Epoch: [48][   70/  211]    Overall Loss 0.065364    Objective Loss 0.065364                                        LR 0.100000    Time 0.029145    
2022-01-25 18:27:39,907 - Epoch: [48][   80/  211]    Overall Loss 0.065864    Objective Loss 0.065864                                        LR 0.100000    Time 0.028642    
2022-01-25 18:27:40,186 - Epoch: [48][   90/  211]    Overall Loss 0.065169    Objective Loss 0.065169                                        LR 0.100000    Time 0.028557    
2022-01-25 18:27:40,438 - Epoch: [48][  100/  211]    Overall Loss 0.065336    Objective Loss 0.065336                                        LR 0.100000    Time 0.028213    
2022-01-25 18:27:40,724 - Epoch: [48][  110/  211]    Overall Loss 0.064441    Objective Loss 0.064441                                        LR 0.100000    Time 0.028249    
2022-01-25 18:27:40,971 - Epoch: [48][  120/  211]    Overall Loss 0.064546    Objective Loss 0.064546                                        LR 0.100000    Time 0.027948    
2022-01-25 18:27:41,252 - Epoch: [48][  130/  211]    Overall Loss 0.064000    Objective Loss 0.064000                                        LR 0.100000    Time 0.027957    
2022-01-25 18:27:41,497 - Epoch: [48][  140/  211]    Overall Loss 0.063752    Objective Loss 0.063752                                        LR 0.100000    Time 0.027710    
2022-01-25 18:27:41,779 - Epoch: [48][  150/  211]    Overall Loss 0.063856    Objective Loss 0.063856                                        LR 0.100000    Time 0.027738    
2022-01-25 18:27:42,032 - Epoch: [48][  160/  211]    Overall Loss 0.063968    Objective Loss 0.063968                                        LR 0.100000    Time 0.027582    
2022-01-25 18:27:42,316 - Epoch: [48][  170/  211]    Overall Loss 0.064041    Objective Loss 0.064041                                        LR 0.100000    Time 0.027626    
2022-01-25 18:27:42,566 - Epoch: [48][  180/  211]    Overall Loss 0.064364    Objective Loss 0.064364                                        LR 0.100000    Time 0.027477    
2022-01-25 18:27:42,848 - Epoch: [48][  190/  211]    Overall Loss 0.064234    Objective Loss 0.064234                                        LR 0.100000    Time 0.027515    
2022-01-25 18:27:43,097 - Epoch: [48][  200/  211]    Overall Loss 0.064664    Objective Loss 0.064664                                        LR 0.100000    Time 0.027383    
2022-01-25 18:27:43,381 - Epoch: [48][  210/  211]    Overall Loss 0.064866    Objective Loss 0.064866    Top1 96.484375    Top5 100.000000    LR 0.100000    Time 0.027430    
2022-01-25 18:27:43,399 - Epoch: [48][  211/  211]    Overall Loss 0.064794    Objective Loss 0.064794    Top1 97.782258    Top5 100.000000    LR 0.100000    Time 0.027387    
2022-01-25 18:27:43,457 - --- validate (epoch=48)-----------
2022-01-25 18:27:43,457 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:43,933 - Epoch: [48][   10/   24]    Loss 0.070405    Top1 98.203125    Top5 99.960938    
2022-01-25 18:27:44,133 - Epoch: [48][   20/   24]    Loss 0.067396    Top1 98.320312    Top5 99.960938    
2022-01-25 18:27:44,217 - Epoch: [48][   24/   24]    Loss 0.066289    Top1 98.350000    Top5 99.966667    
2022-01-25 18:27:44,279 - ==> Top1: 98.350    Top5: 99.967    Loss: 0.066

2022-01-25 18:27:44,279 - ==> Confusion:
[[603   0   1   0   0   0   0   1   0   0]
 [  0 682   2   1   0   1   0   2   0   0]
 [  1   0 583   0   0   0   0   0   2   0]
 [  1   0   1 576   0   3   0   0   2   0]
 [  0   0   0   0 557   0   0   3   0   5]
 [  0   0   0   6   0 505   5   0   2   0]
 [  4   1   0   0   4   1 619   0   2   0]
 [  0   3   3   3   1   0   0 614   0   1]
 [  2   0   3   1   2   0   3   1 572   0]
 [  2   1   2   3   6   3   0   3   6 589]]

2022-01-25 18:27:44,281 - ==> Best [Top1: 98.550   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 39]
2022-01-25 18:27:44,281 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:44,286 - 

2022-01-25 18:27:44,287 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:44,845 - Epoch: [49][   10/  211]    Overall Loss 0.074649    Objective Loss 0.074649                                        LR 0.100000    Time 0.055784    
2022-01-25 18:27:45,057 - Epoch: [49][   20/  211]    Overall Loss 0.069261    Objective Loss 0.069261                                        LR 0.100000    Time 0.038454    
2022-01-25 18:27:45,285 - Epoch: [49][   30/  211]    Overall Loss 0.067724    Objective Loss 0.067724                                        LR 0.100000    Time 0.033245    
2022-01-25 18:27:45,494 - Epoch: [49][   40/  211]    Overall Loss 0.067423    Objective Loss 0.067423                                        LR 0.100000    Time 0.030145    
2022-01-25 18:27:45,726 - Epoch: [49][   50/  211]    Overall Loss 0.066076    Objective Loss 0.066076                                        LR 0.100000    Time 0.028739    
2022-01-25 18:27:45,941 - Epoch: [49][   60/  211]    Overall Loss 0.066056    Objective Loss 0.066056                                        LR 0.100000    Time 0.027533    
2022-01-25 18:27:46,161 - Epoch: [49][   70/  211]    Overall Loss 0.066894    Objective Loss 0.066894                                        LR 0.100000    Time 0.026741    
2022-01-25 18:27:46,378 - Epoch: [49][   80/  211]    Overall Loss 0.066322    Objective Loss 0.066322                                        LR 0.100000    Time 0.026104    
2022-01-25 18:27:46,597 - Epoch: [49][   90/  211]    Overall Loss 0.066397    Objective Loss 0.066397                                        LR 0.100000    Time 0.025629    
2022-01-25 18:27:46,808 - Epoch: [49][  100/  211]    Overall Loss 0.066954    Objective Loss 0.066954                                        LR 0.100000    Time 0.025177    
2022-01-25 18:27:47,027 - Epoch: [49][  110/  211]    Overall Loss 0.066518    Objective Loss 0.066518                                        LR 0.100000    Time 0.024876    
2022-01-25 18:27:47,240 - Epoch: [49][  120/  211]    Overall Loss 0.066584    Objective Loss 0.066584                                        LR 0.100000    Time 0.024576    
2022-01-25 18:27:47,471 - Epoch: [49][  130/  211]    Overall Loss 0.065870    Objective Loss 0.065870                                        LR 0.100000    Time 0.024455    
2022-01-25 18:27:47,751 - Epoch: [49][  140/  211]    Overall Loss 0.065225    Objective Loss 0.065225                                        LR 0.100000    Time 0.024710    
2022-01-25 18:27:47,997 - Epoch: [49][  150/  211]    Overall Loss 0.065110    Objective Loss 0.065110                                        LR 0.100000    Time 0.024698    
2022-01-25 18:27:48,291 - Epoch: [49][  160/  211]    Overall Loss 0.064978    Objective Loss 0.064978                                        LR 0.100000    Time 0.024992    
2022-01-25 18:27:48,531 - Epoch: [49][  170/  211]    Overall Loss 0.064740    Objective Loss 0.064740                                        LR 0.100000    Time 0.024929    
2022-01-25 18:27:48,814 - Epoch: [49][  180/  211]    Overall Loss 0.064356    Objective Loss 0.064356                                        LR 0.100000    Time 0.025115    
2022-01-25 18:27:49,062 - Epoch: [49][  190/  211]    Overall Loss 0.063555    Objective Loss 0.063555                                        LR 0.100000    Time 0.025095    
2022-01-25 18:27:49,344 - Epoch: [49][  200/  211]    Overall Loss 0.063516    Objective Loss 0.063516                                        LR 0.100000    Time 0.025249    
2022-01-25 18:27:49,586 - Epoch: [49][  210/  211]    Overall Loss 0.063692    Objective Loss 0.063692    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.025201    
2022-01-25 18:27:49,639 - Epoch: [49][  211/  211]    Overall Loss 0.063611    Objective Loss 0.063611    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.025331    
2022-01-25 18:27:49,714 - --- validate (epoch=49)-----------
2022-01-25 18:27:49,715 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:50,232 - Epoch: [49][   10/   24]    Loss 0.059872    Top1 98.515625    Top5 100.000000    
2022-01-25 18:27:50,467 - Epoch: [49][   20/   24]    Loss 0.055166    Top1 98.730469    Top5 100.000000    
2022-01-25 18:27:50,571 - Epoch: [49][   24/   24]    Loss 0.058337    Top1 98.616667    Top5 100.000000    
2022-01-25 18:27:50,629 - ==> Top1: 98.617    Top5: 100.000    Loss: 0.058

2022-01-25 18:27:50,630 - ==> Confusion:
[[600   0   0   0   0   0   2   0   2   1]
 [  0 681   1   0   0   0   1   5   0   0]
 [  1   0 582   0   0   1   0   1   1   0]
 [  0   1   6 573   0   2   0   0   1   0]
 [  0   1   1   0 555   0   1   0   1   6]
 [  0   0   0   2   0 507   3   0   6   0]
 [  2   1   0   0   2   0 626   0   0   0]
 [  1   0   3   0   0   0   0 620   1   0]
 [  0   1   0   1   2   0   2   0 576   2]
 [  1   1   0   0   4   1   0   5   6 597]]

2022-01-25 18:27:50,633 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:27:50,633 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:50,643 - 

2022-01-25 18:27:50,643 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:51,336 - Epoch: [50][   10/  211]    Overall Loss 0.076667    Objective Loss 0.076667                                        LR 0.100000    Time 0.069217    
2022-01-25 18:27:51,559 - Epoch: [50][   20/  211]    Overall Loss 0.076083    Objective Loss 0.076083                                        LR 0.100000    Time 0.045735    
2022-01-25 18:27:51,799 - Epoch: [50][   30/  211]    Overall Loss 0.074033    Objective Loss 0.074033                                        LR 0.100000    Time 0.038463    
2022-01-25 18:27:52,025 - Epoch: [50][   40/  211]    Overall Loss 0.071060    Objective Loss 0.071060                                        LR 0.100000    Time 0.034496    
2022-01-25 18:27:52,264 - Epoch: [50][   50/  211]    Overall Loss 0.069241    Objective Loss 0.069241                                        LR 0.100000    Time 0.032369    
2022-01-25 18:27:52,490 - Epoch: [50][   60/  211]    Overall Loss 0.069078    Objective Loss 0.069078                                        LR 0.100000    Time 0.030735    
2022-01-25 18:27:52,731 - Epoch: [50][   70/  211]    Overall Loss 0.068105    Objective Loss 0.068105                                        LR 0.100000    Time 0.029793    
2022-01-25 18:27:52,964 - Epoch: [50][   80/  211]    Overall Loss 0.067796    Objective Loss 0.067796                                        LR 0.100000    Time 0.028972    
2022-01-25 18:27:53,192 - Epoch: [50][   90/  211]    Overall Loss 0.066481    Objective Loss 0.066481                                        LR 0.100000    Time 0.028282    
2022-01-25 18:27:53,407 - Epoch: [50][  100/  211]    Overall Loss 0.065412    Objective Loss 0.065412                                        LR 0.100000    Time 0.027596    
2022-01-25 18:27:53,631 - Epoch: [50][  110/  211]    Overall Loss 0.065058    Objective Loss 0.065058                                        LR 0.100000    Time 0.027124    
2022-01-25 18:27:53,881 - Epoch: [50][  120/  211]    Overall Loss 0.064918    Objective Loss 0.064918                                        LR 0.100000    Time 0.026939    
2022-01-25 18:27:54,158 - Epoch: [50][  130/  211]    Overall Loss 0.064189    Objective Loss 0.064189                                        LR 0.100000    Time 0.026998    
2022-01-25 18:27:54,408 - Epoch: [50][  140/  211]    Overall Loss 0.063657    Objective Loss 0.063657                                        LR 0.100000    Time 0.026856    
2022-01-25 18:27:54,696 - Epoch: [50][  150/  211]    Overall Loss 0.064362    Objective Loss 0.064362                                        LR 0.100000    Time 0.026982    
2022-01-25 18:27:54,946 - Epoch: [50][  160/  211]    Overall Loss 0.064377    Objective Loss 0.064377                                        LR 0.100000    Time 0.026852    
2022-01-25 18:27:55,228 - Epoch: [50][  170/  211]    Overall Loss 0.064566    Objective Loss 0.064566                                        LR 0.100000    Time 0.026930    
2022-01-25 18:27:55,482 - Epoch: [50][  180/  211]    Overall Loss 0.064515    Objective Loss 0.064515                                        LR 0.100000    Time 0.026846    
2022-01-25 18:27:55,769 - Epoch: [50][  190/  211]    Overall Loss 0.064626    Objective Loss 0.064626                                        LR 0.100000    Time 0.026940    
2022-01-25 18:27:56,020 - Epoch: [50][  200/  211]    Overall Loss 0.064578    Objective Loss 0.064578                                        LR 0.100000    Time 0.026846    
2022-01-25 18:27:56,299 - Epoch: [50][  210/  211]    Overall Loss 0.064433    Objective Loss 0.064433    Top1 97.265625    Top5 99.609375    LR 0.100000    Time 0.026893    
2022-01-25 18:27:56,318 - Epoch: [50][  211/  211]    Overall Loss 0.064380    Objective Loss 0.064380    Top1 97.983871    Top5 99.798387    LR 0.100000    Time 0.026858    
2022-01-25 18:27:56,374 - --- validate (epoch=50)-----------
2022-01-25 18:27:56,374 - 6000 samples (256 per mini-batch)
2022-01-25 18:27:56,845 - Epoch: [50][   10/   24]    Loss 0.067857    Top1 98.359375    Top5 99.921875    
2022-01-25 18:27:57,047 - Epoch: [50][   20/   24]    Loss 0.067428    Top1 98.457031    Top5 99.960938    
2022-01-25 18:27:57,131 - Epoch: [50][   24/   24]    Loss 0.066657    Top1 98.450000    Top5 99.950000    
2022-01-25 18:27:57,190 - ==> Top1: 98.450    Top5: 99.950    Loss: 0.067

2022-01-25 18:27:57,191 - ==> Confusion:
[[602   0   2   0   0   0   1   0   0   0]
 [  0 684   0   0   0   0   0   4   0   0]
 [  0   0 582   1   0   0   1   2   0   0]
 [  0   0   1 578   0   1   0   3   0   0]
 [  0   1   3   0 553   1   0   4   0   3]
 [  0   1   0   3   0 511   1   0   2   0]
 [  2   1   2   0   4   5 614   0   3   0]
 [  0   0   3   0   0   0   0 622   0   0]
 [  0   0   4   3   3   2   2   2 567   1]
 [  2   2   0   2   5   2   0   6   2 594]]

2022-01-25 18:27:57,193 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:27:57,193 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:27:57,199 - 

2022-01-25 18:27:57,200 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:27:57,943 - Epoch: [51][   10/  211]    Overall Loss 0.070104    Objective Loss 0.070104                                        LR 0.100000    Time 0.074243    
2022-01-25 18:27:58,196 - Epoch: [51][   20/  211]    Overall Loss 0.064887    Objective Loss 0.064887                                        LR 0.100000    Time 0.049767    
2022-01-25 18:27:58,470 - Epoch: [51][   30/  211]    Overall Loss 0.063443    Objective Loss 0.063443                                        LR 0.100000    Time 0.042301    
2022-01-25 18:27:58,715 - Epoch: [51][   40/  211]    Overall Loss 0.063754    Objective Loss 0.063754                                        LR 0.100000    Time 0.037851    
2022-01-25 18:27:58,996 - Epoch: [51][   50/  211]    Overall Loss 0.062033    Objective Loss 0.062033                                        LR 0.100000    Time 0.035890    
2022-01-25 18:27:59,244 - Epoch: [51][   60/  211]    Overall Loss 0.061066    Objective Loss 0.061066                                        LR 0.100000    Time 0.034042    
2022-01-25 18:27:59,533 - Epoch: [51][   70/  211]    Overall Loss 0.061195    Objective Loss 0.061195                                        LR 0.100000    Time 0.033295    
2022-01-25 18:27:59,781 - Epoch: [51][   80/  211]    Overall Loss 0.061839    Objective Loss 0.061839                                        LR 0.100000    Time 0.032235    
2022-01-25 18:28:00,062 - Epoch: [51][   90/  211]    Overall Loss 0.062532    Objective Loss 0.062532                                        LR 0.100000    Time 0.031771    
2022-01-25 18:28:00,316 - Epoch: [51][  100/  211]    Overall Loss 0.062109    Objective Loss 0.062109                                        LR 0.100000    Time 0.031127    
2022-01-25 18:28:00,599 - Epoch: [51][  110/  211]    Overall Loss 0.062351    Objective Loss 0.062351                                        LR 0.100000    Time 0.030868    
2022-01-25 18:28:00,847 - Epoch: [51][  120/  211]    Overall Loss 0.061851    Objective Loss 0.061851                                        LR 0.100000    Time 0.030359    
2022-01-25 18:28:01,126 - Epoch: [51][  130/  211]    Overall Loss 0.062958    Objective Loss 0.062958                                        LR 0.100000    Time 0.030166    
2022-01-25 18:28:01,382 - Epoch: [51][  140/  211]    Overall Loss 0.063286    Objective Loss 0.063286                                        LR 0.100000    Time 0.029839    
2022-01-25 18:28:01,665 - Epoch: [51][  150/  211]    Overall Loss 0.063604    Objective Loss 0.063604                                        LR 0.100000    Time 0.029735    
2022-01-25 18:28:01,906 - Epoch: [51][  160/  211]    Overall Loss 0.063792    Objective Loss 0.063792                                        LR 0.100000    Time 0.029375    
2022-01-25 18:28:02,188 - Epoch: [51][  170/  211]    Overall Loss 0.063965    Objective Loss 0.063965                                        LR 0.100000    Time 0.029309    
2022-01-25 18:28:02,443 - Epoch: [51][  180/  211]    Overall Loss 0.063748    Objective Loss 0.063748                                        LR 0.100000    Time 0.029092    
2022-01-25 18:28:02,723 - Epoch: [51][  190/  211]    Overall Loss 0.063536    Objective Loss 0.063536                                        LR 0.100000    Time 0.029034    
2022-01-25 18:28:02,974 - Epoch: [51][  200/  211]    Overall Loss 0.063805    Objective Loss 0.063805                                        LR 0.100000    Time 0.028836    
2022-01-25 18:28:03,251 - Epoch: [51][  210/  211]    Overall Loss 0.063997    Objective Loss 0.063997    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.028778    
2022-01-25 18:28:03,272 - Epoch: [51][  211/  211]    Overall Loss 0.063914    Objective Loss 0.063914    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.028741    
2022-01-25 18:28:03,328 - --- validate (epoch=51)-----------
2022-01-25 18:28:03,328 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:03,802 - Epoch: [51][   10/   24]    Loss 0.072407    Top1 98.398438    Top5 100.000000    
2022-01-25 18:28:04,078 - Epoch: [51][   20/   24]    Loss 0.067997    Top1 98.339844    Top5 100.000000    
2022-01-25 18:28:04,165 - Epoch: [51][   24/   24]    Loss 0.066059    Top1 98.383333    Top5 99.983333    
2022-01-25 18:28:04,224 - ==> Top1: 98.383    Top5: 99.983    Loss: 0.066

2022-01-25 18:28:04,225 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 685   0   0   0   0   0   3   0   0]
 [  1   0 567   1   0   0   0  11   1   5]
 [  1   0   2 571   0   3   0   4   2   0]
 [  0   1   0   0 556   0   0   0   1   7]
 [  5   1   0   1   0 501   7   0   3   0]
 [  3   3   0   0   4   0 620   0   1   0]
 [  0   1   0   0   2   0   0 622   0   0]
 [  1   0   0   0   1   1   1   1 577   2]
 [  2   1   0   0   5   0   0   5   2 600]]

2022-01-25 18:28:04,227 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:28:04,228 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:04,235 - 

2022-01-25 18:28:04,236 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:04,786 - Epoch: [52][   10/  211]    Overall Loss 0.063942    Objective Loss 0.063942                                        LR 0.100000    Time 0.054965    
2022-01-25 18:28:04,995 - Epoch: [52][   20/  211]    Overall Loss 0.060508    Objective Loss 0.060508                                        LR 0.100000    Time 0.037912    
2022-01-25 18:28:05,211 - Epoch: [52][   30/  211]    Overall Loss 0.059855    Objective Loss 0.059855                                        LR 0.100000    Time 0.032462    
2022-01-25 18:28:05,415 - Epoch: [52][   40/  211]    Overall Loss 0.060156    Objective Loss 0.060156                                        LR 0.100000    Time 0.029429    
2022-01-25 18:28:05,636 - Epoch: [52][   50/  211]    Overall Loss 0.061655    Objective Loss 0.061655                                        LR 0.100000    Time 0.027956    
2022-01-25 18:28:05,842 - Epoch: [52][   60/  211]    Overall Loss 0.061110    Objective Loss 0.061110                                        LR 0.100000    Time 0.026724    
2022-01-25 18:28:06,073 - Epoch: [52][   70/  211]    Overall Loss 0.060083    Objective Loss 0.060083                                        LR 0.100000    Time 0.026210    
2022-01-25 18:28:06,279 - Epoch: [52][   80/  211]    Overall Loss 0.060216    Objective Loss 0.060216                                        LR 0.100000    Time 0.025507    
2022-01-25 18:28:06,499 - Epoch: [52][   90/  211]    Overall Loss 0.060623    Objective Loss 0.060623                                        LR 0.100000    Time 0.025109    
2022-01-25 18:28:06,718 - Epoch: [52][  100/  211]    Overall Loss 0.060191    Objective Loss 0.060191                                        LR 0.100000    Time 0.024783    
2022-01-25 18:28:06,935 - Epoch: [52][  110/  211]    Overall Loss 0.059932    Objective Loss 0.059932                                        LR 0.100000    Time 0.024501    
2022-01-25 18:28:07,163 - Epoch: [52][  120/  211]    Overall Loss 0.059342    Objective Loss 0.059342                                        LR 0.100000    Time 0.024358    
2022-01-25 18:28:07,383 - Epoch: [52][  130/  211]    Overall Loss 0.059440    Objective Loss 0.059440                                        LR 0.100000    Time 0.024176    
2022-01-25 18:28:07,595 - Epoch: [52][  140/  211]    Overall Loss 0.060601    Objective Loss 0.060601                                        LR 0.100000    Time 0.023958    
2022-01-25 18:28:07,812 - Epoch: [52][  150/  211]    Overall Loss 0.061950    Objective Loss 0.061950                                        LR 0.100000    Time 0.023806    
2022-01-25 18:28:08,035 - Epoch: [52][  160/  211]    Overall Loss 0.062003    Objective Loss 0.062003                                        LR 0.100000    Time 0.023707    
2022-01-25 18:28:08,246 - Epoch: [52][  170/  211]    Overall Loss 0.061972    Objective Loss 0.061972                                        LR 0.100000    Time 0.023555    
2022-01-25 18:28:08,478 - Epoch: [52][  180/  211]    Overall Loss 0.062182    Objective Loss 0.062182                                        LR 0.100000    Time 0.023533    
2022-01-25 18:28:08,688 - Epoch: [52][  190/  211]    Overall Loss 0.061704    Objective Loss 0.061704                                        LR 0.100000    Time 0.023400    
2022-01-25 18:28:08,916 - Epoch: [52][  200/  211]    Overall Loss 0.061722    Objective Loss 0.061722                                        LR 0.100000    Time 0.023366    
2022-01-25 18:28:09,131 - Epoch: [52][  210/  211]    Overall Loss 0.061501    Objective Loss 0.061501    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.023274    
2022-01-25 18:28:09,156 - Epoch: [52][  211/  211]    Overall Loss 0.061636    Objective Loss 0.061636    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.023285    
2022-01-25 18:28:09,229 - --- validate (epoch=52)-----------
2022-01-25 18:28:09,230 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:09,749 - Epoch: [52][   10/   24]    Loss 0.061470    Top1 98.437500    Top5 100.000000    
2022-01-25 18:28:09,982 - Epoch: [52][   20/   24]    Loss 0.060040    Top1 98.476562    Top5 100.000000    
2022-01-25 18:28:10,083 - Epoch: [52][   24/   24]    Loss 0.059438    Top1 98.500000    Top5 100.000000    
2022-01-25 18:28:10,140 - ==> Top1: 98.500    Top5: 100.000    Loss: 0.059

2022-01-25 18:28:10,141 - ==> Confusion:
[[597   0   1   0   0   1   3   0   1   2]
 [  0 685   1   0   0   1   1   0   0   0]
 [  1   0 577   3   0   0   0   2   2   1]
 [  0   1   0 578   0   1   0   0   3   0]
 [  0   0   4   0 544   1   1   3   2  10]
 [  0   0   0   1   0 514   2   0   0   1]
 [  2   1   0   0   1   3 622   0   2   0]
 [  0   0   4   1   0   0   0 619   0   1]
 [  0   0   0   2   0   2   4   0 575   1]
 [  0   2   1   3   1   2   0   2   5 599]]

2022-01-25 18:28:10,144 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:28:10,144 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:10,153 - 

2022-01-25 18:28:10,153 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:10,870 - Epoch: [53][   10/  211]    Overall Loss 0.062135    Objective Loss 0.062135                                        LR 0.100000    Time 0.071569    
2022-01-25 18:28:11,085 - Epoch: [53][   20/  211]    Overall Loss 0.056766    Objective Loss 0.056766                                        LR 0.100000    Time 0.046537    
2022-01-25 18:28:11,299 - Epoch: [53][   30/  211]    Overall Loss 0.061108    Objective Loss 0.061108                                        LR 0.100000    Time 0.038145    
2022-01-25 18:28:11,508 - Epoch: [53][   40/  211]    Overall Loss 0.059896    Objective Loss 0.059896                                        LR 0.100000    Time 0.033814    
2022-01-25 18:28:11,729 - Epoch: [53][   50/  211]    Overall Loss 0.060461    Objective Loss 0.060461                                        LR 0.100000    Time 0.031478    
2022-01-25 18:28:11,938 - Epoch: [53][   60/  211]    Overall Loss 0.058831    Objective Loss 0.058831                                        LR 0.100000    Time 0.029701    
2022-01-25 18:28:12,168 - Epoch: [53][   70/  211]    Overall Loss 0.059595    Objective Loss 0.059595                                        LR 0.100000    Time 0.028739    
2022-01-25 18:28:12,375 - Epoch: [53][   80/  211]    Overall Loss 0.059924    Objective Loss 0.059924                                        LR 0.100000    Time 0.027737    
2022-01-25 18:28:12,601 - Epoch: [53][   90/  211]    Overall Loss 0.060241    Objective Loss 0.060241                                        LR 0.100000    Time 0.027165    
2022-01-25 18:28:12,814 - Epoch: [53][  100/  211]    Overall Loss 0.060749    Objective Loss 0.060749                                        LR 0.100000    Time 0.026570    
2022-01-25 18:28:13,039 - Epoch: [53][  110/  211]    Overall Loss 0.060508    Objective Loss 0.060508                                        LR 0.100000    Time 0.026201    
2022-01-25 18:28:13,251 - Epoch: [53][  120/  211]    Overall Loss 0.060427    Objective Loss 0.060427                                        LR 0.100000    Time 0.025780    
2022-01-25 18:28:13,480 - Epoch: [53][  130/  211]    Overall Loss 0.060481    Objective Loss 0.060481                                        LR 0.100000    Time 0.025555    
2022-01-25 18:28:13,689 - Epoch: [53][  140/  211]    Overall Loss 0.060849    Objective Loss 0.060849                                        LR 0.100000    Time 0.025218    
2022-01-25 18:28:13,910 - Epoch: [53][  150/  211]    Overall Loss 0.060841    Objective Loss 0.060841                                        LR 0.100000    Time 0.025009    
2022-01-25 18:28:14,125 - Epoch: [53][  160/  211]    Overall Loss 0.061153    Objective Loss 0.061153                                        LR 0.100000    Time 0.024787    
2022-01-25 18:28:14,343 - Epoch: [53][  170/  211]    Overall Loss 0.060985    Objective Loss 0.060985                                        LR 0.100000    Time 0.024610    
2022-01-25 18:28:14,568 - Epoch: [53][  180/  211]    Overall Loss 0.061170    Objective Loss 0.061170                                        LR 0.100000    Time 0.024492    
2022-01-25 18:28:14,784 - Epoch: [53][  190/  211]    Overall Loss 0.061258    Objective Loss 0.061258                                        LR 0.100000    Time 0.024338    
2022-01-25 18:28:15,007 - Epoch: [53][  200/  211]    Overall Loss 0.061204    Objective Loss 0.061204                                        LR 0.100000    Time 0.024232    
2022-01-25 18:28:15,221 - Epoch: [53][  210/  211]    Overall Loss 0.061351    Objective Loss 0.061351    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.024093    
2022-01-25 18:28:15,247 - Epoch: [53][  211/  211]    Overall Loss 0.061376    Objective Loss 0.061376    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.024105    
2022-01-25 18:28:15,321 - --- validate (epoch=53)-----------
2022-01-25 18:28:15,322 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:15,841 - Epoch: [53][   10/   24]    Loss 0.063784    Top1 98.359375    Top5 99.960938    
2022-01-25 18:28:16,074 - Epoch: [53][   20/   24]    Loss 0.067558    Top1 98.261719    Top5 99.980469    
2022-01-25 18:28:16,179 - Epoch: [53][   24/   24]    Loss 0.065425    Top1 98.300000    Top5 99.983333    
2022-01-25 18:28:16,233 - ==> Top1: 98.300    Top5: 99.983    Loss: 0.065

2022-01-25 18:28:16,234 - ==> Confusion:
[[601   0   1   0   0   1   1   0   1   0]
 [  0 684   0   0   0   0   0   4   0   0]
 [  0   1 578   2   0   0   0   4   1   0]
 [  0   0   1 574   0   5   0   1   1   1]
 [  0   1   2   0 543   2   0   3   0  14]
 [  0   0   0   1   0 513   2   0   2   0]
 [  3   2   1   0   2  14 608   0   1   0]
 [  0   1   1   1   0   1   0 621   0   0]
 [  0   1   1   2   2   2   2   1 571   2]
 [  0   1   0   0   0   2   0   3   3 606]]

2022-01-25 18:28:16,236 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:28:16,236 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:16,241 - 

2022-01-25 18:28:16,241 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:16,986 - Epoch: [54][   10/  211]    Overall Loss 0.078090    Objective Loss 0.078090                                        LR 0.100000    Time 0.074387    
2022-01-25 18:28:17,234 - Epoch: [54][   20/  211]    Overall Loss 0.070994    Objective Loss 0.070994                                        LR 0.100000    Time 0.049578    
2022-01-25 18:28:17,514 - Epoch: [54][   30/  211]    Overall Loss 0.071795    Objective Loss 0.071795                                        LR 0.100000    Time 0.042394    
2022-01-25 18:28:17,759 - Epoch: [54][   40/  211]    Overall Loss 0.072025    Objective Loss 0.072025                                        LR 0.100000    Time 0.037912    
2022-01-25 18:28:18,040 - Epoch: [54][   50/  211]    Overall Loss 0.069806    Objective Loss 0.069806                                        LR 0.100000    Time 0.035929    
2022-01-25 18:28:18,289 - Epoch: [54][   60/  211]    Overall Loss 0.069330    Objective Loss 0.069330                                        LR 0.100000    Time 0.034099    
2022-01-25 18:28:18,577 - Epoch: [54][   70/  211]    Overall Loss 0.068989    Objective Loss 0.068989                                        LR 0.100000    Time 0.033337    
2022-01-25 18:28:18,822 - Epoch: [54][   80/  211]    Overall Loss 0.067129    Objective Loss 0.067129                                        LR 0.100000    Time 0.032226    
2022-01-25 18:28:19,106 - Epoch: [54][   90/  211]    Overall Loss 0.066619    Objective Loss 0.066619                                        LR 0.100000    Time 0.031797    
2022-01-25 18:28:19,356 - Epoch: [54][  100/  211]    Overall Loss 0.065698    Objective Loss 0.065698                                        LR 0.100000    Time 0.031107    
2022-01-25 18:28:19,645 - Epoch: [54][  110/  211]    Overall Loss 0.065570    Objective Loss 0.065570                                        LR 0.100000    Time 0.030908    
2022-01-25 18:28:19,894 - Epoch: [54][  120/  211]    Overall Loss 0.065175    Objective Loss 0.065175                                        LR 0.100000    Time 0.030401    
2022-01-25 18:28:20,173 - Epoch: [54][  130/  211]    Overall Loss 0.064987    Objective Loss 0.064987                                        LR 0.100000    Time 0.030208    
2022-01-25 18:28:20,425 - Epoch: [54][  140/  211]    Overall Loss 0.064837    Objective Loss 0.064837                                        LR 0.100000    Time 0.029849    
2022-01-25 18:28:20,711 - Epoch: [54][  150/  211]    Overall Loss 0.064361    Objective Loss 0.064361                                        LR 0.100000    Time 0.029762    
2022-01-25 18:28:20,957 - Epoch: [54][  160/  211]    Overall Loss 0.064322    Objective Loss 0.064322                                        LR 0.100000    Time 0.029438    
2022-01-25 18:28:21,236 - Epoch: [54][  170/  211]    Overall Loss 0.064192    Objective Loss 0.064192                                        LR 0.100000    Time 0.029342    
2022-01-25 18:28:21,486 - Epoch: [54][  180/  211]    Overall Loss 0.063748    Objective Loss 0.063748                                        LR 0.100000    Time 0.029098    
2022-01-25 18:28:21,766 - Epoch: [54][  190/  211]    Overall Loss 0.063768    Objective Loss 0.063768                                        LR 0.100000    Time 0.029042    
2022-01-25 18:28:22,021 - Epoch: [54][  200/  211]    Overall Loss 0.063923    Objective Loss 0.063923                                        LR 0.100000    Time 0.028861    
2022-01-25 18:28:22,299 - Epoch: [54][  210/  211]    Overall Loss 0.063643    Objective Loss 0.063643    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.028811    
2022-01-25 18:28:22,318 - Epoch: [54][  211/  211]    Overall Loss 0.063638    Objective Loss 0.063638    Top1 97.580645    Top5 100.000000    LR 0.100000    Time 0.028761    
2022-01-25 18:28:22,374 - --- validate (epoch=54)-----------
2022-01-25 18:28:22,374 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:22,845 - Epoch: [54][   10/   24]    Loss 0.059686    Top1 98.203125    Top5 99.960938    
2022-01-25 18:28:23,046 - Epoch: [54][   20/   24]    Loss 0.062073    Top1 98.398438    Top5 99.941406    
2022-01-25 18:28:23,129 - Epoch: [54][   24/   24]    Loss 0.063460    Top1 98.366667    Top5 99.933333    
2022-01-25 18:28:23,184 - ==> Top1: 98.367    Top5: 99.933    Loss: 0.063

2022-01-25 18:28:23,185 - ==> Confusion:
[[600   0   1   0   0   0   2   0   2   0]
 [  0 682   0   1   1   0   0   3   0   1]
 [  0   1 576   3   0   0   0   2   3   1]
 [  0   0   2 578   0   2   0   0   1   0]
 [  0   0   1   0 541   1   0   2   3  17]
 [  1   0   0   5   0 510   2   0   0   0]
 [  1   1   0   0   2   1 624   0   2   0]
 [  2   3   6   2   2   0   0 609   0   1]
 [  1   0   0   1   0   2   3   0 576   1]
 [  0   1   0   0   0   2   0   1   5 606]]

2022-01-25 18:28:23,187 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:28:23,187 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:23,193 - 

2022-01-25 18:28:23,193 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:23,748 - Epoch: [55][   10/  211]    Overall Loss 0.067612    Objective Loss 0.067612                                        LR 0.100000    Time 0.055361    
2022-01-25 18:28:23,960 - Epoch: [55][   20/  211]    Overall Loss 0.066679    Objective Loss 0.066679                                        LR 0.100000    Time 0.038275    
2022-01-25 18:28:24,182 - Epoch: [55][   30/  211]    Overall Loss 0.063981    Objective Loss 0.063981                                        LR 0.100000    Time 0.032921    
2022-01-25 18:28:24,398 - Epoch: [55][   40/  211]    Overall Loss 0.064142    Objective Loss 0.064142                                        LR 0.100000    Time 0.030076    
2022-01-25 18:28:24,629 - Epoch: [55][   50/  211]    Overall Loss 0.062968    Objective Loss 0.062968                                        LR 0.100000    Time 0.028674    
2022-01-25 18:28:24,879 - Epoch: [55][   60/  211]    Overall Loss 0.062032    Objective Loss 0.062032                                        LR 0.100000    Time 0.028046    
2022-01-25 18:28:25,167 - Epoch: [55][   70/  211]    Overall Loss 0.061150    Objective Loss 0.061150                                        LR 0.100000    Time 0.028154    
2022-01-25 18:28:25,414 - Epoch: [55][   80/  211]    Overall Loss 0.060850    Objective Loss 0.060850                                        LR 0.100000    Time 0.027714    
2022-01-25 18:28:25,692 - Epoch: [55][   90/  211]    Overall Loss 0.061058    Objective Loss 0.061058                                        LR 0.100000    Time 0.027726    
2022-01-25 18:28:25,942 - Epoch: [55][  100/  211]    Overall Loss 0.061796    Objective Loss 0.061796                                        LR 0.100000    Time 0.027444    
2022-01-25 18:28:26,230 - Epoch: [55][  110/  211]    Overall Loss 0.061766    Objective Loss 0.061766                                        LR 0.100000    Time 0.027567    
2022-01-25 18:28:26,480 - Epoch: [55][  120/  211]    Overall Loss 0.062011    Objective Loss 0.062011                                        LR 0.100000    Time 0.027353    
2022-01-25 18:28:26,757 - Epoch: [55][  130/  211]    Overall Loss 0.062968    Objective Loss 0.062968                                        LR 0.100000    Time 0.027378    
2022-01-25 18:28:27,005 - Epoch: [55][  140/  211]    Overall Loss 0.063311    Objective Loss 0.063311                                        LR 0.100000    Time 0.027186    
2022-01-25 18:28:27,285 - Epoch: [55][  150/  211]    Overall Loss 0.063600    Objective Loss 0.063600                                        LR 0.100000    Time 0.027242    
2022-01-25 18:28:27,541 - Epoch: [55][  160/  211]    Overall Loss 0.063150    Objective Loss 0.063150                                        LR 0.100000    Time 0.027135    
2022-01-25 18:28:27,818 - Epoch: [55][  170/  211]    Overall Loss 0.063176    Objective Loss 0.063176                                        LR 0.100000    Time 0.027169    
2022-01-25 18:28:28,064 - Epoch: [55][  180/  211]    Overall Loss 0.063635    Objective Loss 0.063635                                        LR 0.100000    Time 0.027023    
2022-01-25 18:28:28,345 - Epoch: [55][  190/  211]    Overall Loss 0.063419    Objective Loss 0.063419                                        LR 0.100000    Time 0.027076    
2022-01-25 18:28:28,592 - Epoch: [55][  200/  211]    Overall Loss 0.063628    Objective Loss 0.063628                                        LR 0.100000    Time 0.026956    
2022-01-25 18:28:28,868 - Epoch: [55][  210/  211]    Overall Loss 0.063836    Objective Loss 0.063836    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.026987    
2022-01-25 18:28:28,886 - Epoch: [55][  211/  211]    Overall Loss 0.063749    Objective Loss 0.063749    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.026941    
2022-01-25 18:28:28,941 - --- validate (epoch=55)-----------
2022-01-25 18:28:28,942 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:29,447 - Epoch: [55][   10/   24]    Loss 0.074973    Top1 97.773438    Top5 99.960938    
2022-01-25 18:28:29,642 - Epoch: [55][   20/   24]    Loss 0.065491    Top1 98.242188    Top5 99.980469    
2022-01-25 18:28:29,747 - Epoch: [55][   24/   24]    Loss 0.065124    Top1 98.283333    Top5 99.983333    
2022-01-25 18:28:29,804 - ==> Top1: 98.283    Top5: 99.983    Loss: 0.065

2022-01-25 18:28:29,805 - ==> Confusion:
[[602   0   1   1   0   0   0   1   0   0]
 [  0 684   2   0   0   0   0   2   0   0]
 [  0   2 574   1   1   0   0   8   0   0]
 [  0   0   2 574   0   1   0   5   1   0]
 [  0   1   0   0 548   0   2   3   0  11]
 [  1   0   0   2   0 512   3   0   0   0]
 [  4   2   0   0   1   4 619   0   1   0]
 [  0   2   1   0   0   1   0 621   0   0]
 [  4   0   2   3   2   3   4   1 562   3]
 [  1   1   0   2   3   1   0   5   1 601]]

2022-01-25 18:28:29,806 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:28:29,806 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:29,812 - 

2022-01-25 18:28:29,812 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:30,516 - Epoch: [56][   10/  211]    Overall Loss 0.059996    Objective Loss 0.059996                                        LR 0.100000    Time 0.070324    
2022-01-25 18:28:30,766 - Epoch: [56][   20/  211]    Overall Loss 0.064613    Objective Loss 0.064613                                        LR 0.100000    Time 0.047637    
2022-01-25 18:28:31,014 - Epoch: [56][   30/  211]    Overall Loss 0.067005    Objective Loss 0.067005                                        LR 0.100000    Time 0.040014    
2022-01-25 18:28:31,290 - Epoch: [56][   40/  211]    Overall Loss 0.066022    Objective Loss 0.066022                                        LR 0.100000    Time 0.036899    
2022-01-25 18:28:31,548 - Epoch: [56][   50/  211]    Overall Loss 0.065321    Objective Loss 0.065321                                        LR 0.100000    Time 0.034685    
2022-01-25 18:28:31,824 - Epoch: [56][   60/  211]    Overall Loss 0.066765    Objective Loss 0.066765                                        LR 0.100000    Time 0.033501    
2022-01-25 18:28:32,074 - Epoch: [56][   70/  211]    Overall Loss 0.067065    Objective Loss 0.067065                                        LR 0.100000    Time 0.032274    
2022-01-25 18:28:32,363 - Epoch: [56][   80/  211]    Overall Loss 0.066537    Objective Loss 0.066537                                        LR 0.100000    Time 0.031852    
2022-01-25 18:28:32,609 - Epoch: [56][   90/  211]    Overall Loss 0.066705    Objective Loss 0.066705                                        LR 0.100000    Time 0.031034    
2022-01-25 18:28:32,889 - Epoch: [56][  100/  211]    Overall Loss 0.065700    Objective Loss 0.065700                                        LR 0.100000    Time 0.030726    
2022-01-25 18:28:33,145 - Epoch: [56][  110/  211]    Overall Loss 0.065717    Objective Loss 0.065717                                        LR 0.100000    Time 0.030259    
2022-01-25 18:28:33,424 - Epoch: [56][  120/  211]    Overall Loss 0.064626    Objective Loss 0.064626                                        LR 0.100000    Time 0.030063    
2022-01-25 18:28:33,670 - Epoch: [56][  130/  211]    Overall Loss 0.064298    Objective Loss 0.064298                                        LR 0.100000    Time 0.029639    
2022-01-25 18:28:33,950 - Epoch: [56][  140/  211]    Overall Loss 0.064099    Objective Loss 0.064099                                        LR 0.100000    Time 0.029519    
2022-01-25 18:28:34,209 - Epoch: [56][  150/  211]    Overall Loss 0.064015    Objective Loss 0.064015                                        LR 0.100000    Time 0.029278    
2022-01-25 18:28:34,486 - Epoch: [56][  160/  211]    Overall Loss 0.063971    Objective Loss 0.063971                                        LR 0.100000    Time 0.029177    
2022-01-25 18:28:34,741 - Epoch: [56][  170/  211]    Overall Loss 0.063237    Objective Loss 0.063237                                        LR 0.100000    Time 0.028958    
2022-01-25 18:28:35,013 - Epoch: [56][  180/  211]    Overall Loss 0.062855    Objective Loss 0.062855                                        LR 0.100000    Time 0.028858    
2022-01-25 18:28:35,271 - Epoch: [56][  190/  211]    Overall Loss 0.063059    Objective Loss 0.063059                                        LR 0.100000    Time 0.028692    
2022-01-25 18:28:35,551 - Epoch: [56][  200/  211]    Overall Loss 0.063381    Objective Loss 0.063381                                        LR 0.100000    Time 0.028659    
2022-01-25 18:28:35,793 - Epoch: [56][  210/  211]    Overall Loss 0.063702    Objective Loss 0.063702    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.028446    
2022-01-25 18:28:35,811 - Epoch: [56][  211/  211]    Overall Loss 0.063592    Objective Loss 0.063592    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.028394    
2022-01-25 18:28:35,867 - --- validate (epoch=56)-----------
2022-01-25 18:28:35,867 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:36,333 - Epoch: [56][   10/   24]    Loss 0.070610    Top1 97.890625    Top5 99.882812    
2022-01-25 18:28:36,536 - Epoch: [56][   20/   24]    Loss 0.068883    Top1 98.125000    Top5 99.941406    
2022-01-25 18:28:36,622 - Epoch: [56][   24/   24]    Loss 0.068836    Top1 98.200000    Top5 99.950000    
2022-01-25 18:28:36,678 - ==> Top1: 98.200    Top5: 99.950    Loss: 0.069

2022-01-25 18:28:36,679 - ==> Confusion:
[[597   0   0   2   0   1   2   0   3   0]
 [  0 682   1   0   0   1   0   4   0   0]
 [  1   2 568   6   0   0   0   4   3   2]
 [  0   0   0 578   1   1   0   1   2   0]
 [  2   0   1   0 553   2   1   0   1   5]
 [  0   0   0   3   0 513   2   0   0   0]
 [  0   0   0   0   3   6 622   0   0   0]
 [  0   1   0   6   1   1   0 615   0   1]
 [  0   0   0   4   0   5   2   0 572   1]
 [  1   1   0   4   7   3   0   3   4 592]]

2022-01-25 18:28:36,681 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:28:36,681 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:36,687 - 

2022-01-25 18:28:36,687 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:37,240 - Epoch: [57][   10/  211]    Overall Loss 0.061994    Objective Loss 0.061994                                        LR 0.100000    Time 0.055227    
2022-01-25 18:28:37,458 - Epoch: [57][   20/  211]    Overall Loss 0.062280    Objective Loss 0.062280                                        LR 0.100000    Time 0.038452    
2022-01-25 18:28:37,674 - Epoch: [57][   30/  211]    Overall Loss 0.062513    Objective Loss 0.062513                                        LR 0.100000    Time 0.032851    
2022-01-25 18:28:37,878 - Epoch: [57][   40/  211]    Overall Loss 0.063788    Objective Loss 0.063788                                        LR 0.100000    Time 0.029724    
2022-01-25 18:28:38,102 - Epoch: [57][   50/  211]    Overall Loss 0.061177    Objective Loss 0.061177                                        LR 0.100000    Time 0.028246    
2022-01-25 18:28:38,314 - Epoch: [57][   60/  211]    Overall Loss 0.060956    Objective Loss 0.060956                                        LR 0.100000    Time 0.027064    
2022-01-25 18:28:38,547 - Epoch: [57][   70/  211]    Overall Loss 0.062199    Objective Loss 0.062199                                        LR 0.100000    Time 0.026527    
2022-01-25 18:28:38,759 - Epoch: [57][   80/  211]    Overall Loss 0.063064    Objective Loss 0.063064                                        LR 0.100000    Time 0.025855    
2022-01-25 18:28:38,983 - Epoch: [57][   90/  211]    Overall Loss 0.062896    Objective Loss 0.062896                                        LR 0.100000    Time 0.025466    
2022-01-25 18:28:39,196 - Epoch: [57][  100/  211]    Overall Loss 0.065272    Objective Loss 0.065272                                        LR 0.100000    Time 0.025044    
2022-01-25 18:28:39,424 - Epoch: [57][  110/  211]    Overall Loss 0.066251    Objective Loss 0.066251                                        LR 0.100000    Time 0.024835    
2022-01-25 18:28:39,642 - Epoch: [57][  120/  211]    Overall Loss 0.065728    Objective Loss 0.065728                                        LR 0.100000    Time 0.024581    
2022-01-25 18:28:39,919 - Epoch: [57][  130/  211]    Overall Loss 0.064724    Objective Loss 0.064724                                        LR 0.100000    Time 0.024819    
2022-01-25 18:28:40,165 - Epoch: [57][  140/  211]    Overall Loss 0.064266    Objective Loss 0.064266                                        LR 0.100000    Time 0.024797    
2022-01-25 18:28:40,444 - Epoch: [57][  150/  211]    Overall Loss 0.064557    Objective Loss 0.064557                                        LR 0.100000    Time 0.025006    
2022-01-25 18:28:40,695 - Epoch: [57][  160/  211]    Overall Loss 0.064666    Objective Loss 0.064666                                        LR 0.100000    Time 0.025007    
2022-01-25 18:28:40,978 - Epoch: [57][  170/  211]    Overall Loss 0.064806    Objective Loss 0.064806                                        LR 0.100000    Time 0.025200    
2022-01-25 18:28:41,223 - Epoch: [57][  180/  211]    Overall Loss 0.064809    Objective Loss 0.064809                                        LR 0.100000    Time 0.025162    
2022-01-25 18:28:41,502 - Epoch: [57][  190/  211]    Overall Loss 0.064488    Objective Loss 0.064488                                        LR 0.100000    Time 0.025304    
2022-01-25 18:28:41,746 - Epoch: [57][  200/  211]    Overall Loss 0.064375    Objective Loss 0.064375                                        LR 0.100000    Time 0.025254    
2022-01-25 18:28:42,026 - Epoch: [57][  210/  211]    Overall Loss 0.064309    Objective Loss 0.064309    Top1 98.437500    Top5 99.609375    LR 0.100000    Time 0.025385    
2022-01-25 18:28:42,045 - Epoch: [57][  211/  211]    Overall Loss 0.064262    Objective Loss 0.064262    Top1 98.588710    Top5 99.798387    LR 0.100000    Time 0.025354    
2022-01-25 18:28:42,102 - --- validate (epoch=57)-----------
2022-01-25 18:28:42,102 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:42,711 - Epoch: [57][   10/   24]    Loss 0.074678    Top1 97.773438    Top5 99.921875    
2022-01-25 18:28:42,962 - Epoch: [57][   20/   24]    Loss 0.068861    Top1 98.125000    Top5 99.960938    
2022-01-25 18:28:43,068 - Epoch: [57][   24/   24]    Loss 0.067461    Top1 98.233333    Top5 99.933333    
2022-01-25 18:28:43,132 - ==> Top1: 98.233    Top5: 99.933    Loss: 0.067

2022-01-25 18:28:43,133 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 681   3   0   0   1   0   3   0   0]
 [  1   0 576   0   0   0   0   6   2   1]
 [  1   1   2 569   0   5   0   4   1   0]
 [  0   1   0   0 554   0   0   0   1   9]
 [  0   0   0   1   0 512   4   0   1   0]
 [  1   4   0   0   4   7 612   0   3   0]
 [  0   0   2   0   0   0   0 623   0   0]
 [  3   0   1   0   3   3   2   1 569   2]
 [  1   1   0   0   7   2   0   5   4 595]]

2022-01-25 18:28:43,135 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 49]
2022-01-25 18:28:43,135 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:43,141 - 

2022-01-25 18:28:43,141 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:43,690 - Epoch: [58][   10/  211]    Overall Loss 0.063872    Objective Loss 0.063872                                        LR 0.100000    Time 0.054808    
2022-01-25 18:28:43,898 - Epoch: [58][   20/  211]    Overall Loss 0.059522    Objective Loss 0.059522                                        LR 0.100000    Time 0.037796    
2022-01-25 18:28:44,119 - Epoch: [58][   30/  211]    Overall Loss 0.059229    Objective Loss 0.059229                                        LR 0.100000    Time 0.032558    
2022-01-25 18:28:44,330 - Epoch: [58][   40/  211]    Overall Loss 0.058598    Objective Loss 0.058598                                        LR 0.100000    Time 0.029675    
2022-01-25 18:28:44,556 - Epoch: [58][   50/  211]    Overall Loss 0.061423    Objective Loss 0.061423                                        LR 0.100000    Time 0.028260    
2022-01-25 18:28:44,767 - Epoch: [58][   60/  211]    Overall Loss 0.062639    Objective Loss 0.062639                                        LR 0.100000    Time 0.027063    
2022-01-25 18:28:44,997 - Epoch: [58][   70/  211]    Overall Loss 0.061364    Objective Loss 0.061364                                        LR 0.100000    Time 0.026478    
2022-01-25 18:28:45,210 - Epoch: [58][   80/  211]    Overall Loss 0.062331    Objective Loss 0.062331                                        LR 0.100000    Time 0.025828    
2022-01-25 18:28:45,437 - Epoch: [58][   90/  211]    Overall Loss 0.062967    Objective Loss 0.062967                                        LR 0.100000    Time 0.025474    
2022-01-25 18:28:45,650 - Epoch: [58][  100/  211]    Overall Loss 0.062826    Objective Loss 0.062826                                        LR 0.100000    Time 0.025046    
2022-01-25 18:28:45,891 - Epoch: [58][  110/  211]    Overall Loss 0.062899    Objective Loss 0.062899                                        LR 0.100000    Time 0.024960    
2022-01-25 18:28:46,103 - Epoch: [58][  120/  211]    Overall Loss 0.063179    Objective Loss 0.063179                                        LR 0.100000    Time 0.024643    
2022-01-25 18:28:46,329 - Epoch: [58][  130/  211]    Overall Loss 0.063681    Objective Loss 0.063681                                        LR 0.100000    Time 0.024489    
2022-01-25 18:28:46,541 - Epoch: [58][  140/  211]    Overall Loss 0.063277    Objective Loss 0.063277                                        LR 0.100000    Time 0.024252    
2022-01-25 18:28:46,778 - Epoch: [58][  150/  211]    Overall Loss 0.064031    Objective Loss 0.064031                                        LR 0.100000    Time 0.024211    
2022-01-25 18:28:46,985 - Epoch: [58][  160/  211]    Overall Loss 0.064080    Objective Loss 0.064080                                        LR 0.100000    Time 0.023988    
2022-01-25 18:28:47,217 - Epoch: [58][  170/  211]    Overall Loss 0.063560    Objective Loss 0.063560                                        LR 0.100000    Time 0.023942    
2022-01-25 18:28:47,450 - Epoch: [58][  180/  211]    Overall Loss 0.063284    Objective Loss 0.063284                                        LR 0.100000    Time 0.023903    
2022-01-25 18:28:47,678 - Epoch: [58][  190/  211]    Overall Loss 0.063314    Objective Loss 0.063314                                        LR 0.100000    Time 0.023845    
2022-01-25 18:28:47,960 - Epoch: [58][  200/  211]    Overall Loss 0.063651    Objective Loss 0.063651                                        LR 0.100000    Time 0.024059    
2022-01-25 18:28:48,205 - Epoch: [58][  210/  211]    Overall Loss 0.063960    Objective Loss 0.063960    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.024078    
2022-01-25 18:28:48,250 - Epoch: [58][  211/  211]    Overall Loss 0.063998    Objective Loss 0.063998    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.024178    
2022-01-25 18:28:48,322 - --- validate (epoch=58)-----------
2022-01-25 18:28:48,322 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:48,784 - Epoch: [58][   10/   24]    Loss 0.061701    Top1 98.750000    Top5 100.000000    
2022-01-25 18:28:48,979 - Epoch: [58][   20/   24]    Loss 0.061416    Top1 98.593750    Top5 100.000000    
2022-01-25 18:28:49,061 - Epoch: [58][   24/   24]    Loss 0.059893    Top1 98.616667    Top5 100.000000    
2022-01-25 18:28:49,119 - ==> Top1: 98.617    Top5: 100.000    Loss: 0.060

2022-01-25 18:28:49,120 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 684   1   0   0   1   0   2   0   0]
 [  0   0 584   1   0   0   0   0   1   0]
 [  0   0   4 576   0   1   0   0   1   1]
 [  0   1   3   0 551   0   1   2   0   7]
 [  2   3   0   2   0 502   2   1   6   0]
 [  0   3   0   0   3   1 622   0   2   0]
 [  0   0   6   0   0   0   0 619   0   0]
 [  0   0   2   0   1   0   1   1 577   2]
 [  1   1   0   1   6   1   0   2   4 599]]

2022-01-25 18:28:49,121 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:28:49,121 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:49,128 - 

2022-01-25 18:28:49,128 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:49,840 - Epoch: [59][   10/  211]    Overall Loss 0.063012    Objective Loss 0.063012                                        LR 0.100000    Time 0.071124    
2022-01-25 18:28:50,090 - Epoch: [59][   20/  211]    Overall Loss 0.062363    Objective Loss 0.062363                                        LR 0.100000    Time 0.048043    
2022-01-25 18:28:50,370 - Epoch: [59][   30/  211]    Overall Loss 0.059359    Objective Loss 0.059359                                        LR 0.100000    Time 0.041359    
2022-01-25 18:28:50,613 - Epoch: [59][   40/  211]    Overall Loss 0.062129    Objective Loss 0.062129                                        LR 0.100000    Time 0.037092    
2022-01-25 18:28:50,902 - Epoch: [59][   50/  211]    Overall Loss 0.061590    Objective Loss 0.061590                                        LR 0.100000    Time 0.035452    
2022-01-25 18:28:51,147 - Epoch: [59][   60/  211]    Overall Loss 0.063768    Objective Loss 0.063768                                        LR 0.100000    Time 0.033605    
2022-01-25 18:28:51,427 - Epoch: [59][   70/  211]    Overall Loss 0.065574    Objective Loss 0.065574                                        LR 0.100000    Time 0.032813    
2022-01-25 18:28:51,682 - Epoch: [59][   80/  211]    Overall Loss 0.065271    Objective Loss 0.065271                                        LR 0.100000    Time 0.031884    
2022-01-25 18:28:51,968 - Epoch: [59][   90/  211]    Overall Loss 0.064957    Objective Loss 0.064957                                        LR 0.100000    Time 0.031523    
2022-01-25 18:28:52,216 - Epoch: [59][  100/  211]    Overall Loss 0.064759    Objective Loss 0.064759                                        LR 0.100000    Time 0.030834    
2022-01-25 18:28:52,497 - Epoch: [59][  110/  211]    Overall Loss 0.063800    Objective Loss 0.063800                                        LR 0.100000    Time 0.030583    
2022-01-25 18:28:52,748 - Epoch: [59][  120/  211]    Overall Loss 0.063009    Objective Loss 0.063009                                        LR 0.100000    Time 0.030124    
2022-01-25 18:28:53,033 - Epoch: [59][  130/  211]    Overall Loss 0.062539    Objective Loss 0.062539                                        LR 0.100000    Time 0.029998    
2022-01-25 18:28:53,279 - Epoch: [59][  140/  211]    Overall Loss 0.062372    Objective Loss 0.062372                                        LR 0.100000    Time 0.029610    
2022-01-25 18:28:53,560 - Epoch: [59][  150/  211]    Overall Loss 0.062919    Objective Loss 0.062919                                        LR 0.100000    Time 0.029502    
2022-01-25 18:28:53,810 - Epoch: [59][  160/  211]    Overall Loss 0.062660    Objective Loss 0.062660                                        LR 0.100000    Time 0.029220    
2022-01-25 18:28:54,098 - Epoch: [59][  170/  211]    Overall Loss 0.062474    Objective Loss 0.062474                                        LR 0.100000    Time 0.029192    
2022-01-25 18:28:54,350 - Epoch: [59][  180/  211]    Overall Loss 0.062187    Objective Loss 0.062187                                        LR 0.100000    Time 0.028970    
2022-01-25 18:28:54,622 - Epoch: [59][  190/  211]    Overall Loss 0.062082    Objective Loss 0.062082                                        LR 0.100000    Time 0.028874    
2022-01-25 18:28:54,868 - Epoch: [59][  200/  211]    Overall Loss 0.062257    Objective Loss 0.062257                                        LR 0.100000    Time 0.028658    
2022-01-25 18:28:55,147 - Epoch: [59][  210/  211]    Overall Loss 0.062259    Objective Loss 0.062259    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.028620    
2022-01-25 18:28:55,167 - Epoch: [59][  211/  211]    Overall Loss 0.062353    Objective Loss 0.062353    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.028577    
2022-01-25 18:28:55,228 - --- validate (epoch=59)-----------
2022-01-25 18:28:55,229 - 6000 samples (256 per mini-batch)
2022-01-25 18:28:55,699 - Epoch: [59][   10/   24]    Loss 0.065958    Top1 98.281250    Top5 99.960938    
2022-01-25 18:28:55,961 - Epoch: [59][   20/   24]    Loss 0.068533    Top1 98.242188    Top5 99.980469    
2022-01-25 18:28:56,006 - Epoch: [59][   24/   24]    Loss 0.068897    Top1 98.283333    Top5 99.966667    
2022-01-25 18:28:56,063 - ==> Top1: 98.283    Top5: 99.967    Loss: 0.069

2022-01-25 18:28:56,064 - ==> Confusion:
[[601   0   0   0   0   1   1   0   0   2]
 [  0 679   1   0   0   1   0   6   0   1]
 [  1   2 562   0   1   0   0  11   5   4]
 [  0   0   0 579   0   0   0   3   0   1]
 [  0   1   1   0 548   0   1   3   0  11]
 [  0   0   0   2   0 514   0   0   2   0]
 [  2   3   0   0   3   3 618   0   2   0]
 [  0   1   1   0   0   0   0 623   0   0]
 [  1   0   1   3   2   2   4   0 569   2]
 [  1   1   0   1   3   1   0   2   2 604]]

2022-01-25 18:28:56,067 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:28:56,067 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:28:56,075 - 

2022-01-25 18:28:56,076 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:28:56,623 - Epoch: [60][   10/  211]    Overall Loss 0.072296    Objective Loss 0.072296                                        LR 0.100000    Time 0.054727    
2022-01-25 18:28:56,834 - Epoch: [60][   20/  211]    Overall Loss 0.068003    Objective Loss 0.068003                                        LR 0.100000    Time 0.037889    
2022-01-25 18:28:57,057 - Epoch: [60][   30/  211]    Overall Loss 0.067079    Objective Loss 0.067079                                        LR 0.100000    Time 0.032653    
2022-01-25 18:28:57,265 - Epoch: [60][   40/  211]    Overall Loss 0.067407    Objective Loss 0.067407                                        LR 0.100000    Time 0.029699    
2022-01-25 18:28:57,514 - Epoch: [60][   50/  211]    Overall Loss 0.069077    Objective Loss 0.069077                                        LR 0.100000    Time 0.028729    
2022-01-25 18:28:57,767 - Epoch: [60][   60/  211]    Overall Loss 0.067037    Objective Loss 0.067037                                        LR 0.100000    Time 0.028155    
2022-01-25 18:28:58,045 - Epoch: [60][   70/  211]    Overall Loss 0.067816    Objective Loss 0.067816                                        LR 0.100000    Time 0.028099    
2022-01-25 18:28:58,298 - Epoch: [60][   80/  211]    Overall Loss 0.066303    Objective Loss 0.066303                                        LR 0.100000    Time 0.027740    
2022-01-25 18:28:58,584 - Epoch: [60][   90/  211]    Overall Loss 0.066827    Objective Loss 0.066827                                        LR 0.100000    Time 0.027830    
2022-01-25 18:28:58,835 - Epoch: [60][  100/  211]    Overall Loss 0.067750    Objective Loss 0.067750                                        LR 0.100000    Time 0.027557    
2022-01-25 18:28:59,112 - Epoch: [60][  110/  211]    Overall Loss 0.066439    Objective Loss 0.066439                                        LR 0.100000    Time 0.027567    
2022-01-25 18:28:59,359 - Epoch: [60][  120/  211]    Overall Loss 0.065821    Objective Loss 0.065821                                        LR 0.100000    Time 0.027325    
2022-01-25 18:28:59,641 - Epoch: [60][  130/  211]    Overall Loss 0.065330    Objective Loss 0.065330                                        LR 0.100000    Time 0.027388    
2022-01-25 18:28:59,890 - Epoch: [60][  140/  211]    Overall Loss 0.064729    Objective Loss 0.064729                                        LR 0.100000    Time 0.027212    
2022-01-25 18:29:00,178 - Epoch: [60][  150/  211]    Overall Loss 0.065183    Objective Loss 0.065183                                        LR 0.100000    Time 0.027315    
2022-01-25 18:29:00,427 - Epoch: [60][  160/  211]    Overall Loss 0.065604    Objective Loss 0.065604                                        LR 0.100000    Time 0.027158    
2022-01-25 18:29:00,707 - Epoch: [60][  170/  211]    Overall Loss 0.065215    Objective Loss 0.065215                                        LR 0.100000    Time 0.027209    
2022-01-25 18:29:00,953 - Epoch: [60][  180/  211]    Overall Loss 0.065179    Objective Loss 0.065179                                        LR 0.100000    Time 0.027059    
2022-01-25 18:29:01,232 - Epoch: [60][  190/  211]    Overall Loss 0.064822    Objective Loss 0.064822                                        LR 0.100000    Time 0.027103    
2022-01-25 18:29:01,478 - Epoch: [60][  200/  211]    Overall Loss 0.064457    Objective Loss 0.064457                                        LR 0.100000    Time 0.026977    
2022-01-25 18:29:01,767 - Epoch: [60][  210/  211]    Overall Loss 0.064007    Objective Loss 0.064007    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.027069    
2022-01-25 18:29:01,786 - Epoch: [60][  211/  211]    Overall Loss 0.063880    Objective Loss 0.063880    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.027025    
2022-01-25 18:29:01,857 - --- validate (epoch=60)-----------
2022-01-25 18:29:01,857 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:02,330 - Epoch: [60][   10/   24]    Loss 0.053348    Top1 98.671875    Top5 100.000000    
2022-01-25 18:29:02,598 - Epoch: [60][   20/   24]    Loss 0.059241    Top1 98.535156    Top5 99.980469    
2022-01-25 18:29:02,702 - Epoch: [60][   24/   24]    Loss 0.063252    Top1 98.466667    Top5 99.983333    
2022-01-25 18:29:02,758 - ==> Top1: 98.467    Top5: 99.983    Loss: 0.063

2022-01-25 18:29:02,758 - ==> Confusion:
[[598   0   1   0   0   0   2   0   3   1]
 [  0 683   1   1   1   0   0   2   0   0]
 [  0   0 577   0   0   0   1   5   3   0]
 [  0   0   2 574   1   1   0   2   2   1]
 [  0   1   1   0 551   0   0   1   0  11]
 [  1   0   0   2   0 508   5   1   1   0]
 [  1   1   0   0   2   0 625   0   2   0]
 [  0   2   4   2   0   0   0 617   0   0]
 [  0   0   1   2   0   1   1   1 578   0]
 [  1   1   0   2   4   1   0   4   5 597]]

2022-01-25 18:29:02,760 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:02,760 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:02,765 - 

2022-01-25 18:29:02,766 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:03,457 - Epoch: [61][   10/  211]    Overall Loss 0.054846    Objective Loss 0.054846                                        LR 0.100000    Time 0.069070    
2022-01-25 18:29:03,725 - Epoch: [61][   20/  211]    Overall Loss 0.053996    Objective Loss 0.053996                                        LR 0.100000    Time 0.047919    
2022-01-25 18:29:03,969 - Epoch: [61][   30/  211]    Overall Loss 0.055167    Objective Loss 0.055167                                        LR 0.100000    Time 0.040071    
2022-01-25 18:29:04,244 - Epoch: [61][   40/  211]    Overall Loss 0.058412    Objective Loss 0.058412                                        LR 0.100000    Time 0.036912    
2022-01-25 18:29:04,491 - Epoch: [61][   50/  211]    Overall Loss 0.059063    Objective Loss 0.059063                                        LR 0.100000    Time 0.034462    
2022-01-25 18:29:04,776 - Epoch: [61][   60/  211]    Overall Loss 0.059385    Objective Loss 0.059385                                        LR 0.100000    Time 0.033470    
2022-01-25 18:29:05,026 - Epoch: [61][   70/  211]    Overall Loss 0.059818    Objective Loss 0.059818                                        LR 0.100000    Time 0.032248    
2022-01-25 18:29:05,309 - Epoch: [61][   80/  211]    Overall Loss 0.060820    Objective Loss 0.060820                                        LR 0.100000    Time 0.031756    
2022-01-25 18:29:05,561 - Epoch: [61][   90/  211]    Overall Loss 0.061288    Objective Loss 0.061288                                        LR 0.100000    Time 0.031017    
2022-01-25 18:29:05,836 - Epoch: [61][  100/  211]    Overall Loss 0.061166    Objective Loss 0.061166                                        LR 0.100000    Time 0.030661    
2022-01-25 18:29:06,091 - Epoch: [61][  110/  211]    Overall Loss 0.061533    Objective Loss 0.061533                                        LR 0.100000    Time 0.030195    
2022-01-25 18:29:06,372 - Epoch: [61][  120/  211]    Overall Loss 0.061924    Objective Loss 0.061924                                        LR 0.100000    Time 0.030011    
2022-01-25 18:29:06,630 - Epoch: [61][  130/  211]    Overall Loss 0.061666    Objective Loss 0.061666                                        LR 0.100000    Time 0.029687    
2022-01-25 18:29:06,910 - Epoch: [61][  140/  211]    Overall Loss 0.061394    Objective Loss 0.061394                                        LR 0.100000    Time 0.029561    
2022-01-25 18:29:07,165 - Epoch: [61][  150/  211]    Overall Loss 0.061717    Objective Loss 0.061717                                        LR 0.100000    Time 0.029288    
2022-01-25 18:29:07,441 - Epoch: [61][  160/  211]    Overall Loss 0.061571    Objective Loss 0.061571                                        LR 0.100000    Time 0.029180    
2022-01-25 18:29:07,689 - Epoch: [61][  170/  211]    Overall Loss 0.061948    Objective Loss 0.061948                                        LR 0.100000    Time 0.028922    
2022-01-25 18:29:07,975 - Epoch: [61][  180/  211]    Overall Loss 0.062336    Objective Loss 0.062336                                        LR 0.100000    Time 0.028899    
2022-01-25 18:29:08,222 - Epoch: [61][  190/  211]    Overall Loss 0.061864    Objective Loss 0.061864                                        LR 0.100000    Time 0.028676    
2022-01-25 18:29:08,506 - Epoch: [61][  200/  211]    Overall Loss 0.061992    Objective Loss 0.061992                                        LR 0.100000    Time 0.028663    
2022-01-25 18:29:08,757 - Epoch: [61][  210/  211]    Overall Loss 0.061807    Objective Loss 0.061807    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.028488    
2022-01-25 18:29:08,799 - Epoch: [61][  211/  211]    Overall Loss 0.061759    Objective Loss 0.061759    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.028551    
2022-01-25 18:29:08,863 - --- validate (epoch=61)-----------
2022-01-25 18:29:08,864 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:09,341 - Epoch: [61][   10/   24]    Loss 0.055711    Top1 98.398438    Top5 100.000000    
2022-01-25 18:29:09,534 - Epoch: [61][   20/   24]    Loss 0.064658    Top1 98.222656    Top5 99.980469    
2022-01-25 18:29:09,623 - Epoch: [61][   24/   24]    Loss 0.066344    Top1 98.216667    Top5 99.983333    
2022-01-25 18:29:09,680 - ==> Top1: 98.217    Top5: 99.983    Loss: 0.066

2022-01-25 18:29:09,680 - ==> Confusion:
[[601   0   0   0   0   1   3   0   0   0]
 [  0 684   0   0   0   0   0   4   0   0]
 [  2   2 567   4   0   0   0   8   1   2]
 [  0   1   1 573   0   5   1   2   0   0]
 [  1   1   0   0 558   0   0   0   0   5]
 [  3   1   0   1   0 507   4   1   1   0]
 [  2   4   0   0   2   0 623   0   0   0]
 [  0   2   1   2   1   0   0 619   0   0]
 [  4   1   0   0   4   1   8   1 562   3]
 [  1   2   0   0  10   1   0   2   1 598]]

2022-01-25 18:29:09,682 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:09,682 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:09,689 - 

2022-01-25 18:29:09,689 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:10,390 - Epoch: [62][   10/  211]    Overall Loss 0.056529    Objective Loss 0.056529                                        LR 0.100000    Time 0.070056    
2022-01-25 18:29:10,604 - Epoch: [62][   20/  211]    Overall Loss 0.060010    Objective Loss 0.060010                                        LR 0.100000    Time 0.045684    
2022-01-25 18:29:10,819 - Epoch: [62][   30/  211]    Overall Loss 0.059926    Objective Loss 0.059926                                        LR 0.100000    Time 0.037636    
2022-01-25 18:29:11,028 - Epoch: [62][   40/  211]    Overall Loss 0.059886    Objective Loss 0.059886                                        LR 0.100000    Time 0.033430    
2022-01-25 18:29:11,252 - Epoch: [62][   50/  211]    Overall Loss 0.061381    Objective Loss 0.061381                                        LR 0.100000    Time 0.031226    
2022-01-25 18:29:11,463 - Epoch: [62][   60/  211]    Overall Loss 0.060120    Objective Loss 0.060120                                        LR 0.100000    Time 0.029528    
2022-01-25 18:29:11,687 - Epoch: [62][   70/  211]    Overall Loss 0.060445    Objective Loss 0.060445                                        LR 0.100000    Time 0.028503    
2022-01-25 18:29:11,902 - Epoch: [62][   80/  211]    Overall Loss 0.061153    Objective Loss 0.061153                                        LR 0.100000    Time 0.027632    
2022-01-25 18:29:12,129 - Epoch: [62][   90/  211]    Overall Loss 0.060938    Objective Loss 0.060938                                        LR 0.100000    Time 0.027074    
2022-01-25 18:29:12,360 - Epoch: [62][  100/  211]    Overall Loss 0.060914    Objective Loss 0.060914                                        LR 0.100000    Time 0.026670    
2022-01-25 18:29:12,603 - Epoch: [62][  110/  211]    Overall Loss 0.060920    Objective Loss 0.060920                                        LR 0.100000    Time 0.026457    
2022-01-25 18:29:12,826 - Epoch: [62][  120/  211]    Overall Loss 0.061538    Objective Loss 0.061538                                        LR 0.100000    Time 0.026103    
2022-01-25 18:29:13,078 - Epoch: [62][  130/  211]    Overall Loss 0.061752    Objective Loss 0.061752                                        LR 0.100000    Time 0.026031    
2022-01-25 18:29:13,327 - Epoch: [62][  140/  211]    Overall Loss 0.061739    Objective Loss 0.061739                                        LR 0.100000    Time 0.025949    
2022-01-25 18:29:13,607 - Epoch: [62][  150/  211]    Overall Loss 0.061811    Objective Loss 0.061811                                        LR 0.100000    Time 0.026083    
2022-01-25 18:29:13,854 - Epoch: [62][  160/  211]    Overall Loss 0.061474    Objective Loss 0.061474                                        LR 0.100000    Time 0.025994    
2022-01-25 18:29:14,138 - Epoch: [62][  170/  211]    Overall Loss 0.061812    Objective Loss 0.061812                                        LR 0.100000    Time 0.026135    
2022-01-25 18:29:14,386 - Epoch: [62][  180/  211]    Overall Loss 0.061632    Objective Loss 0.061632                                        LR 0.100000    Time 0.026059    
2022-01-25 18:29:14,670 - Epoch: [62][  190/  211]    Overall Loss 0.061478    Objective Loss 0.061478                                        LR 0.100000    Time 0.026180    
2022-01-25 18:29:14,918 - Epoch: [62][  200/  211]    Overall Loss 0.061156    Objective Loss 0.061156                                        LR 0.100000    Time 0.026110    
2022-01-25 18:29:15,193 - Epoch: [62][  210/  211]    Overall Loss 0.060817    Objective Loss 0.060817    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.026175    
2022-01-25 18:29:15,211 - Epoch: [62][  211/  211]    Overall Loss 0.060762    Objective Loss 0.060762    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.026132    
2022-01-25 18:29:15,267 - --- validate (epoch=62)-----------
2022-01-25 18:29:15,267 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:15,741 - Epoch: [62][   10/   24]    Loss 0.057234    Top1 98.554688    Top5 100.000000    
2022-01-25 18:29:15,940 - Epoch: [62][   20/   24]    Loss 0.057398    Top1 98.593750    Top5 100.000000    
2022-01-25 18:29:16,028 - Epoch: [62][   24/   24]    Loss 0.062734    Top1 98.566667    Top5 100.000000    
2022-01-25 18:29:16,083 - ==> Top1: 98.567    Top5: 100.000    Loss: 0.063

2022-01-25 18:29:16,084 - ==> Confusion:
[[601   0   1   0   1   0   2   0   0   0]
 [  0 685   2   1   0   0   0   0   0   0]
 [  0   1 574   2   0   0   2   3   2   2]
 [  0   0   3 577   0   1   0   1   1   0]
 [  0   1   0   0 555   0   0   1   1   7]
 [  0   0   0   2   0 511   2   0   3   0]
 [  1   1   0   0   5   1 622   0   1   0]
 [  0   4   1   2   3   0   0 614   0   1]
 [  0   0   1   2   1   2   1   0 577   0]
 [  0   1   0   1   6   4   0   3   2 598]]

2022-01-25 18:29:16,085 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:16,085 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:16,091 - 

2022-01-25 18:29:16,091 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:16,644 - Epoch: [63][   10/  211]    Overall Loss 0.059799    Objective Loss 0.059799                                        LR 0.100000    Time 0.055180    
2022-01-25 18:29:16,909 - Epoch: [63][   20/  211]    Overall Loss 0.059312    Objective Loss 0.059312                                        LR 0.100000    Time 0.040859    
2022-01-25 18:29:17,153 - Epoch: [63][   30/  211]    Overall Loss 0.058101    Objective Loss 0.058101                                        LR 0.100000    Time 0.035363    
2022-01-25 18:29:17,431 - Epoch: [63][   40/  211]    Overall Loss 0.061717    Objective Loss 0.061717                                        LR 0.100000    Time 0.033467    
2022-01-25 18:29:17,682 - Epoch: [63][   50/  211]    Overall Loss 0.062980    Objective Loss 0.062980                                        LR 0.100000    Time 0.031764    
2022-01-25 18:29:17,962 - Epoch: [63][   60/  211]    Overall Loss 0.062713    Objective Loss 0.062713                                        LR 0.100000    Time 0.031139    
2022-01-25 18:29:18,211 - Epoch: [63][   70/  211]    Overall Loss 0.063487    Objective Loss 0.063487                                        LR 0.100000    Time 0.030238    
2022-01-25 18:29:18,502 - Epoch: [63][   80/  211]    Overall Loss 0.062434    Objective Loss 0.062434                                        LR 0.100000    Time 0.030097    
2022-01-25 18:29:18,746 - Epoch: [63][   90/  211]    Overall Loss 0.061577    Objective Loss 0.061577                                        LR 0.100000    Time 0.029463    
2022-01-25 18:29:18,979 - Epoch: [63][  100/  211]    Overall Loss 0.061802    Objective Loss 0.061802                                        LR 0.100000    Time 0.028841    
2022-01-25 18:29:19,190 - Epoch: [63][  110/  211]    Overall Loss 0.061403    Objective Loss 0.061403                                        LR 0.100000    Time 0.028130    
2022-01-25 18:29:19,430 - Epoch: [63][  120/  211]    Overall Loss 0.061648    Objective Loss 0.061648                                        LR 0.100000    Time 0.027786    
2022-01-25 18:29:19,637 - Epoch: [63][  130/  211]    Overall Loss 0.061282    Objective Loss 0.061282                                        LR 0.100000    Time 0.027238    
2022-01-25 18:29:19,865 - Epoch: [63][  140/  211]    Overall Loss 0.060634    Objective Loss 0.060634                                        LR 0.100000    Time 0.026917    
2022-01-25 18:29:20,072 - Epoch: [63][  150/  211]    Overall Loss 0.060281    Objective Loss 0.060281                                        LR 0.100000    Time 0.026499    
2022-01-25 18:29:20,295 - Epoch: [63][  160/  211]    Overall Loss 0.059970    Objective Loss 0.059970                                        LR 0.100000    Time 0.026234    
2022-01-25 18:29:20,553 - Epoch: [63][  170/  211]    Overall Loss 0.059870    Objective Loss 0.059870                                        LR 0.100000    Time 0.026210    
2022-01-25 18:29:20,801 - Epoch: [63][  180/  211]    Overall Loss 0.059654    Objective Loss 0.059654                                        LR 0.100000    Time 0.026128    
2022-01-25 18:29:21,088 - Epoch: [63][  190/  211]    Overall Loss 0.059413    Objective Loss 0.059413                                        LR 0.100000    Time 0.026263    
2022-01-25 18:29:21,333 - Epoch: [63][  200/  211]    Overall Loss 0.059859    Objective Loss 0.059859                                        LR 0.100000    Time 0.026173    
2022-01-25 18:29:21,612 - Epoch: [63][  210/  211]    Overall Loss 0.060253    Objective Loss 0.060253    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.026253    
2022-01-25 18:29:21,631 - Epoch: [63][  211/  211]    Overall Loss 0.060291    Objective Loss 0.060291    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.026219    
2022-01-25 18:29:21,687 - --- validate (epoch=63)-----------
2022-01-25 18:29:21,688 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:22,207 - Epoch: [63][   10/   24]    Loss 0.062864    Top1 98.437500    Top5 100.000000    
2022-01-25 18:29:22,411 - Epoch: [63][   20/   24]    Loss 0.071791    Top1 98.183594    Top5 99.980469    
2022-01-25 18:29:22,496 - Epoch: [63][   24/   24]    Loss 0.072809    Top1 98.200000    Top5 99.983333    
2022-01-25 18:29:22,553 - ==> Top1: 98.200    Top5: 99.983    Loss: 0.073

2022-01-25 18:29:22,553 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  1   2 574   0   0   0   0   7   1   1]
 [  0   0   2 572   1   2   0   5   1   0]
 [  0   1   0   0 556   1   1   1   0   5]
 [  2   1   0   1   2 508   3   0   1   0]
 [  3   4   0   0   4   1 619   0   0   0]
 [  0   2   2   0   0   0   0 621   0   0]
 [  2   1   1   0   5   3   3   2 566   1]
 [  1   2   0   0  14   1   0   8   3 586]]

2022-01-25 18:29:22,555 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:22,555 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:22,562 - 

2022-01-25 18:29:22,562 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:23,258 - Epoch: [64][   10/  211]    Overall Loss 0.070759    Objective Loss 0.070759                                        LR 0.100000    Time 0.069473    
2022-01-25 18:29:23,513 - Epoch: [64][   20/  211]    Overall Loss 0.070110    Objective Loss 0.070110                                        LR 0.100000    Time 0.047503    
2022-01-25 18:29:23,794 - Epoch: [64][   30/  211]    Overall Loss 0.067983    Objective Loss 0.067983                                        LR 0.100000    Time 0.041014    
2022-01-25 18:29:24,034 - Epoch: [64][   40/  211]    Overall Loss 0.067836    Objective Loss 0.067836                                        LR 0.100000    Time 0.036755    
2022-01-25 18:29:24,319 - Epoch: [64][   50/  211]    Overall Loss 0.066504    Objective Loss 0.066504                                        LR 0.100000    Time 0.035080    
2022-01-25 18:29:24,569 - Epoch: [64][   60/  211]    Overall Loss 0.065809    Objective Loss 0.065809                                        LR 0.100000    Time 0.033394    
2022-01-25 18:29:24,858 - Epoch: [64][   70/  211]    Overall Loss 0.065989    Objective Loss 0.065989                                        LR 0.100000    Time 0.032750    
2022-01-25 18:29:25,105 - Epoch: [64][   80/  211]    Overall Loss 0.065297    Objective Loss 0.065297                                        LR 0.100000    Time 0.031737    
2022-01-25 18:29:25,391 - Epoch: [64][   90/  211]    Overall Loss 0.065895    Objective Loss 0.065895                                        LR 0.100000    Time 0.031387    
2022-01-25 18:29:25,640 - Epoch: [64][  100/  211]    Overall Loss 0.065505    Objective Loss 0.065505                                        LR 0.100000    Time 0.030736    
2022-01-25 18:29:25,928 - Epoch: [64][  110/  211]    Overall Loss 0.064334    Objective Loss 0.064334                                        LR 0.100000    Time 0.030560    
2022-01-25 18:29:26,174 - Epoch: [64][  120/  211]    Overall Loss 0.063448    Objective Loss 0.063448                                        LR 0.100000    Time 0.030059    
2022-01-25 18:29:26,455 - Epoch: [64][  130/  211]    Overall Loss 0.062471    Objective Loss 0.062471                                        LR 0.100000    Time 0.029907    
2022-01-25 18:29:26,701 - Epoch: [64][  140/  211]    Overall Loss 0.062446    Objective Loss 0.062446                                        LR 0.100000    Time 0.029522    
2022-01-25 18:29:26,987 - Epoch: [64][  150/  211]    Overall Loss 0.062962    Objective Loss 0.062962                                        LR 0.100000    Time 0.029459    
2022-01-25 18:29:27,240 - Epoch: [64][  160/  211]    Overall Loss 0.062759    Objective Loss 0.062759                                        LR 0.100000    Time 0.029195    
2022-01-25 18:29:27,522 - Epoch: [64][  170/  211]    Overall Loss 0.062828    Objective Loss 0.062828                                        LR 0.100000    Time 0.029135    
2022-01-25 18:29:27,770 - Epoch: [64][  180/  211]    Overall Loss 0.062280    Objective Loss 0.062280                                        LR 0.100000    Time 0.028892    
2022-01-25 18:29:28,057 - Epoch: [64][  190/  211]    Overall Loss 0.062116    Objective Loss 0.062116                                        LR 0.100000    Time 0.028880    
2022-01-25 18:29:28,300 - Epoch: [64][  200/  211]    Overall Loss 0.062096    Objective Loss 0.062096                                        LR 0.100000    Time 0.028648    
2022-01-25 18:29:28,585 - Epoch: [64][  210/  211]    Overall Loss 0.062054    Objective Loss 0.062054    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.028639    
2022-01-25 18:29:28,605 - Epoch: [64][  211/  211]    Overall Loss 0.061992    Objective Loss 0.061992    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.028596    
2022-01-25 18:29:28,664 - --- validate (epoch=64)-----------
2022-01-25 18:29:28,664 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:29,142 - Epoch: [64][   10/   24]    Loss 0.071705    Top1 98.203125    Top5 100.000000    
2022-01-25 18:29:29,399 - Epoch: [64][   20/   24]    Loss 0.068830    Top1 98.261719    Top5 100.000000    
2022-01-25 18:29:29,444 - Epoch: [64][   24/   24]    Loss 0.069316    Top1 98.216667    Top5 100.000000    
2022-01-25 18:29:29,503 - ==> Top1: 98.217    Top5: 100.000    Loss: 0.069

2022-01-25 18:29:29,504 - ==> Confusion:
[[595   0   3   0   0   0   4   0   1   2]
 [  0 675   3   2   2   0   3   3   0   0]
 [  1   0 581   1   0   0   0   2   1   0]
 [  0   0   2 576   0   2   0   1   1   1]
 [  1   0   2   0 539   0   2   1   0  20]
 [  0   0   0   2   0 510   4   0   1   1]
 [  2   0   0   0   2   1 625   0   1   0]
 [  0   1   5   1   0   0   0 617   0   1]
 [  2   0   3   2   3   0   3   0 571   0]
 [  1   1   0   1   2   2   0   2   2 604]]

2022-01-25 18:29:29,506 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:29,506 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:29,514 - 

2022-01-25 18:29:29,514 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:30,296 - Epoch: [65][   10/  211]    Overall Loss 0.063341    Objective Loss 0.063341                                        LR 0.100000    Time 0.078066    
2022-01-25 18:29:30,555 - Epoch: [65][   20/  211]    Overall Loss 0.062244    Objective Loss 0.062244                                        LR 0.100000    Time 0.051976    
2022-01-25 18:29:30,826 - Epoch: [65][   30/  211]    Overall Loss 0.062524    Objective Loss 0.062524                                        LR 0.100000    Time 0.043658    
2022-01-25 18:29:31,040 - Epoch: [65][   40/  211]    Overall Loss 0.064310    Objective Loss 0.064310                                        LR 0.100000    Time 0.038079    
2022-01-25 18:29:31,271 - Epoch: [65][   50/  211]    Overall Loss 0.065330    Objective Loss 0.065330                                        LR 0.100000    Time 0.035088    
2022-01-25 18:29:31,490 - Epoch: [65][   60/  211]    Overall Loss 0.065421    Objective Loss 0.065421                                        LR 0.100000    Time 0.032875    
2022-01-25 18:29:31,723 - Epoch: [65][   70/  211]    Overall Loss 0.064480    Objective Loss 0.064480                                        LR 0.100000    Time 0.031499    
2022-01-25 18:29:31,931 - Epoch: [65][   80/  211]    Overall Loss 0.065048    Objective Loss 0.065048                                        LR 0.100000    Time 0.030162    
2022-01-25 18:29:32,161 - Epoch: [65][   90/  211]    Overall Loss 0.062807    Objective Loss 0.062807                                        LR 0.100000    Time 0.029358    
2022-01-25 18:29:32,368 - Epoch: [65][  100/  211]    Overall Loss 0.063237    Objective Loss 0.063237                                        LR 0.100000    Time 0.028495    
2022-01-25 18:29:32,606 - Epoch: [65][  110/  211]    Overall Loss 0.063613    Objective Loss 0.063613                                        LR 0.100000    Time 0.028065    
2022-01-25 18:29:32,820 - Epoch: [65][  120/  211]    Overall Loss 0.063822    Objective Loss 0.063822                                        LR 0.100000    Time 0.027507    
2022-01-25 18:29:33,051 - Epoch: [65][  130/  211]    Overall Loss 0.064439    Objective Loss 0.064439                                        LR 0.100000    Time 0.027163    
2022-01-25 18:29:33,266 - Epoch: [65][  140/  211]    Overall Loss 0.064436    Objective Loss 0.064436                                        LR 0.100000    Time 0.026758    
2022-01-25 18:29:33,499 - Epoch: [65][  150/  211]    Overall Loss 0.064455    Objective Loss 0.064455                                        LR 0.100000    Time 0.026526    
2022-01-25 18:29:33,708 - Epoch: [65][  160/  211]    Overall Loss 0.063990    Objective Loss 0.063990                                        LR 0.100000    Time 0.026172    
2022-01-25 18:29:33,934 - Epoch: [65][  170/  211]    Overall Loss 0.064266    Objective Loss 0.064266                                        LR 0.100000    Time 0.025957    
2022-01-25 18:29:34,183 - Epoch: [65][  180/  211]    Overall Loss 0.064004    Objective Loss 0.064004                                        LR 0.100000    Time 0.025895    
2022-01-25 18:29:34,436 - Epoch: [65][  190/  211]    Overall Loss 0.063599    Objective Loss 0.063599                                        LR 0.100000    Time 0.025866    
2022-01-25 18:29:34,718 - Epoch: [65][  200/  211]    Overall Loss 0.063196    Objective Loss 0.063196                                        LR 0.100000    Time 0.025977    
2022-01-25 18:29:34,933 - Epoch: [65][  210/  211]    Overall Loss 0.062467    Objective Loss 0.062467    Top1 100.000000    Top5 100.000000    LR 0.100000    Time 0.025763    
2022-01-25 18:29:34,952 - Epoch: [65][  211/  211]    Overall Loss 0.062472    Objective Loss 0.062472    Top1 99.395161    Top5 100.000000    LR 0.100000    Time 0.025730    
2022-01-25 18:29:35,008 - --- validate (epoch=65)-----------
2022-01-25 18:29:35,009 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:35,520 - Epoch: [65][   10/   24]    Loss 0.055760    Top1 98.671875    Top5 99.960938    
2022-01-25 18:29:35,721 - Epoch: [65][   20/   24]    Loss 0.062742    Top1 98.457031    Top5 99.902344    
2022-01-25 18:29:35,806 - Epoch: [65][   24/   24]    Loss 0.062989    Top1 98.383333    Top5 99.916667    
2022-01-25 18:29:35,864 - ==> Top1: 98.383    Top5: 99.917    Loss: 0.063

2022-01-25 18:29:35,865 - ==> Confusion:
[[604   0   1   0   0   0   0   0   0   0]
 [  0 686   1   0   0   1   0   0   0   0]
 [  0   3 573   3   0   1   0   3   2   1]
 [  1   1   3 573   0   1   0   3   1   0]
 [  0   1   0   0 555   0   0   1   0   8]
 [  1   1   0   4   1 502   3   2   4   0]
 [  2   3   0   0   1   0 625   0   0   0]
 [  0   9   1   2   0   0   0 613   0   0]
 [  2   1   0   0   1   0   5   0 571   4]
 [  0   3   0   0   6   1   0   2   2 601]]

2022-01-25 18:29:35,866 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:35,866 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:35,873 - 

2022-01-25 18:29:35,873 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:36,474 - Epoch: [66][   10/  211]    Overall Loss 0.060762    Objective Loss 0.060762                                        LR 0.100000    Time 0.060001    
2022-01-25 18:29:36,720 - Epoch: [66][   20/  211]    Overall Loss 0.063518    Objective Loss 0.063518                                        LR 0.100000    Time 0.042265    
2022-01-25 18:29:36,998 - Epoch: [66][   30/  211]    Overall Loss 0.060958    Objective Loss 0.060958                                        LR 0.100000    Time 0.037449    
2022-01-25 18:29:37,247 - Epoch: [66][   40/  211]    Overall Loss 0.060223    Objective Loss 0.060223                                        LR 0.100000    Time 0.034308    
2022-01-25 18:29:37,531 - Epoch: [66][   50/  211]    Overall Loss 0.062111    Objective Loss 0.062111                                        LR 0.100000    Time 0.033107    
2022-01-25 18:29:37,751 - Epoch: [66][   60/  211]    Overall Loss 0.062952    Objective Loss 0.062952                                        LR 0.100000    Time 0.031254    
2022-01-25 18:29:37,984 - Epoch: [66][   70/  211]    Overall Loss 0.062883    Objective Loss 0.062883                                        LR 0.100000    Time 0.030111    
2022-01-25 18:29:38,192 - Epoch: [66][   80/  211]    Overall Loss 0.062566    Objective Loss 0.062566                                        LR 0.100000    Time 0.028941    
2022-01-25 18:29:38,433 - Epoch: [66][   90/  211]    Overall Loss 0.062123    Objective Loss 0.062123                                        LR 0.100000    Time 0.028403    
2022-01-25 18:29:38,646 - Epoch: [66][  100/  211]    Overall Loss 0.061285    Objective Loss 0.061285                                        LR 0.100000    Time 0.027689    
2022-01-25 18:29:38,876 - Epoch: [66][  110/  211]    Overall Loss 0.061367    Objective Loss 0.061367                                        LR 0.100000    Time 0.027260    
2022-01-25 18:29:39,087 - Epoch: [66][  120/  211]    Overall Loss 0.061384    Objective Loss 0.061384                                        LR 0.100000    Time 0.026745    
2022-01-25 18:29:39,322 - Epoch: [66][  130/  211]    Overall Loss 0.061787    Objective Loss 0.061787                                        LR 0.100000    Time 0.026492    
2022-01-25 18:29:39,535 - Epoch: [66][  140/  211]    Overall Loss 0.061942    Objective Loss 0.061942                                        LR 0.100000    Time 0.026122    
2022-01-25 18:29:39,759 - Epoch: [66][  150/  211]    Overall Loss 0.061998    Objective Loss 0.061998                                        LR 0.100000    Time 0.025869    
2022-01-25 18:29:39,976 - Epoch: [66][  160/  211]    Overall Loss 0.061836    Objective Loss 0.061836                                        LR 0.100000    Time 0.025604    
2022-01-25 18:29:40,214 - Epoch: [66][  170/  211]    Overall Loss 0.061376    Objective Loss 0.061376                                        LR 0.100000    Time 0.025499    
2022-01-25 18:29:40,423 - Epoch: [66][  180/  211]    Overall Loss 0.061325    Objective Loss 0.061325                                        LR 0.100000    Time 0.025242    
2022-01-25 18:29:40,647 - Epoch: [66][  190/  211]    Overall Loss 0.061663    Objective Loss 0.061663                                        LR 0.100000    Time 0.025092    
2022-01-25 18:29:40,858 - Epoch: [66][  200/  211]    Overall Loss 0.061384    Objective Loss 0.061384                                        LR 0.100000    Time 0.024890    
2022-01-25 18:29:41,086 - Epoch: [66][  210/  211]    Overall Loss 0.061228    Objective Loss 0.061228    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.024786    
2022-01-25 18:29:41,105 - Epoch: [66][  211/  211]    Overall Loss 0.061199    Objective Loss 0.061199    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.024757    
2022-01-25 18:29:41,188 - --- validate (epoch=66)-----------
2022-01-25 18:29:41,189 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:41,693 - Epoch: [66][   10/   24]    Loss 0.060956    Top1 98.515625    Top5 100.000000    
2022-01-25 18:29:41,894 - Epoch: [66][   20/   24]    Loss 0.057092    Top1 98.652344    Top5 100.000000    
2022-01-25 18:29:41,975 - Epoch: [66][   24/   24]    Loss 0.058550    Top1 98.566667    Top5 100.000000    
2022-01-25 18:29:42,034 - ==> Top1: 98.567    Top5: 100.000    Loss: 0.059

2022-01-25 18:29:42,035 - ==> Confusion:
[[598   0   2   1   0   0   4   0   0   0]
 [  0 683   4   0   0   0   0   1   0   0]
 [  0   1 583   0   0   0   0   1   1   0]
 [  0   0   4 574   0   2   0   0   3   0]
 [  0   0   1   0 557   0   0   0   1   6]
 [  1   2   0   1   0 506   5   1   1   1]
 [  0   2   0   0   3   0 625   0   1   0]
 [  0   0   4   0   1   1   0 619   0   0]
 [  0   0   0   1   2   2   5   0 571   3]
 [  0   1   0   0   7   2   0   4   3 598]]

2022-01-25 18:29:42,037 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:42,037 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:42,043 - 

2022-01-25 18:29:42,044 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:42,762 - Epoch: [67][   10/  211]    Overall Loss 0.064462    Objective Loss 0.064462                                        LR 0.100000    Time 0.071749    
2022-01-25 18:29:42,976 - Epoch: [67][   20/  211]    Overall Loss 0.062996    Objective Loss 0.062996                                        LR 0.100000    Time 0.046559    
2022-01-25 18:29:43,201 - Epoch: [67][   30/  211]    Overall Loss 0.062315    Objective Loss 0.062315                                        LR 0.100000    Time 0.038551    
2022-01-25 18:29:43,409 - Epoch: [67][   40/  211]    Overall Loss 0.062691    Objective Loss 0.062691                                        LR 0.100000    Time 0.034093    
2022-01-25 18:29:43,636 - Epoch: [67][   50/  211]    Overall Loss 0.063623    Objective Loss 0.063623                                        LR 0.100000    Time 0.031814    
2022-01-25 18:29:43,847 - Epoch: [67][   60/  211]    Overall Loss 0.063806    Objective Loss 0.063806                                        LR 0.100000    Time 0.030022    
2022-01-25 18:29:44,093 - Epoch: [67][   70/  211]    Overall Loss 0.063316    Objective Loss 0.063316                                        LR 0.100000    Time 0.029242    
2022-01-25 18:29:44,384 - Epoch: [67][   80/  211]    Overall Loss 0.062846    Objective Loss 0.062846                                        LR 0.100000    Time 0.029222    
2022-01-25 18:29:44,627 - Epoch: [67][   90/  211]    Overall Loss 0.062785    Objective Loss 0.062785                                        LR 0.100000    Time 0.028669    
2022-01-25 18:29:44,923 - Epoch: [67][  100/  211]    Overall Loss 0.063569    Objective Loss 0.063569                                        LR 0.100000    Time 0.028754    
2022-01-25 18:29:45,166 - Epoch: [67][  110/  211]    Overall Loss 0.063081    Objective Loss 0.063081                                        LR 0.100000    Time 0.028351    
2022-01-25 18:29:45,446 - Epoch: [67][  120/  211]    Overall Loss 0.062654    Objective Loss 0.062654                                        LR 0.100000    Time 0.028320    
2022-01-25 18:29:45,693 - Epoch: [67][  130/  211]    Overall Loss 0.062293    Objective Loss 0.062293                                        LR 0.100000    Time 0.028035    
2022-01-25 18:29:45,971 - Epoch: [67][  140/  211]    Overall Loss 0.062849    Objective Loss 0.062849                                        LR 0.100000    Time 0.028019    
2022-01-25 18:29:46,230 - Epoch: [67][  150/  211]    Overall Loss 0.062282    Objective Loss 0.062282                                        LR 0.100000    Time 0.027876    
2022-01-25 18:29:46,507 - Epoch: [67][  160/  211]    Overall Loss 0.062096    Objective Loss 0.062096                                        LR 0.100000    Time 0.027863    
2022-01-25 18:29:46,753 - Epoch: [67][  170/  211]    Overall Loss 0.062043    Objective Loss 0.062043                                        LR 0.100000    Time 0.027666    
2022-01-25 18:29:47,031 - Epoch: [67][  180/  211]    Overall Loss 0.061738    Objective Loss 0.061738                                        LR 0.100000    Time 0.027670    
2022-01-25 18:29:47,275 - Epoch: [67][  190/  211]    Overall Loss 0.061035    Objective Loss 0.061035                                        LR 0.100000    Time 0.027501    
2022-01-25 18:29:47,551 - Epoch: [67][  200/  211]    Overall Loss 0.061475    Objective Loss 0.061475                                        LR 0.100000    Time 0.027500    
2022-01-25 18:29:47,792 - Epoch: [67][  210/  211]    Overall Loss 0.061484    Objective Loss 0.061484    Top1 98.046875    Top5 99.609375    LR 0.100000    Time 0.027338    
2022-01-25 18:29:47,837 - Epoch: [67][  211/  211]    Overall Loss 0.061473    Objective Loss 0.061473    Top1 98.588710    Top5 99.798387    LR 0.100000    Time 0.027421    
2022-01-25 18:29:47,916 - --- validate (epoch=67)-----------
2022-01-25 18:29:47,916 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:48,446 - Epoch: [67][   10/   24]    Loss 0.052898    Top1 98.632812    Top5 99.960938    
2022-01-25 18:29:48,706 - Epoch: [67][   20/   24]    Loss 0.057029    Top1 98.476562    Top5 99.980469    
2022-01-25 18:29:48,808 - Epoch: [67][   24/   24]    Loss 0.057561    Top1 98.483333    Top5 99.983333    
2022-01-25 18:29:48,865 - ==> Top1: 98.483    Top5: 99.983    Loss: 0.058

2022-01-25 18:29:48,866 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 682   3   0   0   0   0   3   0   0]
 [  1   0 572   3   1   0   0   5   3   1]
 [  0   0   2 575   0   5   0   0   1   0]
 [  0   1   0   1 557   0   0   0   0   6]
 [  1   0   0   2   0 508   4   0   2   1]
 [  0   1   0   0   1   2 625   0   2   0]
 [  0   1   3   0   2   0   0 619   0   0]
 [  0   0   0   2   2   2   3   0 574   1]
 [  0   2   0   0  10   1   0   4   5 593]]

2022-01-25 18:29:48,868 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:48,868 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:48,874 - 

2022-01-25 18:29:48,874 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:49,426 - Epoch: [68][   10/  211]    Overall Loss 0.065206    Objective Loss 0.065206                                        LR 0.100000    Time 0.055151    
2022-01-25 18:29:49,640 - Epoch: [68][   20/  211]    Overall Loss 0.058509    Objective Loss 0.058509                                        LR 0.100000    Time 0.038222    
2022-01-25 18:29:49,867 - Epoch: [68][   30/  211]    Overall Loss 0.058701    Objective Loss 0.058701                                        LR 0.100000    Time 0.033030    
2022-01-25 18:29:50,077 - Epoch: [68][   40/  211]    Overall Loss 0.057808    Objective Loss 0.057808                                        LR 0.100000    Time 0.030033    
2022-01-25 18:29:50,299 - Epoch: [68][   50/  211]    Overall Loss 0.059501    Objective Loss 0.059501                                        LR 0.100000    Time 0.028458    
2022-01-25 18:29:50,511 - Epoch: [68][   60/  211]    Overall Loss 0.058357    Objective Loss 0.058357                                        LR 0.100000    Time 0.027242    
2022-01-25 18:29:50,747 - Epoch: [68][   70/  211]    Overall Loss 0.057198    Objective Loss 0.057198                                        LR 0.100000    Time 0.026714    
2022-01-25 18:29:50,957 - Epoch: [68][   80/  211]    Overall Loss 0.056396    Objective Loss 0.056396                                        LR 0.100000    Time 0.025992    
2022-01-25 18:29:51,183 - Epoch: [68][   90/  211]    Overall Loss 0.056305    Objective Loss 0.056305                                        LR 0.100000    Time 0.025619    
2022-01-25 18:29:51,400 - Epoch: [68][  100/  211]    Overall Loss 0.057870    Objective Loss 0.057870                                        LR 0.100000    Time 0.025215    
2022-01-25 18:29:51,633 - Epoch: [68][  110/  211]    Overall Loss 0.058311    Objective Loss 0.058311                                        LR 0.100000    Time 0.025042    
2022-01-25 18:29:51,842 - Epoch: [68][  120/  211]    Overall Loss 0.058759    Objective Loss 0.058759                                        LR 0.100000    Time 0.024692    
2022-01-25 18:29:52,062 - Epoch: [68][  130/  211]    Overall Loss 0.059713    Objective Loss 0.059713                                        LR 0.100000    Time 0.024484    
2022-01-25 18:29:52,286 - Epoch: [68][  140/  211]    Overall Loss 0.060301    Objective Loss 0.060301                                        LR 0.100000    Time 0.024332    
2022-01-25 18:29:52,510 - Epoch: [68][  150/  211]    Overall Loss 0.060285    Objective Loss 0.060285                                        LR 0.100000    Time 0.024199    
2022-01-25 18:29:52,723 - Epoch: [68][  160/  211]    Overall Loss 0.060999    Objective Loss 0.060999                                        LR 0.100000    Time 0.024018    
2022-01-25 18:29:52,947 - Epoch: [68][  170/  211]    Overall Loss 0.061283    Objective Loss 0.061283                                        LR 0.100000    Time 0.023919    
2022-01-25 18:29:53,173 - Epoch: [68][  180/  211]    Overall Loss 0.061578    Objective Loss 0.061578                                        LR 0.100000    Time 0.023849    
2022-01-25 18:29:53,398 - Epoch: [68][  190/  211]    Overall Loss 0.061270    Objective Loss 0.061270                                        LR 0.100000    Time 0.023775    
2022-01-25 18:29:53,611 - Epoch: [68][  200/  211]    Overall Loss 0.061170    Objective Loss 0.061170                                        LR 0.100000    Time 0.023647    
2022-01-25 18:29:53,833 - Epoch: [68][  210/  211]    Overall Loss 0.061317    Objective Loss 0.061317    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.023577    
2022-01-25 18:29:53,852 - Epoch: [68][  211/  211]    Overall Loss 0.061220    Objective Loss 0.061220    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.023554    
2022-01-25 18:29:53,927 - --- validate (epoch=68)-----------
2022-01-25 18:29:53,927 - 6000 samples (256 per mini-batch)
2022-01-25 18:29:54,402 - Epoch: [68][   10/   24]    Loss 0.063409    Top1 98.476562    Top5 100.000000    
2022-01-25 18:29:54,668 - Epoch: [68][   20/   24]    Loss 0.064448    Top1 98.300781    Top5 99.980469    
2022-01-25 18:29:54,771 - Epoch: [68][   24/   24]    Loss 0.062503    Top1 98.333333    Top5 99.966667    
2022-01-25 18:29:54,827 - ==> Top1: 98.333    Top5: 99.967    Loss: 0.063

2022-01-25 18:29:54,828 - ==> Confusion:
[[597   1   1   0   0   0   4   0   1   1]
 [  0 684   1   0   1   0   0   2   0   0]
 [  0   0 579   0   0   0   2   4   1   0]
 [  0   1   3 569   0   4   0   5   1   0]
 [  0   1   1   0 553   1   0   1   0   8]
 [  0   0   0   3   0 509   4   0   2   0]
 [  1   2   0   0   3   1 621   0   3   0]
 [  1   1   0   1   1   0   0 621   0   0]
 [  1   0   1   0   5   0   5   1 570   1]
 [  1   1   1   1   9   2   0   2   1 597]]

2022-01-25 18:29:54,830 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:29:54,830 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:29:54,837 - 

2022-01-25 18:29:54,837 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:29:55,547 - Epoch: [69][   10/  211]    Overall Loss 0.050858    Objective Loss 0.050858                                        LR 0.100000    Time 0.070987    
2022-01-25 18:29:55,755 - Epoch: [69][   20/  211]    Overall Loss 0.055710    Objective Loss 0.055710                                        LR 0.100000    Time 0.045855    
2022-01-25 18:29:55,977 - Epoch: [69][   30/  211]    Overall Loss 0.058069    Objective Loss 0.058069                                        LR 0.100000    Time 0.037952    
2022-01-25 18:29:56,183 - Epoch: [69][   40/  211]    Overall Loss 0.061146    Objective Loss 0.061146                                        LR 0.100000    Time 0.033603    
2022-01-25 18:29:56,398 - Epoch: [69][   50/  211]    Overall Loss 0.062229    Objective Loss 0.062229                                        LR 0.100000    Time 0.031185    
2022-01-25 18:29:56,608 - Epoch: [69][   60/  211]    Overall Loss 0.061903    Objective Loss 0.061903                                        LR 0.100000    Time 0.029482    
2022-01-25 18:29:56,873 - Epoch: [69][   70/  211]    Overall Loss 0.062764    Objective Loss 0.062764                                        LR 0.100000    Time 0.029043    
2022-01-25 18:29:57,121 - Epoch: [69][   80/  211]    Overall Loss 0.063076    Objective Loss 0.063076                                        LR 0.100000    Time 0.028514    
2022-01-25 18:29:57,398 - Epoch: [69][   90/  211]    Overall Loss 0.062436    Objective Loss 0.062436                                        LR 0.100000    Time 0.028422    
2022-01-25 18:29:57,645 - Epoch: [69][  100/  211]    Overall Loss 0.062251    Objective Loss 0.062251                                        LR 0.100000    Time 0.028040    
2022-01-25 18:29:57,932 - Epoch: [69][  110/  211]    Overall Loss 0.063267    Objective Loss 0.063267                                        LR 0.100000    Time 0.028100    
2022-01-25 18:29:58,179 - Epoch: [69][  120/  211]    Overall Loss 0.063517    Objective Loss 0.063517                                        LR 0.100000    Time 0.027818    
2022-01-25 18:29:58,461 - Epoch: [69][  130/  211]    Overall Loss 0.063581    Objective Loss 0.063581                                        LR 0.100000    Time 0.027837    
2022-01-25 18:29:58,717 - Epoch: [69][  140/  211]    Overall Loss 0.062315    Objective Loss 0.062315                                        LR 0.100000    Time 0.027676    
2022-01-25 18:29:58,995 - Epoch: [69][  150/  211]    Overall Loss 0.062227    Objective Loss 0.062227                                        LR 0.100000    Time 0.027685    
2022-01-25 18:29:59,240 - Epoch: [69][  160/  211]    Overall Loss 0.061952    Objective Loss 0.061952                                        LR 0.100000    Time 0.027480    
2022-01-25 18:29:59,523 - Epoch: [69][  170/  211]    Overall Loss 0.061404    Objective Loss 0.061404                                        LR 0.100000    Time 0.027526    
2022-01-25 18:29:59,775 - Epoch: [69][  180/  211]    Overall Loss 0.061407    Objective Loss 0.061407                                        LR 0.100000    Time 0.027398    
2022-01-25 18:30:00,054 - Epoch: [69][  190/  211]    Overall Loss 0.060867    Objective Loss 0.060867                                        LR 0.100000    Time 0.027419    
2022-01-25 18:30:00,299 - Epoch: [69][  200/  211]    Overall Loss 0.060430    Objective Loss 0.060430                                        LR 0.100000    Time 0.027275    
2022-01-25 18:30:00,580 - Epoch: [69][  210/  211]    Overall Loss 0.060448    Objective Loss 0.060448    Top1 96.875000    Top5 100.000000    LR 0.100000    Time 0.027313    
2022-01-25 18:30:00,600 - Epoch: [69][  211/  211]    Overall Loss 0.060447    Objective Loss 0.060447    Top1 97.782258    Top5 100.000000    LR 0.100000    Time 0.027274    
2022-01-25 18:30:00,656 - --- validate (epoch=69)-----------
2022-01-25 18:30:00,656 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:01,129 - Epoch: [69][   10/   24]    Loss 0.048562    Top1 98.906250    Top5 99.960938    
2022-01-25 18:30:01,320 - Epoch: [69][   20/   24]    Loss 0.058467    Top1 98.574219    Top5 99.960938    
2022-01-25 18:30:01,411 - Epoch: [69][   24/   24]    Loss 0.059910    Top1 98.500000    Top5 99.966667    
2022-01-25 18:30:01,470 - ==> Top1: 98.500    Top5: 99.967    Loss: 0.060

2022-01-25 18:30:01,470 - ==> Confusion:
[[599   0   1   2   0   0   2   1   0   0]
 [  0 683   1   0   0   0   0   4   0   0]
 [  0   1 574   1   0   0   0   8   2   0]
 [  0   0   1 577   1   0   0   3   1   0]
 [  0   1   1   0 551   0   0   1   3   8]
 [  0   0   0   6   0 507   2   0   3   0]
 [  0   2   0   0   2   1 625   0   1   0]
 [  0   1   1   3   0   0   0 620   0   0]
 [  1   1   0   6   0   0   1   0 574   1]
 [  0   2   0   2   2   1   0   5   3 600]]

2022-01-25 18:30:01,472 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:30:01,472 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:01,479 - 

2022-01-25 18:30:01,479 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:02,191 - Epoch: [70][   10/  211]    Overall Loss 0.052206    Objective Loss 0.052206                                        LR 0.100000    Time 0.071170    
2022-01-25 18:30:02,402 - Epoch: [70][   20/  211]    Overall Loss 0.056334    Objective Loss 0.056334                                        LR 0.100000    Time 0.046103    
2022-01-25 18:30:02,629 - Epoch: [70][   30/  211]    Overall Loss 0.053899    Objective Loss 0.053899                                        LR 0.100000    Time 0.038289    
2022-01-25 18:30:02,837 - Epoch: [70][   40/  211]    Overall Loss 0.056221    Objective Loss 0.056221                                        LR 0.100000    Time 0.033908    
2022-01-25 18:30:03,064 - Epoch: [70][   50/  211]    Overall Loss 0.057811    Objective Loss 0.057811                                        LR 0.100000    Time 0.031668    
2022-01-25 18:30:03,298 - Epoch: [70][   60/  211]    Overall Loss 0.058789    Objective Loss 0.058789                                        LR 0.100000    Time 0.030283    
2022-01-25 18:30:03,575 - Epoch: [70][   70/  211]    Overall Loss 0.058682    Objective Loss 0.058682                                        LR 0.100000    Time 0.029896    
2022-01-25 18:30:03,820 - Epoch: [70][   80/  211]    Overall Loss 0.058764    Objective Loss 0.058764                                        LR 0.100000    Time 0.029220    
2022-01-25 18:30:04,098 - Epoch: [70][   90/  211]    Overall Loss 0.058630    Objective Loss 0.058630                                        LR 0.100000    Time 0.029056    
2022-01-25 18:30:04,351 - Epoch: [70][  100/  211]    Overall Loss 0.059048    Objective Loss 0.059048                                        LR 0.100000    Time 0.028681    
2022-01-25 18:30:04,628 - Epoch: [70][  110/  211]    Overall Loss 0.058375    Objective Loss 0.058375                                        LR 0.100000    Time 0.028588    
2022-01-25 18:30:04,878 - Epoch: [70][  120/  211]    Overall Loss 0.058278    Objective Loss 0.058278                                        LR 0.100000    Time 0.028284    
2022-01-25 18:30:05,154 - Epoch: [70][  130/  211]    Overall Loss 0.058330    Objective Loss 0.058330                                        LR 0.100000    Time 0.028234    
2022-01-25 18:30:05,405 - Epoch: [70][  140/  211]    Overall Loss 0.058142    Objective Loss 0.058142                                        LR 0.100000    Time 0.028004    
2022-01-25 18:30:05,692 - Epoch: [70][  150/  211]    Overall Loss 0.057708    Objective Loss 0.057708                                        LR 0.100000    Time 0.028046    
2022-01-25 18:30:05,941 - Epoch: [70][  160/  211]    Overall Loss 0.057294    Objective Loss 0.057294                                        LR 0.100000    Time 0.027850    
2022-01-25 18:30:06,217 - Epoch: [70][  170/  211]    Overall Loss 0.057902    Objective Loss 0.057902                                        LR 0.100000    Time 0.027833    
2022-01-25 18:30:06,467 - Epoch: [70][  180/  211]    Overall Loss 0.058179    Objective Loss 0.058179                                        LR 0.100000    Time 0.027676    
2022-01-25 18:30:06,745 - Epoch: [70][  190/  211]    Overall Loss 0.057984    Objective Loss 0.057984                                        LR 0.100000    Time 0.027677    
2022-01-25 18:30:06,991 - Epoch: [70][  200/  211]    Overall Loss 0.057934    Objective Loss 0.057934                                        LR 0.100000    Time 0.027524    
2022-01-25 18:30:07,274 - Epoch: [70][  210/  211]    Overall Loss 0.058736    Objective Loss 0.058736    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.027558    
2022-01-25 18:30:07,294 - Epoch: [70][  211/  211]    Overall Loss 0.058769    Objective Loss 0.058769    Top1 97.782258    Top5 100.000000    LR 0.100000    Time 0.027521    
2022-01-25 18:30:07,350 - --- validate (epoch=70)-----------
2022-01-25 18:30:07,351 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:07,830 - Epoch: [70][   10/   24]    Loss 0.065048    Top1 98.281250    Top5 100.000000    
2022-01-25 18:30:08,074 - Epoch: [70][   20/   24]    Loss 0.064991    Top1 98.359375    Top5 100.000000    
2022-01-25 18:30:08,157 - Epoch: [70][   24/   24]    Loss 0.060663    Top1 98.500000    Top5 100.000000    
2022-01-25 18:30:08,217 - ==> Top1: 98.500    Top5: 100.000    Loss: 0.061

2022-01-25 18:30:08,218 - ==> Confusion:
[[603   0   0   0   0   0   1   0   1   0]
 [  0 685   0   0   1   0   0   2   0   0]
 [  0   0 575   0   0   1   0   7   3   0]
 [  0   1   2 577   0   2   0   0   1   0]
 [  0   0   0   0 561   0   0   0   1   3]
 [  1   0   0   2   0 507   4   0   4   0]
 [  2   1   0   0   3   0 623   0   2   0]
 [  1   2   1   0   0   0   0 620   0   1]
 [  3   1   0   1   0   0   5   1 573   0]
 [  0   2   0   0  16   2   0   4   5 586]]

2022-01-25 18:30:08,220 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:30:08,220 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:08,227 - 

2022-01-25 18:30:08,227 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:08,786 - Epoch: [71][   10/  211]    Overall Loss 0.066122    Objective Loss 0.066122                                        LR 0.100000    Time 0.055813    
2022-01-25 18:30:09,026 - Epoch: [71][   20/  211]    Overall Loss 0.065621    Objective Loss 0.065621                                        LR 0.100000    Time 0.039868    
2022-01-25 18:30:09,301 - Epoch: [71][   30/  211]    Overall Loss 0.064608    Objective Loss 0.064608                                        LR 0.100000    Time 0.035739    
2022-01-25 18:30:09,548 - Epoch: [71][   40/  211]    Overall Loss 0.062046    Objective Loss 0.062046                                        LR 0.100000    Time 0.032987    
2022-01-25 18:30:09,832 - Epoch: [71][   50/  211]    Overall Loss 0.060624    Objective Loss 0.060624                                        LR 0.100000    Time 0.032049    
2022-01-25 18:30:10,086 - Epoch: [71][   60/  211]    Overall Loss 0.061030    Objective Loss 0.061030                                        LR 0.100000    Time 0.030947    
2022-01-25 18:30:10,364 - Epoch: [71][   70/  211]    Overall Loss 0.060622    Objective Loss 0.060622                                        LR 0.100000    Time 0.030486    
2022-01-25 18:30:10,612 - Epoch: [71][   80/  211]    Overall Loss 0.059678    Objective Loss 0.059678                                        LR 0.100000    Time 0.029771    
2022-01-25 18:30:10,895 - Epoch: [71][   90/  211]    Overall Loss 0.060366    Objective Loss 0.060366                                        LR 0.100000    Time 0.029601    
2022-01-25 18:30:11,143 - Epoch: [71][  100/  211]    Overall Loss 0.060132    Objective Loss 0.060132                                        LR 0.100000    Time 0.029123    
2022-01-25 18:30:11,430 - Epoch: [71][  110/  211]    Overall Loss 0.059834    Objective Loss 0.059834                                        LR 0.100000    Time 0.029078    
2022-01-25 18:30:11,682 - Epoch: [71][  120/  211]    Overall Loss 0.059682    Objective Loss 0.059682                                        LR 0.100000    Time 0.028755    
2022-01-25 18:30:11,960 - Epoch: [71][  130/  211]    Overall Loss 0.059706    Objective Loss 0.059706                                        LR 0.100000    Time 0.028678    
2022-01-25 18:30:12,207 - Epoch: [71][  140/  211]    Overall Loss 0.059324    Objective Loss 0.059324                                        LR 0.100000    Time 0.028388    
2022-01-25 18:30:12,499 - Epoch: [71][  150/  211]    Overall Loss 0.059437    Objective Loss 0.059437                                        LR 0.100000    Time 0.028440    
2022-01-25 18:30:12,741 - Epoch: [71][  160/  211]    Overall Loss 0.059765    Objective Loss 0.059765                                        LR 0.100000    Time 0.028177    
2022-01-25 18:30:13,013 - Epoch: [71][  170/  211]    Overall Loss 0.059696    Objective Loss 0.059696                                        LR 0.100000    Time 0.028117    
2022-01-25 18:30:13,239 - Epoch: [71][  180/  211]    Overall Loss 0.059392    Objective Loss 0.059392                                        LR 0.100000    Time 0.027808    
2022-01-25 18:30:13,483 - Epoch: [71][  190/  211]    Overall Loss 0.059172    Objective Loss 0.059172                                        LR 0.100000    Time 0.027628    
2022-01-25 18:30:13,703 - Epoch: [71][  200/  211]    Overall Loss 0.059314    Objective Loss 0.059314                                        LR 0.100000    Time 0.027343    
2022-01-25 18:30:13,927 - Epoch: [71][  210/  211]    Overall Loss 0.059836    Objective Loss 0.059836    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.027107    
2022-01-25 18:30:13,945 - Epoch: [71][  211/  211]    Overall Loss 0.059798    Objective Loss 0.059798    Top1 97.782258    Top5 100.000000    LR 0.100000    Time 0.027064    
2022-01-25 18:30:14,001 - --- validate (epoch=71)-----------
2022-01-25 18:30:14,001 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:14,473 - Epoch: [71][   10/   24]    Loss 0.062129    Top1 98.437500    Top5 99.960938    
2022-01-25 18:30:14,672 - Epoch: [71][   20/   24]    Loss 0.060099    Top1 98.593750    Top5 99.980469    
2022-01-25 18:30:14,758 - Epoch: [71][   24/   24]    Loss 0.060703    Top1 98.616667    Top5 99.983333    
2022-01-25 18:30:14,812 - ==> Top1: 98.617    Top5: 99.983    Loss: 0.061

2022-01-25 18:30:14,813 - ==> Confusion:
[[601   0   1   0   0   0   1   1   1   0]
 [  0 685   0   1   0   1   0   1   0   0]
 [  0   1 573   2   0   0   1   4   3   2]
 [  0   0   0 576   0   1   0   2   4   0]
 [  0   1   0   0 558   0   0   1   0   5]
 [  1   2   0   3   0 506   2   0   4   0]
 [  2   4   0   0   1   3 620   0   1   0]
 [  0   3   0   2   1   0   0 618   0   1]
 [  1   0   0   1   3   1   0   0 576   2]
 [  0   1   0   2   3   0   0   2   4 603]]

2022-01-25 18:30:14,815 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:30:14,815 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:14,822 - 

2022-01-25 18:30:14,822 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:15,525 - Epoch: [72][   10/  211]    Overall Loss 0.050997    Objective Loss 0.050997                                        LR 0.100000    Time 0.070257    
2022-01-25 18:30:15,740 - Epoch: [72][   20/  211]    Overall Loss 0.054456    Objective Loss 0.054456                                        LR 0.100000    Time 0.045843    
2022-01-25 18:30:15,962 - Epoch: [72][   30/  211]    Overall Loss 0.056969    Objective Loss 0.056969                                        LR 0.100000    Time 0.037943    
2022-01-25 18:30:16,181 - Epoch: [72][   40/  211]    Overall Loss 0.057687    Objective Loss 0.057687                                        LR 0.100000    Time 0.033920    
2022-01-25 18:30:16,434 - Epoch: [72][   50/  211]    Overall Loss 0.057149    Objective Loss 0.057149                                        LR 0.100000    Time 0.032199    
2022-01-25 18:30:16,685 - Epoch: [72][   60/  211]    Overall Loss 0.057552    Objective Loss 0.057552                                        LR 0.100000    Time 0.031014    
2022-01-25 18:30:16,972 - Epoch: [72][   70/  211]    Overall Loss 0.057609    Objective Loss 0.057609                                        LR 0.100000    Time 0.030666    
2022-01-25 18:30:17,216 - Epoch: [72][   80/  211]    Overall Loss 0.059661    Objective Loss 0.059661                                        LR 0.100000    Time 0.029883    
2022-01-25 18:30:17,502 - Epoch: [72][   90/  211]    Overall Loss 0.059481    Objective Loss 0.059481                                        LR 0.100000    Time 0.029732    
2022-01-25 18:30:17,751 - Epoch: [72][  100/  211]    Overall Loss 0.060053    Objective Loss 0.060053                                        LR 0.100000    Time 0.029250    
2022-01-25 18:30:18,038 - Epoch: [72][  110/  211]    Overall Loss 0.060090    Objective Loss 0.060090                                        LR 0.100000    Time 0.029200    
2022-01-25 18:30:18,286 - Epoch: [72][  120/  211]    Overall Loss 0.060078    Objective Loss 0.060078                                        LR 0.100000    Time 0.028827    
2022-01-25 18:30:18,546 - Epoch: [72][  130/  211]    Overall Loss 0.059352    Objective Loss 0.059352                                        LR 0.100000    Time 0.028610    
2022-01-25 18:30:18,800 - Epoch: [72][  140/  211]    Overall Loss 0.059424    Objective Loss 0.059424                                        LR 0.100000    Time 0.028376    
2022-01-25 18:30:19,078 - Epoch: [72][  150/  211]    Overall Loss 0.059198    Objective Loss 0.059198                                        LR 0.100000    Time 0.028337    
2022-01-25 18:30:19,325 - Epoch: [72][  160/  211]    Overall Loss 0.059336    Objective Loss 0.059336                                        LR 0.100000    Time 0.028100    
2022-01-25 18:30:19,606 - Epoch: [72][  170/  211]    Overall Loss 0.059621    Objective Loss 0.059621                                        LR 0.100000    Time 0.028103    
2022-01-25 18:30:19,859 - Epoch: [72][  180/  211]    Overall Loss 0.060075    Objective Loss 0.060075                                        LR 0.100000    Time 0.027944    
2022-01-25 18:30:20,141 - Epoch: [72][  190/  211]    Overall Loss 0.060187    Objective Loss 0.060187                                        LR 0.100000    Time 0.027952    
2022-01-25 18:30:20,387 - Epoch: [72][  200/  211]    Overall Loss 0.060111    Objective Loss 0.060111                                        LR 0.100000    Time 0.027787    
2022-01-25 18:30:20,669 - Epoch: [72][  210/  211]    Overall Loss 0.059724    Objective Loss 0.059724    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.027804    
2022-01-25 18:30:20,689 - Epoch: [72][  211/  211]    Overall Loss 0.059644    Objective Loss 0.059644    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.027766    
2022-01-25 18:30:20,753 - --- validate (epoch=72)-----------
2022-01-25 18:30:20,754 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:21,237 - Epoch: [72][   10/   24]    Loss 0.062806    Top1 98.085938    Top5 100.000000    
2022-01-25 18:30:21,436 - Epoch: [72][   20/   24]    Loss 0.071078    Top1 98.144531    Top5 100.000000    
2022-01-25 18:30:21,519 - Epoch: [72][   24/   24]    Loss 0.068627    Top1 98.216667    Top5 100.000000    
2022-01-25 18:30:21,578 - ==> Top1: 98.217    Top5: 100.000    Loss: 0.069

2022-01-25 18:30:21,579 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 681   1   0   0   2   0   4   0   0]
 [  0   1 556   6   1   0   0  10  10   2]
 [  1   0   0 577   0   0   0   2   1   2]
 [  0   1   1   0 543   0   1   2   1  16]
 [  0   0   0   2   0 509   2   0   4   1]
 [  2   2   0   0   1   1 621   0   4   0]
 [  0   2   0   2   1   0   0 619   0   1]
 [  0   0   0   1   0   1   3   0 577   2]
 [  0   0   0   2   0   1   0   1   3 608]]

2022-01-25 18:30:21,580 - ==> Best [Top1: 98.617   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 58]
2022-01-25 18:30:21,580 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:21,587 - 

2022-01-25 18:30:21,587 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:22,295 - Epoch: [73][   10/  211]    Overall Loss 0.060086    Objective Loss 0.060086                                        LR 0.100000    Time 0.070706    
2022-01-25 18:30:22,506 - Epoch: [73][   20/  211]    Overall Loss 0.062754    Objective Loss 0.062754                                        LR 0.100000    Time 0.045876    
2022-01-25 18:30:22,726 - Epoch: [73][   30/  211]    Overall Loss 0.061230    Objective Loss 0.061230                                        LR 0.100000    Time 0.037921    
2022-01-25 18:30:22,928 - Epoch: [73][   40/  211]    Overall Loss 0.059757    Objective Loss 0.059757                                        LR 0.100000    Time 0.033492    
2022-01-25 18:30:23,156 - Epoch: [73][   50/  211]    Overall Loss 0.059404    Objective Loss 0.059404                                        LR 0.100000    Time 0.031332    
2022-01-25 18:30:23,371 - Epoch: [73][   60/  211]    Overall Loss 0.059600    Objective Loss 0.059600                                        LR 0.100000    Time 0.029700    
2022-01-25 18:30:23,591 - Epoch: [73][   70/  211]    Overall Loss 0.059403    Objective Loss 0.059403                                        LR 0.100000    Time 0.028583    
2022-01-25 18:30:23,799 - Epoch: [73][   80/  211]    Overall Loss 0.059114    Objective Loss 0.059114                                        LR 0.100000    Time 0.027608    
2022-01-25 18:30:24,019 - Epoch: [73][   90/  211]    Overall Loss 0.058994    Objective Loss 0.058994                                        LR 0.100000    Time 0.026978    
2022-01-25 18:30:24,228 - Epoch: [73][  100/  211]    Overall Loss 0.059491    Objective Loss 0.059491                                        LR 0.100000    Time 0.026369    
2022-01-25 18:30:24,457 - Epoch: [73][  110/  211]    Overall Loss 0.059356    Objective Loss 0.059356                                        LR 0.100000    Time 0.026050    
2022-01-25 18:30:24,668 - Epoch: [73][  120/  211]    Overall Loss 0.059621    Objective Loss 0.059621                                        LR 0.100000    Time 0.025639    
2022-01-25 18:30:24,900 - Epoch: [73][  130/  211]    Overall Loss 0.059827    Objective Loss 0.059827                                        LR 0.100000    Time 0.025445    
2022-01-25 18:30:25,112 - Epoch: [73][  140/  211]    Overall Loss 0.059645    Objective Loss 0.059645                                        LR 0.100000    Time 0.025138    
2022-01-25 18:30:25,334 - Epoch: [73][  150/  211]    Overall Loss 0.059699    Objective Loss 0.059699                                        LR 0.100000    Time 0.024945    
2022-01-25 18:30:25,550 - Epoch: [73][  160/  211]    Overall Loss 0.059380    Objective Loss 0.059380                                        LR 0.100000    Time 0.024733    
2022-01-25 18:30:25,774 - Epoch: [73][  170/  211]    Overall Loss 0.059199    Objective Loss 0.059199                                        LR 0.100000    Time 0.024591    
2022-01-25 18:30:25,986 - Epoch: [73][  180/  211]    Overall Loss 0.058973    Objective Loss 0.058973                                        LR 0.100000    Time 0.024400    
2022-01-25 18:30:26,219 - Epoch: [73][  190/  211]    Overall Loss 0.058794    Objective Loss 0.058794                                        LR 0.100000    Time 0.024340    
2022-01-25 18:30:26,467 - Epoch: [73][  200/  211]    Overall Loss 0.058846    Objective Loss 0.058846                                        LR 0.100000    Time 0.024364    
2022-01-25 18:30:26,716 - Epoch: [73][  210/  211]    Overall Loss 0.058954    Objective Loss 0.058954    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.024386    
2022-01-25 18:30:26,758 - Epoch: [73][  211/  211]    Overall Loss 0.058908    Objective Loss 0.058908    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.024470    
2022-01-25 18:30:26,816 - --- validate (epoch=73)-----------
2022-01-25 18:30:26,817 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:27,297 - Epoch: [73][   10/   24]    Loss 0.062240    Top1 98.593750    Top5 99.960938    
2022-01-25 18:30:27,492 - Epoch: [73][   20/   24]    Loss 0.060241    Top1 98.613281    Top5 99.960938    
2022-01-25 18:30:27,575 - Epoch: [73][   24/   24]    Loss 0.058495    Top1 98.633333    Top5 99.966667    
2022-01-25 18:30:27,637 - ==> Top1: 98.633    Top5: 99.967    Loss: 0.058

2022-01-25 18:30:27,638 - ==> Confusion:
[[602   0   0   0   0   0   3   0   0   0]
 [  0 685   0   1   0   0   0   1   1   0]
 [  0   1 581   2   0   0   1   1   0   0]
 [  1   0   3 574   0   1   0   1   3   0]
 [  0   0   1   0 552   1   1   1   0   9]
 [  0   0   0   2   0 507   3   0   4   2]
 [  0   0   0   0   0   0 629   0   2   0]
 [  1   3   3   2   1   0   0 614   0   1]
 [  1   0   1   1   1   1   2   0 577   0]
 [  0   1   0   0  10   2   0   2   3 597]]

2022-01-25 18:30:27,639 - ==> Best [Top1: 98.633   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 73]
2022-01-25 18:30:27,639 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:27,647 - 

2022-01-25 18:30:27,647 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:28,194 - Epoch: [74][   10/  211]    Overall Loss 0.066880    Objective Loss 0.066880                                        LR 0.100000    Time 0.054621    
2022-01-25 18:30:28,450 - Epoch: [74][   20/  211]    Overall Loss 0.066411    Objective Loss 0.066411                                        LR 0.100000    Time 0.040075    
2022-01-25 18:30:28,689 - Epoch: [74][   30/  211]    Overall Loss 0.065907    Objective Loss 0.065907                                        LR 0.100000    Time 0.034687    
2022-01-25 18:30:28,907 - Epoch: [74][   40/  211]    Overall Loss 0.064763    Objective Loss 0.064763                                        LR 0.100000    Time 0.031450    
2022-01-25 18:30:29,135 - Epoch: [74][   50/  211]    Overall Loss 0.062060    Objective Loss 0.062060                                        LR 0.100000    Time 0.029713    
2022-01-25 18:30:29,356 - Epoch: [74][   60/  211]    Overall Loss 0.061071    Objective Loss 0.061071                                        LR 0.100000    Time 0.028452    
2022-01-25 18:30:29,572 - Epoch: [74][   70/  211]    Overall Loss 0.061647    Objective Loss 0.061647                                        LR 0.100000    Time 0.027456    
2022-01-25 18:30:29,789 - Epoch: [74][   80/  211]    Overall Loss 0.061810    Objective Loss 0.061810                                        LR 0.100000    Time 0.026743    
2022-01-25 18:30:30,006 - Epoch: [74][   90/  211]    Overall Loss 0.061346    Objective Loss 0.061346                                        LR 0.100000    Time 0.026172    
2022-01-25 18:30:30,231 - Epoch: [74][  100/  211]    Overall Loss 0.061567    Objective Loss 0.061567                                        LR 0.100000    Time 0.025800    
2022-01-25 18:30:30,456 - Epoch: [74][  110/  211]    Overall Loss 0.061092    Objective Loss 0.061092                                        LR 0.100000    Time 0.025498    
2022-01-25 18:30:30,686 - Epoch: [74][  120/  211]    Overall Loss 0.061821    Objective Loss 0.061821                                        LR 0.100000    Time 0.025289    
2022-01-25 18:30:30,895 - Epoch: [74][  130/  211]    Overall Loss 0.061340    Objective Loss 0.061340                                        LR 0.100000    Time 0.024948    
2022-01-25 18:30:31,128 - Epoch: [74][  140/  211]    Overall Loss 0.061193    Objective Loss 0.061193                                        LR 0.100000    Time 0.024825    
2022-01-25 18:30:31,346 - Epoch: [74][  150/  211]    Overall Loss 0.060880    Objective Loss 0.060880                                        LR 0.100000    Time 0.024620    
2022-01-25 18:30:31,574 - Epoch: [74][  160/  211]    Overall Loss 0.061103    Objective Loss 0.061103                                        LR 0.100000    Time 0.024508    
2022-01-25 18:30:31,785 - Epoch: [74][  170/  211]    Overall Loss 0.061754    Objective Loss 0.061754                                        LR 0.100000    Time 0.024304    
2022-01-25 18:30:32,025 - Epoch: [74][  180/  211]    Overall Loss 0.061570    Objective Loss 0.061570                                        LR 0.100000    Time 0.024283    
2022-01-25 18:30:32,240 - Epoch: [74][  190/  211]    Overall Loss 0.061123    Objective Loss 0.061123                                        LR 0.100000    Time 0.024134    
2022-01-25 18:30:32,476 - Epoch: [74][  200/  211]    Overall Loss 0.060735    Objective Loss 0.060735                                        LR 0.100000    Time 0.024106    
2022-01-25 18:30:32,752 - Epoch: [74][  210/  211]    Overall Loss 0.060562    Objective Loss 0.060562    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.024273    
2022-01-25 18:30:32,772 - Epoch: [74][  211/  211]    Overall Loss 0.060588    Objective Loss 0.060588    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.024248    
2022-01-25 18:30:32,855 - --- validate (epoch=74)-----------
2022-01-25 18:30:32,855 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:33,330 - Epoch: [74][   10/   24]    Loss 0.056145    Top1 98.593750    Top5 99.960938    
2022-01-25 18:30:33,599 - Epoch: [74][   20/   24]    Loss 0.056057    Top1 98.613281    Top5 99.980469    
2022-01-25 18:30:33,702 - Epoch: [74][   24/   24]    Loss 0.058955    Top1 98.550000    Top5 99.966667    
2022-01-25 18:30:33,757 - ==> Top1: 98.550    Top5: 99.967    Loss: 0.059

2022-01-25 18:30:33,758 - ==> Confusion:
[[599   0   3   1   0   0   1   0   1   0]
 [  0 685   0   0   0   1   0   2   0   0]
 [  0   1 579   2   0   0   0   2   1   1]
 [  0   0   2 575   0   3   0   2   1   0]
 [  0   1   1   0 551   1   2   1   1   7]
 [  1   0   0   3   0 510   3   0   1   0]
 [  0   2   0   0   1   1 627   0   0   0]
 [  0   2   0   3   0   0   0 620   0   0]
 [  1   0   1   1   1   2   2   0 575   1]
 [  1   3   0   3   5   4   1   3   3 592]]

2022-01-25 18:30:33,760 - ==> Best [Top1: 98.633   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 73]
2022-01-25 18:30:33,760 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:33,766 - 

2022-01-25 18:30:33,766 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:34,472 - Epoch: [75][   10/  211]    Overall Loss 0.053790    Objective Loss 0.053790                                        LR 0.100000    Time 0.070538    
2022-01-25 18:30:34,745 - Epoch: [75][   20/  211]    Overall Loss 0.054921    Objective Loss 0.054921                                        LR 0.100000    Time 0.048898    
2022-01-25 18:30:34,988 - Epoch: [75][   30/  211]    Overall Loss 0.056519    Objective Loss 0.056519                                        LR 0.100000    Time 0.040673    
2022-01-25 18:30:35,274 - Epoch: [75][   40/  211]    Overall Loss 0.054947    Objective Loss 0.054947                                        LR 0.100000    Time 0.037645    
2022-01-25 18:30:35,525 - Epoch: [75][   50/  211]    Overall Loss 0.055409    Objective Loss 0.055409                                        LR 0.100000    Time 0.035139    
2022-01-25 18:30:35,810 - Epoch: [75][   60/  211]    Overall Loss 0.057190    Objective Loss 0.057190                                        LR 0.100000    Time 0.034013    
2022-01-25 18:30:36,068 - Epoch: [75][   70/  211]    Overall Loss 0.057553    Objective Loss 0.057553                                        LR 0.100000    Time 0.032839    
2022-01-25 18:30:36,350 - Epoch: [75][   80/  211]    Overall Loss 0.058356    Objective Loss 0.058356                                        LR 0.100000    Time 0.032258    
2022-01-25 18:30:36,601 - Epoch: [75][   90/  211]    Overall Loss 0.058257    Objective Loss 0.058257                                        LR 0.100000    Time 0.031453    
2022-01-25 18:30:36,829 - Epoch: [75][  100/  211]    Overall Loss 0.057918    Objective Loss 0.057918                                        LR 0.100000    Time 0.030589    
2022-01-25 18:30:37,043 - Epoch: [75][  110/  211]    Overall Loss 0.058601    Objective Loss 0.058601                                        LR 0.100000    Time 0.029747    
2022-01-25 18:30:37,271 - Epoch: [75][  120/  211]    Overall Loss 0.059143    Objective Loss 0.059143                                        LR 0.100000    Time 0.029167    
2022-01-25 18:30:37,486 - Epoch: [75][  130/  211]    Overall Loss 0.059859    Objective Loss 0.059859                                        LR 0.100000    Time 0.028574    
2022-01-25 18:30:37,719 - Epoch: [75][  140/  211]    Overall Loss 0.059100    Objective Loss 0.059100                                        LR 0.100000    Time 0.028197    
2022-01-25 18:30:37,929 - Epoch: [75][  150/  211]    Overall Loss 0.058722    Objective Loss 0.058722                                        LR 0.100000    Time 0.027714    
2022-01-25 18:30:38,159 - Epoch: [75][  160/  211]    Overall Loss 0.058955    Objective Loss 0.058955                                        LR 0.100000    Time 0.027415    
2022-01-25 18:30:38,374 - Epoch: [75][  170/  211]    Overall Loss 0.059357    Objective Loss 0.059357                                        LR 0.100000    Time 0.027064    
2022-01-25 18:30:38,604 - Epoch: [75][  180/  211]    Overall Loss 0.059637    Objective Loss 0.059637                                        LR 0.100000    Time 0.026839    
2022-01-25 18:30:38,813 - Epoch: [75][  190/  211]    Overall Loss 0.059518    Objective Loss 0.059518                                        LR 0.100000    Time 0.026524    
2022-01-25 18:30:39,051 - Epoch: [75][  200/  211]    Overall Loss 0.059214    Objective Loss 0.059214                                        LR 0.100000    Time 0.026385    
2022-01-25 18:30:39,269 - Epoch: [75][  210/  211]    Overall Loss 0.058965    Objective Loss 0.058965    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.026164    
2022-01-25 18:30:39,295 - Epoch: [75][  211/  211]    Overall Loss 0.058913    Objective Loss 0.058913    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.026165    
2022-01-25 18:30:39,379 - --- validate (epoch=75)-----------
2022-01-25 18:30:39,379 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:39,866 - Epoch: [75][   10/   24]    Loss 0.055753    Top1 98.750000    Top5 99.960938    
2022-01-25 18:30:40,132 - Epoch: [75][   20/   24]    Loss 0.060346    Top1 98.535156    Top5 99.980469    
2022-01-25 18:30:40,235 - Epoch: [75][   24/   24]    Loss 0.058118    Top1 98.616667    Top5 99.966667    
2022-01-25 18:30:40,289 - ==> Top1: 98.617    Top5: 99.967    Loss: 0.058

2022-01-25 18:30:40,290 - ==> Confusion:
[[601   0   1   0   0   0   2   0   0   1]
 [  0 685   2   0   0   0   0   1   0   0]
 [  0   0 581   0   0   0   0   3   2   0]
 [  0   0   3 572   0   6   0   0   1   1]
 [  0   1   2   0 555   0   0   1   0   6]
 [  0   0   0   1   0 513   3   0   1   0]
 [  0   0   1   0   3   2 624   0   1   0]
 [  0   2   7   1   0   0   0 615   0   0]
 [  0   1   0   1   3   3   5   0 571   0]
 [  1   1   0   0   4   2   0   4   3 600]]

2022-01-25 18:30:40,292 - ==> Best [Top1: 98.633   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 73]
2022-01-25 18:30:40,292 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:40,298 - 

2022-01-25 18:30:40,298 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:40,850 - Epoch: [76][   10/  211]    Overall Loss 0.060483    Objective Loss 0.060483                                        LR 0.100000    Time 0.055130    
2022-01-25 18:30:41,057 - Epoch: [76][   20/  211]    Overall Loss 0.055681    Objective Loss 0.055681                                        LR 0.100000    Time 0.037858    
2022-01-25 18:30:41,334 - Epoch: [76][   30/  211]    Overall Loss 0.055044    Objective Loss 0.055044                                        LR 0.100000    Time 0.034474    
2022-01-25 18:30:41,556 - Epoch: [76][   40/  211]    Overall Loss 0.054204    Objective Loss 0.054204                                        LR 0.100000    Time 0.031392    
2022-01-25 18:30:41,803 - Epoch: [76][   50/  211]    Overall Loss 0.054582    Objective Loss 0.054582                                        LR 0.100000    Time 0.030056    
2022-01-25 18:30:42,049 - Epoch: [76][   60/  211]    Overall Loss 0.055082    Objective Loss 0.055082                                        LR 0.100000    Time 0.029136    
2022-01-25 18:30:42,297 - Epoch: [76][   70/  211]    Overall Loss 0.054448    Objective Loss 0.054448                                        LR 0.100000    Time 0.028508    
2022-01-25 18:30:42,511 - Epoch: [76][   80/  211]    Overall Loss 0.054393    Objective Loss 0.054393                                        LR 0.100000    Time 0.027618    
2022-01-25 18:30:42,741 - Epoch: [76][   90/  211]    Overall Loss 0.054548    Objective Loss 0.054548                                        LR 0.100000    Time 0.027102    
2022-01-25 18:30:42,960 - Epoch: [76][  100/  211]    Overall Loss 0.055013    Objective Loss 0.055013                                        LR 0.100000    Time 0.026577    
2022-01-25 18:30:43,179 - Epoch: [76][  110/  211]    Overall Loss 0.054795    Objective Loss 0.054795                                        LR 0.100000    Time 0.026150    
2022-01-25 18:30:43,391 - Epoch: [76][  120/  211]    Overall Loss 0.055237    Objective Loss 0.055237                                        LR 0.100000    Time 0.025731    
2022-01-25 18:30:43,614 - Epoch: [76][  130/  211]    Overall Loss 0.056405    Objective Loss 0.056405                                        LR 0.100000    Time 0.025471    
2022-01-25 18:30:43,825 - Epoch: [76][  140/  211]    Overall Loss 0.057115    Objective Loss 0.057115                                        LR 0.100000    Time 0.025151    
2022-01-25 18:30:44,051 - Epoch: [76][  150/  211]    Overall Loss 0.057304    Objective Loss 0.057304                                        LR 0.100000    Time 0.024980    
2022-01-25 18:30:44,272 - Epoch: [76][  160/  211]    Overall Loss 0.057053    Objective Loss 0.057053                                        LR 0.100000    Time 0.024798    
2022-01-25 18:30:44,492 - Epoch: [76][  170/  211]    Overall Loss 0.057336    Objective Loss 0.057336                                        LR 0.100000    Time 0.024630    
2022-01-25 18:30:44,716 - Epoch: [76][  180/  211]    Overall Loss 0.057250    Objective Loss 0.057250                                        LR 0.100000    Time 0.024505    
2022-01-25 18:30:44,936 - Epoch: [76][  190/  211]    Overall Loss 0.057476    Objective Loss 0.057476                                        LR 0.100000    Time 0.024371    
2022-01-25 18:30:45,145 - Epoch: [76][  200/  211]    Overall Loss 0.057883    Objective Loss 0.057883                                        LR 0.100000    Time 0.024198    
2022-01-25 18:30:45,373 - Epoch: [76][  210/  211]    Overall Loss 0.057751    Objective Loss 0.057751    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.024128    
2022-01-25 18:30:45,393 - Epoch: [76][  211/  211]    Overall Loss 0.057699    Objective Loss 0.057699    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.024107    
2022-01-25 18:30:45,467 - --- validate (epoch=76)-----------
2022-01-25 18:30:45,468 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:45,941 - Epoch: [76][   10/   24]    Loss 0.059054    Top1 98.320312    Top5 100.000000    
2022-01-25 18:30:46,162 - Epoch: [76][   20/   24]    Loss 0.059138    Top1 98.437500    Top5 99.980469    
2022-01-25 18:30:46,265 - Epoch: [76][   24/   24]    Loss 0.060867    Top1 98.283333    Top5 99.983333    
2022-01-25 18:30:46,323 - ==> Top1: 98.283    Top5: 99.983    Loss: 0.061

2022-01-25 18:30:46,324 - ==> Confusion:
[[594   0   1   1   0   1   5   2   0   1]
 [  0 682   1   1   0   1   0   3   0   0]
 [  0   1 575   0   0   0   0   9   0   1]
 [  0   0   1 579   0   2   0   1   0   0]
 [  0   0   1   0 557   1   0   2   0   4]
 [  0   0   0   2   0 510   4   0   2   0]
 [  1   0   1   0   1   1 625   0   2   0]
 [  0   2   1   2   0   0   0 620   0   0]
 [  2   0   0   0   2   3   2   1 573   1]
 [  1   2   1   0   9   5   0  11   3 583]]

2022-01-25 18:30:46,325 - ==> Best [Top1: 98.633   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 73]
2022-01-25 18:30:46,326 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:46,331 - 

2022-01-25 18:30:46,331 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:47,034 - Epoch: [77][   10/  211]    Overall Loss 0.053833    Objective Loss 0.053833                                        LR 0.100000    Time 0.070202    
2022-01-25 18:30:47,244 - Epoch: [77][   20/  211]    Overall Loss 0.056616    Objective Loss 0.056616                                        LR 0.100000    Time 0.045589    
2022-01-25 18:30:47,471 - Epoch: [77][   30/  211]    Overall Loss 0.059868    Objective Loss 0.059868                                        LR 0.100000    Time 0.037965    
2022-01-25 18:30:47,684 - Epoch: [77][   40/  211]    Overall Loss 0.057981    Objective Loss 0.057981                                        LR 0.100000    Time 0.033771    
2022-01-25 18:30:47,904 - Epoch: [77][   50/  211]    Overall Loss 0.059224    Objective Loss 0.059224                                        LR 0.100000    Time 0.031424    
2022-01-25 18:30:48,119 - Epoch: [77][   60/  211]    Overall Loss 0.057862    Objective Loss 0.057862                                        LR 0.100000    Time 0.029756    
2022-01-25 18:30:48,344 - Epoch: [77][   70/  211]    Overall Loss 0.056563    Objective Loss 0.056563                                        LR 0.100000    Time 0.028723    
2022-01-25 18:30:48,555 - Epoch: [77][   80/  211]    Overall Loss 0.057253    Objective Loss 0.057253                                        LR 0.100000    Time 0.027760    
2022-01-25 18:30:48,787 - Epoch: [77][   90/  211]    Overall Loss 0.056581    Objective Loss 0.056581                                        LR 0.100000    Time 0.027253    
2022-01-25 18:30:48,999 - Epoch: [77][  100/  211]    Overall Loss 0.056660    Objective Loss 0.056660                                        LR 0.100000    Time 0.026645    
2022-01-25 18:30:49,229 - Epoch: [77][  110/  211]    Overall Loss 0.056983    Objective Loss 0.056983                                        LR 0.100000    Time 0.026308    
2022-01-25 18:30:49,447 - Epoch: [77][  120/  211]    Overall Loss 0.056534    Objective Loss 0.056534                                        LR 0.100000    Time 0.025934    
2022-01-25 18:30:49,673 - Epoch: [77][  130/  211]    Overall Loss 0.056537    Objective Loss 0.056537                                        LR 0.100000    Time 0.025674    
2022-01-25 18:30:49,883 - Epoch: [77][  140/  211]    Overall Loss 0.057503    Objective Loss 0.057503                                        LR 0.100000    Time 0.025337    
2022-01-25 18:30:50,109 - Epoch: [77][  150/  211]    Overall Loss 0.057355    Objective Loss 0.057355                                        LR 0.100000    Time 0.025155    
2022-01-25 18:30:50,320 - Epoch: [77][  160/  211]    Overall Loss 0.057630    Objective Loss 0.057630                                        LR 0.100000    Time 0.024895    
2022-01-25 18:30:50,550 - Epoch: [77][  170/  211]    Overall Loss 0.057918    Objective Loss 0.057918                                        LR 0.100000    Time 0.024785    
2022-01-25 18:30:50,762 - Epoch: [77][  180/  211]    Overall Loss 0.058192    Objective Loss 0.058192                                        LR 0.100000    Time 0.024582    
2022-01-25 18:30:50,986 - Epoch: [77][  190/  211]    Overall Loss 0.058250    Objective Loss 0.058250                                        LR 0.100000    Time 0.024465    
2022-01-25 18:30:51,194 - Epoch: [77][  200/  211]    Overall Loss 0.058398    Objective Loss 0.058398                                        LR 0.100000    Time 0.024279    
2022-01-25 18:30:51,422 - Epoch: [77][  210/  211]    Overall Loss 0.058573    Objective Loss 0.058573    Top1 96.875000    Top5 99.609375    LR 0.100000    Time 0.024206    
2022-01-25 18:30:51,441 - Epoch: [77][  211/  211]    Overall Loss 0.058768    Objective Loss 0.058768    Top1 97.580645    Top5 99.798387    LR 0.100000    Time 0.024180    
2022-01-25 18:30:51,547 - --- validate (epoch=77)-----------
2022-01-25 18:30:51,548 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:52,077 - Epoch: [77][   10/   24]    Loss 0.066993    Top1 98.164062    Top5 100.000000    
2022-01-25 18:30:52,312 - Epoch: [77][   20/   24]    Loss 0.065556    Top1 98.300781    Top5 100.000000    
2022-01-25 18:30:52,416 - Epoch: [77][   24/   24]    Loss 0.063239    Top1 98.316667    Top5 100.000000    
2022-01-25 18:30:52,476 - ==> Top1: 98.317    Top5: 100.000    Loss: 0.063

2022-01-25 18:30:52,477 - ==> Confusion:
[[600   0   0   0   0   1   1   0   3   0]
 [  0 683   0   0   0   1   1   3   0   0]
 [  1   1 565   6   0   0   1   8   4   0]
 [  0   0   0 578   0   4   0   0   1   0]
 [  0   0   0   0 556   0   1   0   1   7]
 [  0   1   0   4   0 511   2   0   0   0]
 [  0   1   0   0   2   4 624   0   0   0]
 [  0   4   4   0   2   1   0 613   0   1]
 [  0   1   0   1   4   2   3   2 570   1]
 [  1   3   0   0   1   4   1   3   3 599]]

2022-01-25 18:30:52,479 - ==> Best [Top1: 98.633   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 73]
2022-01-25 18:30:52,479 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:52,486 - 

2022-01-25 18:30:52,486 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:53,221 - Epoch: [78][   10/  211]    Overall Loss 0.059753    Objective Loss 0.059753                                        LR 0.100000    Time 0.073441    
2022-01-25 18:30:53,470 - Epoch: [78][   20/  211]    Overall Loss 0.058479    Objective Loss 0.058479                                        LR 0.100000    Time 0.049123    
2022-01-25 18:30:53,752 - Epoch: [78][   30/  211]    Overall Loss 0.057334    Objective Loss 0.057334                                        LR 0.100000    Time 0.042148    
2022-01-25 18:30:53,995 - Epoch: [78][   40/  211]    Overall Loss 0.059054    Objective Loss 0.059054                                        LR 0.100000    Time 0.037681    
2022-01-25 18:30:54,274 - Epoch: [78][   50/  211]    Overall Loss 0.057691    Objective Loss 0.057691                                        LR 0.100000    Time 0.035709    
2022-01-25 18:30:54,523 - Epoch: [78][   60/  211]    Overall Loss 0.057441    Objective Loss 0.057441                                        LR 0.100000    Time 0.033906    
2022-01-25 18:30:54,809 - Epoch: [78][   70/  211]    Overall Loss 0.057735    Objective Loss 0.057735                                        LR 0.100000    Time 0.033141    
2022-01-25 18:30:55,054 - Epoch: [78][   80/  211]    Overall Loss 0.059138    Objective Loss 0.059138                                        LR 0.100000    Time 0.032065    
2022-01-25 18:30:55,336 - Epoch: [78][   90/  211]    Overall Loss 0.059399    Objective Loss 0.059399                                        LR 0.100000    Time 0.031632    
2022-01-25 18:30:55,585 - Epoch: [78][  100/  211]    Overall Loss 0.059607    Objective Loss 0.059607                                        LR 0.100000    Time 0.030952    
2022-01-25 18:30:55,870 - Epoch: [78][  110/  211]    Overall Loss 0.060161    Objective Loss 0.060161                                        LR 0.100000    Time 0.030727    
2022-01-25 18:30:56,117 - Epoch: [78][  120/  211]    Overall Loss 0.059973    Objective Loss 0.059973                                        LR 0.100000    Time 0.030224    
2022-01-25 18:30:56,396 - Epoch: [78][  130/  211]    Overall Loss 0.060955    Objective Loss 0.060955                                        LR 0.100000    Time 0.030039    
2022-01-25 18:30:56,647 - Epoch: [78][  140/  211]    Overall Loss 0.061684    Objective Loss 0.061684                                        LR 0.100000    Time 0.029685    
2022-01-25 18:30:56,923 - Epoch: [78][  150/  211]    Overall Loss 0.061779    Objective Loss 0.061779                                        LR 0.100000    Time 0.029541    
2022-01-25 18:30:57,177 - Epoch: [78][  160/  211]    Overall Loss 0.061636    Objective Loss 0.061636                                        LR 0.100000    Time 0.029281    
2022-01-25 18:30:57,453 - Epoch: [78][  170/  211]    Overall Loss 0.062017    Objective Loss 0.062017                                        LR 0.100000    Time 0.029179    
2022-01-25 18:30:57,700 - Epoch: [78][  180/  211]    Overall Loss 0.061610    Objective Loss 0.061610                                        LR 0.100000    Time 0.028928    
2022-01-25 18:30:57,979 - Epoch: [78][  190/  211]    Overall Loss 0.061787    Objective Loss 0.061787                                        LR 0.100000    Time 0.028871    
2022-01-25 18:30:58,224 - Epoch: [78][  200/  211]    Overall Loss 0.061734    Objective Loss 0.061734                                        LR 0.100000    Time 0.028655    
2022-01-25 18:30:58,513 - Epoch: [78][  210/  211]    Overall Loss 0.061434    Objective Loss 0.061434    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.028665    
2022-01-25 18:30:58,533 - Epoch: [78][  211/  211]    Overall Loss 0.061400    Objective Loss 0.061400    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.028621    
2022-01-25 18:30:58,590 - --- validate (epoch=78)-----------
2022-01-25 18:30:58,591 - 6000 samples (256 per mini-batch)
2022-01-25 18:30:59,061 - Epoch: [78][   10/   24]    Loss 0.067089    Top1 98.398438    Top5 100.000000    
2022-01-25 18:30:59,263 - Epoch: [78][   20/   24]    Loss 0.063274    Top1 98.437500    Top5 99.980469    
2022-01-25 18:30:59,348 - Epoch: [78][   24/   24]    Loss 0.065436    Top1 98.416667    Top5 99.983333    
2022-01-25 18:30:59,404 - ==> Top1: 98.417    Top5: 99.983    Loss: 0.065

2022-01-25 18:30:59,405 - ==> Confusion:
[[598   0   2   0   1   0   2   2   0   0]
 [  0 684   0   1   0   0   0   3   0   0]
 [  0   2 577   0   0   0   0   4   2   1]
 [  0   0   1 577   0   1   0   3   1   0]
 [  0   1   0   0 546   0   0   8   1   9]
 [  0   2   0   2   0 510   1   1   1   1]
 [  2   6   0   0   1   1 620   0   1   0]
 [  1   0   0   1   0   0   0 622   0   1]
 [  0   0   0   0   1   3   2   1 574   3]
 [  0   1   0   2   4   2   0   8   1 597]]

2022-01-25 18:30:59,407 - ==> Best [Top1: 98.633   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 73]
2022-01-25 18:30:59,407 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:30:59,414 - 

2022-01-25 18:30:59,414 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:30:59,975 - Epoch: [79][   10/  211]    Overall Loss 0.055874    Objective Loss 0.055874                                        LR 0.100000    Time 0.055981    
2022-01-25 18:31:00,186 - Epoch: [79][   20/  211]    Overall Loss 0.059785    Objective Loss 0.059785                                        LR 0.100000    Time 0.038507    
2022-01-25 18:31:00,406 - Epoch: [79][   30/  211]    Overall Loss 0.067773    Objective Loss 0.067773                                        LR 0.100000    Time 0.033012    
2022-01-25 18:31:00,618 - Epoch: [79][   40/  211]    Overall Loss 0.065776    Objective Loss 0.065776                                        LR 0.100000    Time 0.030042    
2022-01-25 18:31:00,843 - Epoch: [79][   50/  211]    Overall Loss 0.064347    Objective Loss 0.064347                                        LR 0.100000    Time 0.028498    
2022-01-25 18:31:01,064 - Epoch: [79][   60/  211]    Overall Loss 0.064301    Objective Loss 0.064301                                        LR 0.100000    Time 0.027413    
2022-01-25 18:31:01,301 - Epoch: [79][   70/  211]    Overall Loss 0.063519    Objective Loss 0.063519                                        LR 0.100000    Time 0.026879    
2022-01-25 18:31:01,584 - Epoch: [79][   80/  211]    Overall Loss 0.063126    Objective Loss 0.063126                                        LR 0.100000    Time 0.027051    
2022-01-25 18:31:01,841 - Epoch: [79][   90/  211]    Overall Loss 0.062122    Objective Loss 0.062122                                        LR 0.100000    Time 0.026896    
2022-01-25 18:31:02,121 - Epoch: [79][  100/  211]    Overall Loss 0.061582    Objective Loss 0.061582                                        LR 0.100000    Time 0.027011    
2022-01-25 18:31:02,369 - Epoch: [79][  110/  211]    Overall Loss 0.060338    Objective Loss 0.060338                                        LR 0.100000    Time 0.026803    
2022-01-25 18:31:02,650 - Epoch: [79][  120/  211]    Overall Loss 0.059672    Objective Loss 0.059672                                        LR 0.100000    Time 0.026907    
2022-01-25 18:31:02,896 - Epoch: [79][  130/  211]    Overall Loss 0.059140    Objective Loss 0.059140                                        LR 0.100000    Time 0.026727    
2022-01-25 18:31:03,188 - Epoch: [79][  140/  211]    Overall Loss 0.059100    Objective Loss 0.059100                                        LR 0.100000    Time 0.026901    
2022-01-25 18:31:03,436 - Epoch: [79][  150/  211]    Overall Loss 0.059755    Objective Loss 0.059755                                        LR 0.100000    Time 0.026757    
2022-01-25 18:31:03,715 - Epoch: [79][  160/  211]    Overall Loss 0.060502    Objective Loss 0.060502                                        LR 0.100000    Time 0.026827    
2022-01-25 18:31:03,964 - Epoch: [79][  170/  211]    Overall Loss 0.060654    Objective Loss 0.060654                                        LR 0.100000    Time 0.026713    
2022-01-25 18:31:04,244 - Epoch: [79][  180/  211]    Overall Loss 0.060401    Objective Loss 0.060401                                        LR 0.100000    Time 0.026782    
2022-01-25 18:31:04,491 - Epoch: [79][  190/  211]    Overall Loss 0.060173    Objective Loss 0.060173                                        LR 0.100000    Time 0.026673    
2022-01-25 18:31:04,775 - Epoch: [79][  200/  211]    Overall Loss 0.060079    Objective Loss 0.060079                                        LR 0.100000    Time 0.026756    
2022-01-25 18:31:05,022 - Epoch: [79][  210/  211]    Overall Loss 0.059738    Objective Loss 0.059738    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.026657    
2022-01-25 18:31:05,040 - Epoch: [79][  211/  211]    Overall Loss 0.059748    Objective Loss 0.059748    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.026614    
2022-01-25 18:31:05,116 - --- validate (epoch=79)-----------
2022-01-25 18:31:05,116 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:05,638 - Epoch: [79][   10/   24]    Loss 0.064016    Top1 98.554688    Top5 99.960938    
2022-01-25 18:31:05,844 - Epoch: [79][   20/   24]    Loss 0.059865    Top1 98.476562    Top5 99.980469    
2022-01-25 18:31:05,930 - Epoch: [79][   24/   24]    Loss 0.060162    Top1 98.466667    Top5 99.983333    
2022-01-25 18:31:05,988 - ==> Top1: 98.467    Top5: 99.983    Loss: 0.060

2022-01-25 18:31:05,989 - ==> Confusion:
[[598   0   2   1   0   0   2   0   0   2]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   2 572   0   2   0   0   6   1   3]
 [  1   0   1 578   0   2   0   0   1   0]
 [  0   1   1   0 559   0   0   0   0   4]
 [  1   1   0   2   2 508   2   0   1   1]
 [  0   1   0   0   3   1 625   0   1   0]
 [  1   1   1   1   1   0   0 620   0   0]
 [  2   1   1   2   4   3   3   0 567   1]
 [  0   6   0   0   7   2   0   1   4 595]]

2022-01-25 18:31:05,991 - ==> Best [Top1: 98.633   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 73]
2022-01-25 18:31:05,991 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:05,998 - 

2022-01-25 18:31:05,999 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:06,758 - Epoch: [80][   10/  211]    Overall Loss 0.057140    Objective Loss 0.057140                                        LR 0.100000    Time 0.075845    
2022-01-25 18:31:07,006 - Epoch: [80][   20/  211]    Overall Loss 0.058119    Objective Loss 0.058119                                        LR 0.100000    Time 0.050331    
2022-01-25 18:31:07,287 - Epoch: [80][   30/  211]    Overall Loss 0.058134    Objective Loss 0.058134                                        LR 0.100000    Time 0.042910    
2022-01-25 18:31:07,532 - Epoch: [80][   40/  211]    Overall Loss 0.060063    Objective Loss 0.060063                                        LR 0.100000    Time 0.038296    
2022-01-25 18:31:07,776 - Epoch: [80][   50/  211]    Overall Loss 0.061587    Objective Loss 0.061587                                        LR 0.100000    Time 0.035505    
2022-01-25 18:31:07,998 - Epoch: [80][   60/  211]    Overall Loss 0.061696    Objective Loss 0.061696                                        LR 0.100000    Time 0.033291    
2022-01-25 18:31:08,227 - Epoch: [80][   70/  211]    Overall Loss 0.062165    Objective Loss 0.062165                                        LR 0.100000    Time 0.031795    
2022-01-25 18:31:08,436 - Epoch: [80][   80/  211]    Overall Loss 0.061875    Objective Loss 0.061875                                        LR 0.100000    Time 0.030425    
2022-01-25 18:31:08,659 - Epoch: [80][   90/  211]    Overall Loss 0.063233    Objective Loss 0.063233                                        LR 0.100000    Time 0.029521    
2022-01-25 18:31:08,870 - Epoch: [80][  100/  211]    Overall Loss 0.063483    Objective Loss 0.063483                                        LR 0.100000    Time 0.028670    
2022-01-25 18:31:09,096 - Epoch: [80][  110/  211]    Overall Loss 0.062680    Objective Loss 0.062680                                        LR 0.100000    Time 0.028116    
2022-01-25 18:31:09,306 - Epoch: [80][  120/  211]    Overall Loss 0.062201    Objective Loss 0.062201                                        LR 0.100000    Time 0.027521    
2022-01-25 18:31:09,540 - Epoch: [80][  130/  211]    Overall Loss 0.061875    Objective Loss 0.061875                                        LR 0.100000    Time 0.027201    
2022-01-25 18:31:09,750 - Epoch: [80][  140/  211]    Overall Loss 0.061471    Objective Loss 0.061471                                        LR 0.100000    Time 0.026759    
2022-01-25 18:31:09,973 - Epoch: [80][  150/  211]    Overall Loss 0.062099    Objective Loss 0.062099                                        LR 0.100000    Time 0.026456    
2022-01-25 18:31:10,182 - Epoch: [80][  160/  211]    Overall Loss 0.062023    Objective Loss 0.062023                                        LR 0.100000    Time 0.026106    
2022-01-25 18:31:10,414 - Epoch: [80][  170/  211]    Overall Loss 0.062081    Objective Loss 0.062081                                        LR 0.100000    Time 0.025937    
2022-01-25 18:31:10,622 - Epoch: [80][  180/  211]    Overall Loss 0.062424    Objective Loss 0.062424                                        LR 0.100000    Time 0.025649    
2022-01-25 18:31:10,847 - Epoch: [80][  190/  211]    Overall Loss 0.062458    Objective Loss 0.062458                                        LR 0.100000    Time 0.025479    
2022-01-25 18:31:11,070 - Epoch: [80][  200/  211]    Overall Loss 0.062377    Objective Loss 0.062377                                        LR 0.100000    Time 0.025320    
2022-01-25 18:31:11,294 - Epoch: [80][  210/  211]    Overall Loss 0.062436    Objective Loss 0.062436    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.025180    
2022-01-25 18:31:11,314 - Epoch: [80][  211/  211]    Overall Loss 0.062707    Objective Loss 0.062707    Top1 97.580645    Top5 100.000000    LR 0.100000    Time 0.025154    
2022-01-25 18:31:11,396 - --- validate (epoch=80)-----------
2022-01-25 18:31:11,397 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:11,877 - Epoch: [80][   10/   24]    Loss 0.051935    Top1 98.750000    Top5 100.000000    
2022-01-25 18:31:12,070 - Epoch: [80][   20/   24]    Loss 0.056330    Top1 98.671875    Top5 99.980469    
2022-01-25 18:31:12,155 - Epoch: [80][   24/   24]    Loss 0.055353    Top1 98.666667    Top5 99.983333    
2022-01-25 18:31:12,209 - ==> Top1: 98.667    Top5: 99.983    Loss: 0.055

2022-01-25 18:31:12,210 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 681   1   1   0   1   1   3   0   0]
 [  0   1 580   0   0   0   0   4   1   0]
 [  0   0   5 574   0   1   0   1   1   1]
 [  1   0   1   0 552   0   1   1   0   9]
 [  0   0   1   4   0 510   1   0   2   0]
 [  1   3   1   0   2   2 621   0   1   0]
 [  0   0   7   0   1   0   0 617   0   0]
 [  1   0   1   0   2   1   1   0 578   0]
 [  1   0   0   0   3   3   0   0   5 603]]

2022-01-25 18:31:12,212 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:31:12,213 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:12,221 - 

2022-01-25 18:31:12,221 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:12,935 - Epoch: [81][   10/  211]    Overall Loss 0.058430    Objective Loss 0.058430                                        LR 0.100000    Time 0.071339    
2022-01-25 18:31:13,149 - Epoch: [81][   20/  211]    Overall Loss 0.057961    Objective Loss 0.057961                                        LR 0.100000    Time 0.046343    
2022-01-25 18:31:13,360 - Epoch: [81][   30/  211]    Overall Loss 0.060602    Objective Loss 0.060602                                        LR 0.100000    Time 0.037925    
2022-01-25 18:31:13,564 - Epoch: [81][   40/  211]    Overall Loss 0.060345    Objective Loss 0.060345                                        LR 0.100000    Time 0.033538    
2022-01-25 18:31:13,787 - Epoch: [81][   50/  211]    Overall Loss 0.060885    Objective Loss 0.060885                                        LR 0.100000    Time 0.031273    
2022-01-25 18:31:14,001 - Epoch: [81][   60/  211]    Overall Loss 0.060984    Objective Loss 0.060984                                        LR 0.100000    Time 0.029627    
2022-01-25 18:31:14,226 - Epoch: [81][   70/  211]    Overall Loss 0.059774    Objective Loss 0.059774                                        LR 0.100000    Time 0.028596    
2022-01-25 18:31:14,443 - Epoch: [81][   80/  211]    Overall Loss 0.059795    Objective Loss 0.059795                                        LR 0.100000    Time 0.027740    
2022-01-25 18:31:14,689 - Epoch: [81][   90/  211]    Overall Loss 0.060518    Objective Loss 0.060518                                        LR 0.100000    Time 0.027383    
2022-01-25 18:31:14,975 - Epoch: [81][  100/  211]    Overall Loss 0.059873    Objective Loss 0.059873                                        LR 0.100000    Time 0.027500    
2022-01-25 18:31:15,223 - Epoch: [81][  110/  211]    Overall Loss 0.060188    Objective Loss 0.060188                                        LR 0.100000    Time 0.027255    
2022-01-25 18:31:15,511 - Epoch: [81][  120/  211]    Overall Loss 0.059858    Objective Loss 0.059858                                        LR 0.100000    Time 0.027382    
2022-01-25 18:31:15,762 - Epoch: [81][  130/  211]    Overall Loss 0.059286    Objective Loss 0.059286                                        LR 0.100000    Time 0.027200    
2022-01-25 18:31:15,995 - Epoch: [81][  140/  211]    Overall Loss 0.059019    Objective Loss 0.059019                                        LR 0.100000    Time 0.026918    
2022-01-25 18:31:16,206 - Epoch: [81][  150/  211]    Overall Loss 0.058862    Objective Loss 0.058862                                        LR 0.100000    Time 0.026531    
2022-01-25 18:31:16,439 - Epoch: [81][  160/  211]    Overall Loss 0.059069    Objective Loss 0.059069                                        LR 0.100000    Time 0.026325    
2022-01-25 18:31:16,650 - Epoch: [81][  170/  211]    Overall Loss 0.058849    Objective Loss 0.058849                                        LR 0.100000    Time 0.026014    
2022-01-25 18:31:16,875 - Epoch: [81][  180/  211]    Overall Loss 0.058831    Objective Loss 0.058831                                        LR 0.100000    Time 0.025821    
2022-01-25 18:31:17,119 - Epoch: [81][  190/  211]    Overall Loss 0.058890    Objective Loss 0.058890                                        LR 0.100000    Time 0.025741    
2022-01-25 18:31:17,374 - Epoch: [81][  200/  211]    Overall Loss 0.058839    Objective Loss 0.058839                                        LR 0.100000    Time 0.025731    
2022-01-25 18:31:17,652 - Epoch: [81][  210/  211]    Overall Loss 0.058569    Objective Loss 0.058569    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.025827    
2022-01-25 18:31:17,671 - Epoch: [81][  211/  211]    Overall Loss 0.058524    Objective Loss 0.058524    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.025793    
2022-01-25 18:31:17,728 - --- validate (epoch=81)-----------
2022-01-25 18:31:17,729 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:18,205 - Epoch: [81][   10/   24]    Loss 0.057773    Top1 98.476562    Top5 99.960938    
2022-01-25 18:31:18,460 - Epoch: [81][   20/   24]    Loss 0.052462    Top1 98.691406    Top5 99.980469    
2022-01-25 18:31:18,504 - Epoch: [81][   24/   24]    Loss 0.056448    Top1 98.616667    Top5 99.966667    
2022-01-25 18:31:18,560 - ==> Top1: 98.617    Top5: 99.967    Loss: 0.056

2022-01-25 18:31:18,561 - ==> Confusion:
[[605   0   0   0   0   0   0   0   0   0]
 [  0 684   1   0   0   1   0   2   0   0]
 [  2   0 576   0   0   0   0   2   4   2]
 [  1   0   0 575   0   2   0   1   3   1]
 [  0   1   3   0 549   0   1   1   0  10]
 [  3   0   0   3   0 505   4   0   3   0]
 [  1   0   0   0   1   1 627   0   1   0]
 [  0   2   6   1   1   0   0 615   0   0]
 [  3   0   0   0   1   0   1   0 576   3]
 [  0   1   0   0   3   1   0   3   2 605]]

2022-01-25 18:31:18,563 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:31:18,563 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:18,570 - 

2022-01-25 18:31:18,570 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:19,117 - Epoch: [82][   10/  211]    Overall Loss 0.062004    Objective Loss 0.062004                                        LR 0.100000    Time 0.054663    
2022-01-25 18:31:19,366 - Epoch: [82][   20/  211]    Overall Loss 0.054765    Objective Loss 0.054765                                        LR 0.100000    Time 0.039722    
2022-01-25 18:31:19,611 - Epoch: [82][   30/  211]    Overall Loss 0.059352    Objective Loss 0.059352                                        LR 0.100000    Time 0.034647    
2022-01-25 18:31:19,889 - Epoch: [82][   40/  211]    Overall Loss 0.058243    Objective Loss 0.058243                                        LR 0.100000    Time 0.032929    
2022-01-25 18:31:20,135 - Epoch: [82][   50/  211]    Overall Loss 0.058875    Objective Loss 0.058875                                        LR 0.100000    Time 0.031258    
2022-01-25 18:31:20,419 - Epoch: [82][   60/  211]    Overall Loss 0.059455    Objective Loss 0.059455                                        LR 0.100000    Time 0.030772    
2022-01-25 18:31:20,675 - Epoch: [82][   70/  211]    Overall Loss 0.058313    Objective Loss 0.058313                                        LR 0.100000    Time 0.030030    
2022-01-25 18:31:20,953 - Epoch: [82][   80/  211]    Overall Loss 0.058096    Objective Loss 0.058096                                        LR 0.100000    Time 0.029746    
2022-01-25 18:31:21,205 - Epoch: [82][   90/  211]    Overall Loss 0.058502    Objective Loss 0.058502                                        LR 0.100000    Time 0.029243    
2022-01-25 18:31:21,491 - Epoch: [82][  100/  211]    Overall Loss 0.058458    Objective Loss 0.058458                                        LR 0.100000    Time 0.029173    
2022-01-25 18:31:21,749 - Epoch: [82][  110/  211]    Overall Loss 0.058364    Objective Loss 0.058364                                        LR 0.100000    Time 0.028865    
2022-01-25 18:31:22,021 - Epoch: [82][  120/  211]    Overall Loss 0.058174    Objective Loss 0.058174                                        LR 0.100000    Time 0.028716    
2022-01-25 18:31:22,266 - Epoch: [82][  130/  211]    Overall Loss 0.058168    Objective Loss 0.058168                                        LR 0.100000    Time 0.028395    
2022-01-25 18:31:22,552 - Epoch: [82][  140/  211]    Overall Loss 0.058041    Objective Loss 0.058041                                        LR 0.100000    Time 0.028405    
2022-01-25 18:31:22,799 - Epoch: [82][  150/  211]    Overall Loss 0.058201    Objective Loss 0.058201                                        LR 0.100000    Time 0.028153    
2022-01-25 18:31:23,079 - Epoch: [82][  160/  211]    Overall Loss 0.058504    Objective Loss 0.058504                                        LR 0.100000    Time 0.028146    
2022-01-25 18:31:23,325 - Epoch: [82][  170/  211]    Overall Loss 0.058386    Objective Loss 0.058386                                        LR 0.100000    Time 0.027936    
2022-01-25 18:31:23,609 - Epoch: [82][  180/  211]    Overall Loss 0.058661    Objective Loss 0.058661                                        LR 0.100000    Time 0.027958    
2022-01-25 18:31:23,855 - Epoch: [82][  190/  211]    Overall Loss 0.058887    Objective Loss 0.058887                                        LR 0.100000    Time 0.027780    
2022-01-25 18:31:24,140 - Epoch: [82][  200/  211]    Overall Loss 0.059072    Objective Loss 0.059072                                        LR 0.100000    Time 0.027813    
2022-01-25 18:31:24,385 - Epoch: [82][  210/  211]    Overall Loss 0.059078    Objective Loss 0.059078    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.027655    
2022-01-25 18:31:24,406 - Epoch: [82][  211/  211]    Overall Loss 0.059218    Objective Loss 0.059218    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.027619    
2022-01-25 18:31:24,462 - --- validate (epoch=82)-----------
2022-01-25 18:31:24,463 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:24,932 - Epoch: [82][   10/   24]    Loss 0.063693    Top1 98.125000    Top5 99.960938    
2022-01-25 18:31:25,156 - Epoch: [82][   20/   24]    Loss 0.064679    Top1 98.300781    Top5 99.960938    
2022-01-25 18:31:25,247 - Epoch: [82][   24/   24]    Loss 0.065728    Top1 98.316667    Top5 99.966667    
2022-01-25 18:31:25,302 - ==> Top1: 98.317    Top5: 99.967    Loss: 0.066

2022-01-25 18:31:25,303 - ==> Confusion:
[[598   0   1   0   0   0   5   0   1   0]
 [  0 679   3   1   0   1   1   3   0   0]
 [  0   0 579   0   0   0   3   1   3   0]
 [  0   0   6 568   0   4   0   1   3   1]
 [  0   0   0   0 554   1   3   0   0   7]
 [  2   0   0   3   0 499  12   0   2   0]
 [  0   0   0   0   2   0 628   0   1   0]
 [  0   2   6   2   0   0   0 614   1   0]
 [  0   0   0   0   1   0   2   1 579   1]
 [  1   1   1   0   4   2   0   1   4 601]]

2022-01-25 18:31:25,304 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:31:25,305 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:25,310 - 

2022-01-25 18:31:25,310 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:26,013 - Epoch: [83][   10/  211]    Overall Loss 0.063305    Objective Loss 0.063305                                        LR 0.100000    Time 0.070233    
2022-01-25 18:31:26,221 - Epoch: [83][   20/  211]    Overall Loss 0.068399    Objective Loss 0.068399                                        LR 0.100000    Time 0.045492    
2022-01-25 18:31:26,443 - Epoch: [83][   30/  211]    Overall Loss 0.064497    Objective Loss 0.064497                                        LR 0.100000    Time 0.037701    
2022-01-25 18:31:26,656 - Epoch: [83][   40/  211]    Overall Loss 0.062561    Objective Loss 0.062561                                        LR 0.100000    Time 0.033605    
2022-01-25 18:31:26,902 - Epoch: [83][   50/  211]    Overall Loss 0.062717    Objective Loss 0.062717                                        LR 0.100000    Time 0.031791    
2022-01-25 18:31:27,130 - Epoch: [83][   60/  211]    Overall Loss 0.062036    Objective Loss 0.062036                                        LR 0.100000    Time 0.030290    
2022-01-25 18:31:27,379 - Epoch: [83][   70/  211]    Overall Loss 0.061041    Objective Loss 0.061041                                        LR 0.100000    Time 0.029519    
2022-01-25 18:31:27,611 - Epoch: [83][   80/  211]    Overall Loss 0.061244    Objective Loss 0.061244                                        LR 0.100000    Time 0.028723    
2022-01-25 18:31:27,855 - Epoch: [83][   90/  211]    Overall Loss 0.060251    Objective Loss 0.060251                                        LR 0.100000    Time 0.028239    
2022-01-25 18:31:28,080 - Epoch: [83][  100/  211]    Overall Loss 0.059960    Objective Loss 0.059960                                        LR 0.100000    Time 0.027654    
2022-01-25 18:31:28,328 - Epoch: [83][  110/  211]    Overall Loss 0.060265    Objective Loss 0.060265                                        LR 0.100000    Time 0.027398    
2022-01-25 18:31:28,556 - Epoch: [83][  120/  211]    Overall Loss 0.059321    Objective Loss 0.059321                                        LR 0.100000    Time 0.027010    
2022-01-25 18:31:28,807 - Epoch: [83][  130/  211]    Overall Loss 0.059039    Objective Loss 0.059039                                        LR 0.100000    Time 0.026863    
2022-01-25 18:31:29,055 - Epoch: [83][  140/  211]    Overall Loss 0.059057    Objective Loss 0.059057                                        LR 0.100000    Time 0.026710    
2022-01-25 18:31:29,301 - Epoch: [83][  150/  211]    Overall Loss 0.058290    Objective Loss 0.058290                                        LR 0.100000    Time 0.026570    
2022-01-25 18:31:29,591 - Epoch: [83][  160/  211]    Overall Loss 0.057953    Objective Loss 0.057953                                        LR 0.100000    Time 0.026718    
2022-01-25 18:31:29,835 - Epoch: [83][  170/  211]    Overall Loss 0.058006    Objective Loss 0.058006                                        LR 0.100000    Time 0.026580    
2022-01-25 18:31:30,114 - Epoch: [83][  180/  211]    Overall Loss 0.058040    Objective Loss 0.058040                                        LR 0.100000    Time 0.026648    
2022-01-25 18:31:30,364 - Epoch: [83][  190/  211]    Overall Loss 0.057990    Objective Loss 0.057990                                        LR 0.100000    Time 0.026562    
2022-01-25 18:31:30,645 - Epoch: [83][  200/  211]    Overall Loss 0.058866    Objective Loss 0.058866                                        LR 0.100000    Time 0.026634    
2022-01-25 18:31:30,897 - Epoch: [83][  210/  211]    Overall Loss 0.058932    Objective Loss 0.058932    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.026565    
2022-01-25 18:31:30,940 - Epoch: [83][  211/  211]    Overall Loss 0.058899    Objective Loss 0.058899    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.026642    
2022-01-25 18:31:31,009 - --- validate (epoch=83)-----------
2022-01-25 18:31:31,009 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:31,477 - Epoch: [83][   10/   24]    Loss 0.054424    Top1 98.593750    Top5 99.960938    
2022-01-25 18:31:31,676 - Epoch: [83][   20/   24]    Loss 0.055357    Top1 98.632812    Top5 99.980469    
2022-01-25 18:31:31,762 - Epoch: [83][   24/   24]    Loss 0.056956    Top1 98.600000    Top5 99.983333    
2022-01-25 18:31:31,817 - ==> Top1: 98.600    Top5: 99.983    Loss: 0.057

2022-01-25 18:31:31,818 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 686   0   1   0   0   0   1   0   0]
 [  1   1 571   1   0   0   0   5   7   0]
 [  0   0   0 574   0   6   0   1   2   0]
 [  0   0   1   0 551   0   2   1   1   9]
 [  0   0   0   1   0 513   4   0   0   0]
 [  1   2   0   0   1   4 622   0   1   0]
 [  0   0   2   0   0   0   0 623   0   0]
 [  3   0   0   1   1   2   3   0 572   2]
 [  1   1   0   0   3   2   1   3   3 601]]

2022-01-25 18:31:31,819 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:31:31,820 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:31,826 - 

2022-01-25 18:31:31,826 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:32,413 - Epoch: [84][   10/  211]    Overall Loss 0.064765    Objective Loss 0.064765                                        LR 0.100000    Time 0.058611    
2022-01-25 18:31:32,627 - Epoch: [84][   20/  211]    Overall Loss 0.064087    Objective Loss 0.064087                                        LR 0.100000    Time 0.039986    
2022-01-25 18:31:32,843 - Epoch: [84][   30/  211]    Overall Loss 0.065427    Objective Loss 0.065427                                        LR 0.100000    Time 0.033824    
2022-01-25 18:31:33,051 - Epoch: [84][   40/  211]    Overall Loss 0.065543    Objective Loss 0.065543                                        LR 0.100000    Time 0.030572    
2022-01-25 18:31:33,274 - Epoch: [84][   50/  211]    Overall Loss 0.063769    Objective Loss 0.063769                                        LR 0.100000    Time 0.028902    
2022-01-25 18:31:33,487 - Epoch: [84][   60/  211]    Overall Loss 0.063371    Objective Loss 0.063371                                        LR 0.100000    Time 0.027628    
2022-01-25 18:31:33,715 - Epoch: [84][   70/  211]    Overall Loss 0.061393    Objective Loss 0.061393                                        LR 0.100000    Time 0.026942    
2022-01-25 18:31:33,990 - Epoch: [84][   80/  211]    Overall Loss 0.060136    Objective Loss 0.060136                                        LR 0.100000    Time 0.027002    
2022-01-25 18:31:34,235 - Epoch: [84][   90/  211]    Overall Loss 0.062016    Objective Loss 0.062016                                        LR 0.100000    Time 0.026717    
2022-01-25 18:31:34,512 - Epoch: [84][  100/  211]    Overall Loss 0.061177    Objective Loss 0.061177                                        LR 0.100000    Time 0.026821    
2022-01-25 18:31:34,761 - Epoch: [84][  110/  211]    Overall Loss 0.060445    Objective Loss 0.060445                                        LR 0.100000    Time 0.026640    
2022-01-25 18:31:35,048 - Epoch: [84][  120/  211]    Overall Loss 0.059949    Objective Loss 0.059949                                        LR 0.100000    Time 0.026809    
2022-01-25 18:31:35,293 - Epoch: [84][  130/  211]    Overall Loss 0.059083    Objective Loss 0.059083                                        LR 0.100000    Time 0.026625    
2022-01-25 18:31:35,572 - Epoch: [84][  140/  211]    Overall Loss 0.058512    Objective Loss 0.058512                                        LR 0.100000    Time 0.026714    
2022-01-25 18:31:35,820 - Epoch: [84][  150/  211]    Overall Loss 0.058663    Objective Loss 0.058663                                        LR 0.100000    Time 0.026588    
2022-01-25 18:31:36,106 - Epoch: [84][  160/  211]    Overall Loss 0.058332    Objective Loss 0.058332                                        LR 0.100000    Time 0.026710    
2022-01-25 18:31:36,351 - Epoch: [84][  170/  211]    Overall Loss 0.058415    Objective Loss 0.058415                                        LR 0.100000    Time 0.026577    
2022-01-25 18:31:36,631 - Epoch: [84][  180/  211]    Overall Loss 0.058336    Objective Loss 0.058336                                        LR 0.100000    Time 0.026657    
2022-01-25 18:31:36,875 - Epoch: [84][  190/  211]    Overall Loss 0.057837    Objective Loss 0.057837                                        LR 0.100000    Time 0.026535    
2022-01-25 18:31:37,154 - Epoch: [84][  200/  211]    Overall Loss 0.058602    Objective Loss 0.058602                                        LR 0.100000    Time 0.026601    
2022-01-25 18:31:37,405 - Epoch: [84][  210/  211]    Overall Loss 0.058509    Objective Loss 0.058509    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.026528    
2022-01-25 18:31:37,449 - Epoch: [84][  211/  211]    Overall Loss 0.058589    Objective Loss 0.058589    Top1 98.588710    Top5 99.798387    LR 0.100000    Time 0.026608    
2022-01-25 18:31:37,515 - --- validate (epoch=84)-----------
2022-01-25 18:31:37,515 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:38,128 - Epoch: [84][   10/   24]    Loss 0.055635    Top1 98.593750    Top5 100.000000    
2022-01-25 18:31:38,388 - Epoch: [84][   20/   24]    Loss 0.061897    Top1 98.457031    Top5 99.960938    
2022-01-25 18:31:38,488 - Epoch: [84][   24/   24]    Loss 0.064630    Top1 98.300000    Top5 99.950000    
2022-01-25 18:31:38,546 - ==> Top1: 98.300    Top5: 99.950    Loss: 0.065

2022-01-25 18:31:38,547 - ==> Confusion:
[[601   0   2   0   0   0   1   0   0   1]
 [  0 680   2   0   1   1   0   4   0   0]
 [  0   0 583   0   0   0   0   3   0   0]
 [  0   0   3 571   1   2   0   4   1   1]
 [  0   0   2   0 552   0   0   1   0  10]
 [  0   0   0   2   1 509   4   0   1   1]
 [  2   2   1   0   1   4 620   0   1   0]
 [  0   1   5   0   0   0   0 619   0   0]
 [  2   0   3   0   4   1   2   0 567   5]
 [  0   2   0   1   8   2   0   6   0 596]]

2022-01-25 18:31:38,549 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:31:38,549 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:38,556 - 

2022-01-25 18:31:38,556 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:39,128 - Epoch: [85][   10/  211]    Overall Loss 0.054752    Objective Loss 0.054752                                        LR 0.100000    Time 0.057074    
2022-01-25 18:31:39,351 - Epoch: [85][   20/  211]    Overall Loss 0.060483    Objective Loss 0.060483                                        LR 0.100000    Time 0.039698    
2022-01-25 18:31:39,597 - Epoch: [85][   30/  211]    Overall Loss 0.054860    Objective Loss 0.054860                                        LR 0.100000    Time 0.034647    
2022-01-25 18:31:39,859 - Epoch: [85][   40/  211]    Overall Loss 0.055837    Objective Loss 0.055837                                        LR 0.100000    Time 0.032513    
2022-01-25 18:31:40,071 - Epoch: [85][   50/  211]    Overall Loss 0.057387    Objective Loss 0.057387                                        LR 0.100000    Time 0.030241    
2022-01-25 18:31:40,299 - Epoch: [85][   60/  211]    Overall Loss 0.058673    Objective Loss 0.058673                                        LR 0.100000    Time 0.028996    
2022-01-25 18:31:40,516 - Epoch: [85][   70/  211]    Overall Loss 0.058933    Objective Loss 0.058933                                        LR 0.100000    Time 0.027953    
2022-01-25 18:31:40,739 - Epoch: [85][   80/  211]    Overall Loss 0.058052    Objective Loss 0.058052                                        LR 0.100000    Time 0.027247    
2022-01-25 18:31:40,954 - Epoch: [85][   90/  211]    Overall Loss 0.057585    Objective Loss 0.057585                                        LR 0.100000    Time 0.026604    
2022-01-25 18:31:41,177 - Epoch: [85][  100/  211]    Overall Loss 0.057847    Objective Loss 0.057847                                        LR 0.100000    Time 0.026170    
2022-01-25 18:31:41,386 - Epoch: [85][  110/  211]    Overall Loss 0.058750    Objective Loss 0.058750                                        LR 0.100000    Time 0.025680    
2022-01-25 18:31:41,609 - Epoch: [85][  120/  211]    Overall Loss 0.059433    Objective Loss 0.059433                                        LR 0.100000    Time 0.025397    
2022-01-25 18:31:41,824 - Epoch: [85][  130/  211]    Overall Loss 0.059371    Objective Loss 0.059371                                        LR 0.100000    Time 0.025096    
2022-01-25 18:31:42,053 - Epoch: [85][  140/  211]    Overall Loss 0.058776    Objective Loss 0.058776                                        LR 0.100000    Time 0.024936    
2022-01-25 18:31:42,266 - Epoch: [85][  150/  211]    Overall Loss 0.058826    Objective Loss 0.058826                                        LR 0.100000    Time 0.024693    
2022-01-25 18:31:42,488 - Epoch: [85][  160/  211]    Overall Loss 0.059070    Objective Loss 0.059070                                        LR 0.100000    Time 0.024533    
2022-01-25 18:31:42,697 - Epoch: [85][  170/  211]    Overall Loss 0.059043    Objective Loss 0.059043                                        LR 0.100000    Time 0.024318    
2022-01-25 18:31:42,920 - Epoch: [85][  180/  211]    Overall Loss 0.058742    Objective Loss 0.058742                                        LR 0.100000    Time 0.024200    
2022-01-25 18:31:43,141 - Epoch: [85][  190/  211]    Overall Loss 0.059246    Objective Loss 0.059246                                        LR 0.100000    Time 0.024092    
2022-01-25 18:31:43,368 - Epoch: [85][  200/  211]    Overall Loss 0.059429    Objective Loss 0.059429                                        LR 0.100000    Time 0.024019    
2022-01-25 18:31:43,575 - Epoch: [85][  210/  211]    Overall Loss 0.058973    Objective Loss 0.058973    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.023858    
2022-01-25 18:31:43,593 - Epoch: [85][  211/  211]    Overall Loss 0.059004    Objective Loss 0.059004    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.023831    
2022-01-25 18:31:43,684 - --- validate (epoch=85)-----------
2022-01-25 18:31:43,685 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:44,165 - Epoch: [85][   10/   24]    Loss 0.061869    Top1 98.320312    Top5 100.000000    
2022-01-25 18:31:44,369 - Epoch: [85][   20/   24]    Loss 0.061388    Top1 98.437500    Top5 100.000000    
2022-01-25 18:31:44,454 - Epoch: [85][   24/   24]    Loss 0.058395    Top1 98.566667    Top5 100.000000    
2022-01-25 18:31:44,512 - ==> Top1: 98.567    Top5: 100.000    Loss: 0.058

2022-01-25 18:31:44,512 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   1 576   6   0   0   0   1   1   1]
 [  1   0   2 577   0   1   0   2   0   0]
 [  1   1   1   0 546   1   1   1   1  12]
 [  0   0   0   1   0 513   3   0   1   0]
 [  1   1   0   0   1   1 626   0   1   0]
 [  0   2   3   3   0   0   0 617   0   0]
 [  3   0   1   5   0   1   3   0 570   1]
 [  1   2   0   2   2   3   0   3   3 599]]

2022-01-25 18:31:44,514 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:31:44,515 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:44,522 - 

2022-01-25 18:31:44,522 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:45,235 - Epoch: [86][   10/  211]    Overall Loss 0.068710    Objective Loss 0.068710                                        LR 0.100000    Time 0.071248    
2022-01-25 18:31:45,450 - Epoch: [86][   20/  211]    Overall Loss 0.065399    Objective Loss 0.065399                                        LR 0.100000    Time 0.046332    
2022-01-25 18:31:45,674 - Epoch: [86][   30/  211]    Overall Loss 0.061030    Objective Loss 0.061030                                        LR 0.100000    Time 0.038333    
2022-01-25 18:31:45,882 - Epoch: [86][   40/  211]    Overall Loss 0.059476    Objective Loss 0.059476                                        LR 0.100000    Time 0.033953    
2022-01-25 18:31:46,114 - Epoch: [86][   50/  211]    Overall Loss 0.059664    Objective Loss 0.059664                                        LR 0.100000    Time 0.031783    
2022-01-25 18:31:46,325 - Epoch: [86][   60/  211]    Overall Loss 0.060805    Objective Loss 0.060805                                        LR 0.100000    Time 0.030008    
2022-01-25 18:31:46,551 - Epoch: [86][   70/  211]    Overall Loss 0.060884    Objective Loss 0.060884                                        LR 0.100000    Time 0.028949    
2022-01-25 18:31:46,764 - Epoch: [86][   80/  211]    Overall Loss 0.059761    Objective Loss 0.059761                                        LR 0.100000    Time 0.027987    
2022-01-25 18:31:46,995 - Epoch: [86][   90/  211]    Overall Loss 0.059474    Objective Loss 0.059474                                        LR 0.100000    Time 0.027432    
2022-01-25 18:31:47,209 - Epoch: [86][  100/  211]    Overall Loss 0.060545    Objective Loss 0.060545                                        LR 0.100000    Time 0.026830    
2022-01-25 18:31:47,434 - Epoch: [86][  110/  211]    Overall Loss 0.059883    Objective Loss 0.059883                                        LR 0.100000    Time 0.026434    
2022-01-25 18:31:47,646 - Epoch: [86][  120/  211]    Overall Loss 0.059612    Objective Loss 0.059612                                        LR 0.100000    Time 0.025993    
2022-01-25 18:31:47,877 - Epoch: [86][  130/  211]    Overall Loss 0.059326    Objective Loss 0.059326                                        LR 0.100000    Time 0.025772    
2022-01-25 18:31:48,092 - Epoch: [86][  140/  211]    Overall Loss 0.059349    Objective Loss 0.059349                                        LR 0.100000    Time 0.025465    
2022-01-25 18:31:48,318 - Epoch: [86][  150/  211]    Overall Loss 0.059615    Objective Loss 0.059615                                        LR 0.100000    Time 0.025267    
2022-01-25 18:31:48,532 - Epoch: [86][  160/  211]    Overall Loss 0.059271    Objective Loss 0.059271                                        LR 0.100000    Time 0.025027    
2022-01-25 18:31:48,764 - Epoch: [86][  170/  211]    Overall Loss 0.059582    Objective Loss 0.059582                                        LR 0.100000    Time 0.024913    
2022-01-25 18:31:48,979 - Epoch: [86][  180/  211]    Overall Loss 0.059815    Objective Loss 0.059815                                        LR 0.100000    Time 0.024722    
2022-01-25 18:31:49,201 - Epoch: [86][  190/  211]    Overall Loss 0.059227    Objective Loss 0.059227                                        LR 0.100000    Time 0.024588    
2022-01-25 18:31:49,417 - Epoch: [86][  200/  211]    Overall Loss 0.058757    Objective Loss 0.058757                                        LR 0.100000    Time 0.024437    
2022-01-25 18:31:49,644 - Epoch: [86][  210/  211]    Overall Loss 0.058573    Objective Loss 0.058573    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.024352    
2022-01-25 18:31:49,662 - Epoch: [86][  211/  211]    Overall Loss 0.058573    Objective Loss 0.058573    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.024322    
2022-01-25 18:31:49,773 - --- validate (epoch=86)-----------
2022-01-25 18:31:49,773 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:50,253 - Epoch: [86][   10/   24]    Loss 0.062187    Top1 98.320312    Top5 99.960938    
2022-01-25 18:31:50,496 - Epoch: [86][   20/   24]    Loss 0.055503    Top1 98.476562    Top5 99.980469    
2022-01-25 18:31:50,543 - Epoch: [86][   24/   24]    Loss 0.057581    Top1 98.500000    Top5 99.983333    
2022-01-25 18:31:50,599 - ==> Top1: 98.500    Top5: 99.983    Loss: 0.058

2022-01-25 18:31:50,600 - ==> Confusion:
[[598   0   2   0   0   0   3   0   2   0]
 [  0 685   1   0   0   1   0   1   0   0]
 [  0   2 579   0   0   0   0   0   5   0]
 [  0   0   0 575   0   4   0   2   2   0]
 [  0   0   0   0 555   0   2   1   2   5]
 [  0   0   0   2   0 513   2   0   1   0]
 [  0   0   0   0   4   1 625   0   1   0]
 [  0   2   3   1   2   0   0 616   0   1]
 [  0   0   2   0   0   1   2   0 578   1]
 [  1   3   0   0   6   4   0   6   9 586]]

2022-01-25 18:31:50,602 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:31:50,603 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:50,609 - 

2022-01-25 18:31:50,609 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:51,160 - Epoch: [87][   10/  211]    Overall Loss 0.056430    Objective Loss 0.056430                                        LR 0.100000    Time 0.055034    
2022-01-25 18:31:51,373 - Epoch: [87][   20/  211]    Overall Loss 0.054115    Objective Loss 0.054115                                        LR 0.100000    Time 0.038137    
2022-01-25 18:31:51,596 - Epoch: [87][   30/  211]    Overall Loss 0.052710    Objective Loss 0.052710                                        LR 0.100000    Time 0.032845    
2022-01-25 18:31:51,812 - Epoch: [87][   40/  211]    Overall Loss 0.054270    Objective Loss 0.054270                                        LR 0.100000    Time 0.030029    
2022-01-25 18:31:52,036 - Epoch: [87][   50/  211]    Overall Loss 0.054670    Objective Loss 0.054670                                        LR 0.100000    Time 0.028496    
2022-01-25 18:31:52,247 - Epoch: [87][   60/  211]    Overall Loss 0.054359    Objective Loss 0.054359                                        LR 0.100000    Time 0.027269    
2022-01-25 18:31:52,483 - Epoch: [87][   70/  211]    Overall Loss 0.055052    Objective Loss 0.055052                                        LR 0.100000    Time 0.026739    
2022-01-25 18:31:52,693 - Epoch: [87][   80/  211]    Overall Loss 0.054165    Objective Loss 0.054165                                        LR 0.100000    Time 0.026011    
2022-01-25 18:31:52,917 - Epoch: [87][   90/  211]    Overall Loss 0.055518    Objective Loss 0.055518                                        LR 0.100000    Time 0.025606    
2022-01-25 18:31:53,130 - Epoch: [87][  100/  211]    Overall Loss 0.056116    Objective Loss 0.056116                                        LR 0.100000    Time 0.025171    
2022-01-25 18:31:53,359 - Epoch: [87][  110/  211]    Overall Loss 0.057331    Objective Loss 0.057331                                        LR 0.100000    Time 0.024966    
2022-01-25 18:31:53,569 - Epoch: [87][  120/  211]    Overall Loss 0.056712    Objective Loss 0.056712                                        LR 0.100000    Time 0.024632    
2022-01-25 18:31:53,804 - Epoch: [87][  130/  211]    Overall Loss 0.057507    Objective Loss 0.057507                                        LR 0.100000    Time 0.024540    
2022-01-25 18:31:54,017 - Epoch: [87][  140/  211]    Overall Loss 0.057989    Objective Loss 0.057989                                        LR 0.100000    Time 0.024309    
2022-01-25 18:31:54,246 - Epoch: [87][  150/  211]    Overall Loss 0.058133    Objective Loss 0.058133                                        LR 0.100000    Time 0.024212    
2022-01-25 18:31:54,456 - Epoch: [87][  160/  211]    Overall Loss 0.058499    Objective Loss 0.058499                                        LR 0.100000    Time 0.024010    
2022-01-25 18:31:54,682 - Epoch: [87][  170/  211]    Overall Loss 0.059056    Objective Loss 0.059056                                        LR 0.100000    Time 0.023923    
2022-01-25 18:31:54,901 - Epoch: [87][  180/  211]    Overall Loss 0.059346    Objective Loss 0.059346                                        LR 0.100000    Time 0.023809    
2022-01-25 18:31:55,133 - Epoch: [87][  190/  211]    Overall Loss 0.059485    Objective Loss 0.059485                                        LR 0.100000    Time 0.023778    
2022-01-25 18:31:55,349 - Epoch: [87][  200/  211]    Overall Loss 0.059160    Objective Loss 0.059160                                        LR 0.100000    Time 0.023662    
2022-01-25 18:31:55,572 - Epoch: [87][  210/  211]    Overall Loss 0.059173    Objective Loss 0.059173    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.023596    
2022-01-25 18:31:55,593 - Epoch: [87][  211/  211]    Overall Loss 0.059324    Objective Loss 0.059324    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.023583    
2022-01-25 18:31:55,657 - --- validate (epoch=87)-----------
2022-01-25 18:31:55,658 - 6000 samples (256 per mini-batch)
2022-01-25 18:31:56,234 - Epoch: [87][   10/   24]    Loss 0.065589    Top1 98.437500    Top5 99.921875    
2022-01-25 18:31:56,449 - Epoch: [87][   20/   24]    Loss 0.064092    Top1 98.378906    Top5 99.960938    
2022-01-25 18:31:56,533 - Epoch: [87][   24/   24]    Loss 0.066888    Top1 98.316667    Top5 99.966667    
2022-01-25 18:31:56,593 - ==> Top1: 98.317    Top5: 99.967    Loss: 0.067

2022-01-25 18:31:56,593 - ==> Confusion:
[[600   0   1   1   0   0   1   0   2   0]
 [  0 682   1   0   1   1   0   1   1   1]
 [  0   1 573   5   0   0   0   3   4   0]
 [  0   0   1 576   0   1   0   2   3   0]
 [  0   1   0   0 554   0   0   3   1   6]
 [  1   1   0   5   0 502   2   0   7   0]
 [  3   1   0   0   1   4 617   0   5   0]
 [  0   0   0   2   2   0   0 618   2   1]
 [  0   0   0   0   3   0   0   0 580   1]
 [  2   1   0   0   3   1   0   4   6 598]]

2022-01-25 18:31:56,595 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:31:56,595 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:31:56,601 - 

2022-01-25 18:31:56,602 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:31:57,148 - Epoch: [88][   10/  211]    Overall Loss 0.059935    Objective Loss 0.059935                                        LR 0.100000    Time 0.054601    
2022-01-25 18:31:57,356 - Epoch: [88][   20/  211]    Overall Loss 0.060923    Objective Loss 0.060923                                        LR 0.100000    Time 0.037674    
2022-01-25 18:31:57,575 - Epoch: [88][   30/  211]    Overall Loss 0.060830    Objective Loss 0.060830                                        LR 0.100000    Time 0.032396    
2022-01-25 18:31:57,784 - Epoch: [88][   40/  211]    Overall Loss 0.060196    Objective Loss 0.060196                                        LR 0.100000    Time 0.029504    
2022-01-25 18:31:58,007 - Epoch: [88][   50/  211]    Overall Loss 0.058717    Objective Loss 0.058717                                        LR 0.100000    Time 0.028069    
2022-01-25 18:31:58,216 - Epoch: [88][   60/  211]    Overall Loss 0.058800    Objective Loss 0.058800                                        LR 0.100000    Time 0.026861    
2022-01-25 18:31:58,440 - Epoch: [88][   70/  211]    Overall Loss 0.059392    Objective Loss 0.059392                                        LR 0.100000    Time 0.026218    
2022-01-25 18:31:58,659 - Epoch: [88][   80/  211]    Overall Loss 0.059767    Objective Loss 0.059767                                        LR 0.100000    Time 0.025671    
2022-01-25 18:31:58,881 - Epoch: [88][   90/  211]    Overall Loss 0.059611    Objective Loss 0.059611                                        LR 0.100000    Time 0.025289    
2022-01-25 18:31:59,092 - Epoch: [88][  100/  211]    Overall Loss 0.059991    Objective Loss 0.059991                                        LR 0.100000    Time 0.024865    
2022-01-25 18:31:59,318 - Epoch: [88][  110/  211]    Overall Loss 0.059808    Objective Loss 0.059808                                        LR 0.100000    Time 0.024653    
2022-01-25 18:31:59,549 - Epoch: [88][  120/  211]    Overall Loss 0.059332    Objective Loss 0.059332                                        LR 0.100000    Time 0.024517    
2022-01-25 18:31:59,799 - Epoch: [88][  130/  211]    Overall Loss 0.059171    Objective Loss 0.059171                                        LR 0.100000    Time 0.024558    
2022-01-25 18:32:00,077 - Epoch: [88][  140/  211]    Overall Loss 0.058901    Objective Loss 0.058901                                        LR 0.100000    Time 0.024787    
2022-01-25 18:32:00,325 - Epoch: [88][  150/  211]    Overall Loss 0.059070    Objective Loss 0.059070                                        LR 0.100000    Time 0.024780    
2022-01-25 18:32:00,604 - Epoch: [88][  160/  211]    Overall Loss 0.059846    Objective Loss 0.059846                                        LR 0.100000    Time 0.024978    
2022-01-25 18:32:00,849 - Epoch: [88][  170/  211]    Overall Loss 0.059874    Objective Loss 0.059874                                        LR 0.100000    Time 0.024947    
2022-01-25 18:32:01,140 - Epoch: [88][  180/  211]    Overall Loss 0.060028    Objective Loss 0.060028                                        LR 0.100000    Time 0.025174    
2022-01-25 18:32:01,386 - Epoch: [88][  190/  211]    Overall Loss 0.059281    Objective Loss 0.059281                                        LR 0.100000    Time 0.025142    
2022-01-25 18:32:01,659 - Epoch: [88][  200/  211]    Overall Loss 0.058952    Objective Loss 0.058952                                        LR 0.100000    Time 0.025250    
2022-01-25 18:32:01,907 - Epoch: [88][  210/  211]    Overall Loss 0.059158    Objective Loss 0.059158    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.025223    
2022-01-25 18:32:01,949 - Epoch: [88][  211/  211]    Overall Loss 0.059144    Objective Loss 0.059144    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.025303    
2022-01-25 18:32:02,006 - --- validate (epoch=88)-----------
2022-01-25 18:32:02,006 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:02,538 - Epoch: [88][   10/   24]    Loss 0.062445    Top1 98.554688    Top5 100.000000    
2022-01-25 18:32:02,800 - Epoch: [88][   20/   24]    Loss 0.060475    Top1 98.632812    Top5 100.000000    
2022-01-25 18:32:02,884 - Epoch: [88][   24/   24]    Loss 0.064954    Top1 98.433333    Top5 100.000000    
2022-01-25 18:32:02,941 - ==> Top1: 98.433    Top5: 100.000    Loss: 0.065

2022-01-25 18:32:02,942 - ==> Confusion:
[[596   0   0   1   0   1   6   0   0   1]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   2 578   0   1   0   0   2   1   2]
 [  0   0   0 580   0   1   0   1   1   0]
 [  0   3   1   0 552   1   1   0   0   7]
 [  0   0   0   3   0 512   3   0   0   0]
 [  0   2   0   0   3   1 625   0   0   0]
 [  0   4   0   1   0   0   0 620   0   0]
 [  1   1   0   5   1   8   9   1 551   7]
 [  0   1   0   0   4   3   0   2   2 603]]

2022-01-25 18:32:02,944 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:32:02,944 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:02,950 - 

2022-01-25 18:32:02,951 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:03,649 - Epoch: [89][   10/  211]    Overall Loss 0.060558    Objective Loss 0.060558                                        LR 0.100000    Time 0.069771    
2022-01-25 18:32:03,917 - Epoch: [89][   20/  211]    Overall Loss 0.062048    Objective Loss 0.062048                                        LR 0.100000    Time 0.048257    
2022-01-25 18:32:04,154 - Epoch: [89][   30/  211]    Overall Loss 0.059836    Objective Loss 0.059836                                        LR 0.100000    Time 0.040070    
2022-01-25 18:32:04,393 - Epoch: [89][   40/  211]    Overall Loss 0.060110    Objective Loss 0.060110                                        LR 0.100000    Time 0.036016    
2022-01-25 18:32:04,609 - Epoch: [89][   50/  211]    Overall Loss 0.062195    Objective Loss 0.062195                                        LR 0.100000    Time 0.033123    
2022-01-25 18:32:04,833 - Epoch: [89][   60/  211]    Overall Loss 0.064802    Objective Loss 0.064802                                        LR 0.100000    Time 0.031328    
2022-01-25 18:32:05,066 - Epoch: [89][   70/  211]    Overall Loss 0.065981    Objective Loss 0.065981                                        LR 0.100000    Time 0.030187    
2022-01-25 18:32:05,292 - Epoch: [89][   80/  211]    Overall Loss 0.067025    Objective Loss 0.067025                                        LR 0.100000    Time 0.029229    
2022-01-25 18:32:05,502 - Epoch: [89][   90/  211]    Overall Loss 0.066074    Objective Loss 0.066074                                        LR 0.100000    Time 0.028310    
2022-01-25 18:32:05,727 - Epoch: [89][  100/  211]    Overall Loss 0.064672    Objective Loss 0.064672                                        LR 0.100000    Time 0.027720    
2022-01-25 18:32:05,944 - Epoch: [89][  110/  211]    Overall Loss 0.062698    Objective Loss 0.062698                                        LR 0.100000    Time 0.027175    
2022-01-25 18:32:06,177 - Epoch: [89][  120/  211]    Overall Loss 0.061453    Objective Loss 0.061453                                        LR 0.100000    Time 0.026849    
2022-01-25 18:32:06,387 - Epoch: [89][  130/  211]    Overall Loss 0.061016    Objective Loss 0.061016                                        LR 0.100000    Time 0.026399    
2022-01-25 18:32:06,609 - Epoch: [89][  140/  211]    Overall Loss 0.060638    Objective Loss 0.060638                                        LR 0.100000    Time 0.026097    
2022-01-25 18:32:06,822 - Epoch: [89][  150/  211]    Overall Loss 0.060153    Objective Loss 0.060153                                        LR 0.100000    Time 0.025770    
2022-01-25 18:32:07,059 - Epoch: [89][  160/  211]    Overall Loss 0.060166    Objective Loss 0.060166                                        LR 0.100000    Time 0.025638    
2022-01-25 18:32:07,273 - Epoch: [89][  170/  211]    Overall Loss 0.060133    Objective Loss 0.060133                                        LR 0.100000    Time 0.025390    
2022-01-25 18:32:07,490 - Epoch: [89][  180/  211]    Overall Loss 0.060158    Objective Loss 0.060158                                        LR 0.100000    Time 0.025178    
2022-01-25 18:32:07,700 - Epoch: [89][  190/  211]    Overall Loss 0.060085    Objective Loss 0.060085                                        LR 0.100000    Time 0.024961    
2022-01-25 18:32:07,925 - Epoch: [89][  200/  211]    Overall Loss 0.059891    Objective Loss 0.059891                                        LR 0.100000    Time 0.024833    
2022-01-25 18:32:08,138 - Epoch: [89][  210/  211]    Overall Loss 0.059805    Objective Loss 0.059805    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.024665    
2022-01-25 18:32:08,166 - Epoch: [89][  211/  211]    Overall Loss 0.059810    Objective Loss 0.059810    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.024680    
2022-01-25 18:32:08,244 - --- validate (epoch=89)-----------
2022-01-25 18:32:08,245 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:08,722 - Epoch: [89][   10/   24]    Loss 0.057703    Top1 98.437500    Top5 100.000000    
2022-01-25 18:32:08,922 - Epoch: [89][   20/   24]    Loss 0.054879    Top1 98.593750    Top5 100.000000    
2022-01-25 18:32:09,003 - Epoch: [89][   24/   24]    Loss 0.056040    Top1 98.516667    Top5 100.000000    
2022-01-25 18:32:09,059 - ==> Top1: 98.517    Top5: 100.000    Loss: 0.056

2022-01-25 18:32:09,060 - ==> Confusion:
[[601   0   1   1   0   0   2   0   0   0]
 [  0 682   1   0   0   1   0   4   0   0]
 [  0   0 576   4   0   0   0   5   1   0]
 [  0   0   2 577   0   1   0   2   1   0]
 [  0   1   0   0 554   0   1   3   0   6]
 [  1   0   0   3   0 508   3   0   2   1]
 [  1   1   0   0   1   2 625   0   1   0]
 [  0   1   0   0   1   0   0 623   0   0]
 [  2   0   0   3   0   5   0   2 572   0]
 [  1   2   0   1   4   5   0   6   3 593]]

2022-01-25 18:32:09,062 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:32:09,062 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:09,069 - 

2022-01-25 18:32:09,070 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:09,612 - Epoch: [90][   10/  211]    Overall Loss 0.055354    Objective Loss 0.055354                                        LR 0.100000    Time 0.054140    
2022-01-25 18:32:09,863 - Epoch: [90][   20/  211]    Overall Loss 0.052977    Objective Loss 0.052977                                        LR 0.100000    Time 0.039609    
2022-01-25 18:32:10,101 - Epoch: [90][   30/  211]    Overall Loss 0.052285    Objective Loss 0.052285                                        LR 0.100000    Time 0.034325    
2022-01-25 18:32:10,325 - Epoch: [90][   40/  211]    Overall Loss 0.053659    Objective Loss 0.053659                                        LR 0.100000    Time 0.031339    
2022-01-25 18:32:10,536 - Epoch: [90][   50/  211]    Overall Loss 0.054983    Objective Loss 0.054983                                        LR 0.100000    Time 0.029280    
2022-01-25 18:32:10,822 - Epoch: [90][   60/  211]    Overall Loss 0.056286    Objective Loss 0.056286                                        LR 0.100000    Time 0.029161    
2022-01-25 18:32:11,077 - Epoch: [90][   70/  211]    Overall Loss 0.057436    Objective Loss 0.057436                                        LR 0.100000    Time 0.028637    
2022-01-25 18:32:11,330 - Epoch: [90][   80/  211]    Overall Loss 0.058218    Objective Loss 0.058218                                        LR 0.100000    Time 0.028209    
2022-01-25 18:32:11,550 - Epoch: [90][   90/  211]    Overall Loss 0.058543    Objective Loss 0.058543                                        LR 0.100000    Time 0.027514    
2022-01-25 18:32:11,773 - Epoch: [90][  100/  211]    Overall Loss 0.059027    Objective Loss 0.059027                                        LR 0.100000    Time 0.026990    
2022-01-25 18:32:12,003 - Epoch: [90][  110/  211]    Overall Loss 0.058902    Objective Loss 0.058902                                        LR 0.100000    Time 0.026629    
2022-01-25 18:32:12,226 - Epoch: [90][  120/  211]    Overall Loss 0.058622    Objective Loss 0.058622                                        LR 0.100000    Time 0.026262    
2022-01-25 18:32:12,437 - Epoch: [90][  130/  211]    Overall Loss 0.058970    Objective Loss 0.058970                                        LR 0.100000    Time 0.025866    
2022-01-25 18:32:12,666 - Epoch: [90][  140/  211]    Overall Loss 0.058204    Objective Loss 0.058204                                        LR 0.100000    Time 0.025652    
2022-01-25 18:32:12,878 - Epoch: [90][  150/  211]    Overall Loss 0.058018    Objective Loss 0.058018                                        LR 0.100000    Time 0.025348    
2022-01-25 18:32:13,109 - Epoch: [90][  160/  211]    Overall Loss 0.057801    Objective Loss 0.057801                                        LR 0.100000    Time 0.025206    
2022-01-25 18:32:13,320 - Epoch: [90][  170/  211]    Overall Loss 0.057561    Objective Loss 0.057561                                        LR 0.100000    Time 0.024962    
2022-01-25 18:32:13,541 - Epoch: [90][  180/  211]    Overall Loss 0.057837    Objective Loss 0.057837                                        LR 0.100000    Time 0.024803    
2022-01-25 18:32:13,756 - Epoch: [90][  190/  211]    Overall Loss 0.057788    Objective Loss 0.057788                                        LR 0.100000    Time 0.024627    
2022-01-25 18:32:13,977 - Epoch: [90][  200/  211]    Overall Loss 0.057976    Objective Loss 0.057976                                        LR 0.100000    Time 0.024501    
2022-01-25 18:32:14,188 - Epoch: [90][  210/  211]    Overall Loss 0.058092    Objective Loss 0.058092    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.024334    
2022-01-25 18:32:14,206 - Epoch: [90][  211/  211]    Overall Loss 0.058140    Objective Loss 0.058140    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.024305    
2022-01-25 18:32:14,279 - --- validate (epoch=90)-----------
2022-01-25 18:32:14,279 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:14,753 - Epoch: [90][   10/   24]    Loss 0.065293    Top1 98.320312    Top5 99.921875    
2022-01-25 18:32:14,952 - Epoch: [90][   20/   24]    Loss 0.067000    Top1 98.339844    Top5 99.960938    
2022-01-25 18:32:15,039 - Epoch: [90][   24/   24]    Loss 0.067485    Top1 98.233333    Top5 99.966667    
2022-01-25 18:32:15,095 - ==> Top1: 98.233    Top5: 99.967    Loss: 0.067

2022-01-25 18:32:15,096 - ==> Confusion:
[[601   0   0   0   0   0   1   1   1   1]
 [  0 684   1   0   0   0   0   3   0   0]
 [  0   0 565   3   0   0   1  14   3   0]
 [  0   0   0 579   0   1   0   2   1   0]
 [  1   1   0   0 543   1   2   4   4   9]
 [  0   1   0   4   2 507   0   0   2   2]
 [  5   1   0   0   2   7 615   0   1   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  0   1   0   1   0   2   0   0 579   1]
 [  2   0   0   1   1   1   0   7   3 600]]

2022-01-25 18:32:15,098 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:32:15,099 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:15,106 - 

2022-01-25 18:32:15,106 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:15,808 - Epoch: [91][   10/  211]    Overall Loss 0.065184    Objective Loss 0.065184                                        LR 0.100000    Time 0.070083    
2022-01-25 18:32:16,013 - Epoch: [91][   20/  211]    Overall Loss 0.061375    Objective Loss 0.061375                                        LR 0.100000    Time 0.045295    
2022-01-25 18:32:16,239 - Epoch: [91][   30/  211]    Overall Loss 0.059047    Objective Loss 0.059047                                        LR 0.100000    Time 0.037704    
2022-01-25 18:32:16,447 - Epoch: [91][   40/  211]    Overall Loss 0.056777    Objective Loss 0.056777                                        LR 0.100000    Time 0.033493    
2022-01-25 18:32:16,673 - Epoch: [91][   50/  211]    Overall Loss 0.057321    Objective Loss 0.057321                                        LR 0.100000    Time 0.031292    
2022-01-25 18:32:16,882 - Epoch: [91][   60/  211]    Overall Loss 0.057766    Objective Loss 0.057766                                        LR 0.100000    Time 0.029558    
2022-01-25 18:32:17,111 - Epoch: [91][   70/  211]    Overall Loss 0.058031    Objective Loss 0.058031                                        LR 0.100000    Time 0.028602    
2022-01-25 18:32:17,322 - Epoch: [91][   80/  211]    Overall Loss 0.058876    Objective Loss 0.058876                                        LR 0.100000    Time 0.027667    
2022-01-25 18:32:17,554 - Epoch: [91][   90/  211]    Overall Loss 0.058384    Objective Loss 0.058384                                        LR 0.100000    Time 0.027162    
2022-01-25 18:32:17,771 - Epoch: [91][  100/  211]    Overall Loss 0.059581    Objective Loss 0.059581                                        LR 0.100000    Time 0.026616    
2022-01-25 18:32:17,994 - Epoch: [91][  110/  211]    Overall Loss 0.059609    Objective Loss 0.059609                                        LR 0.100000    Time 0.026220    
2022-01-25 18:32:18,206 - Epoch: [91][  120/  211]    Overall Loss 0.059478    Objective Loss 0.059478                                        LR 0.100000    Time 0.025797    
2022-01-25 18:32:18,434 - Epoch: [91][  130/  211]    Overall Loss 0.058471    Objective Loss 0.058471                                        LR 0.100000    Time 0.025562    
2022-01-25 18:32:18,658 - Epoch: [91][  140/  211]    Overall Loss 0.057863    Objective Loss 0.057863                                        LR 0.100000    Time 0.025335    
2022-01-25 18:32:18,895 - Epoch: [91][  150/  211]    Overall Loss 0.057898    Objective Loss 0.057898                                        LR 0.100000    Time 0.025227    
2022-01-25 18:32:19,174 - Epoch: [91][  160/  211]    Overall Loss 0.057831    Objective Loss 0.057831                                        LR 0.100000    Time 0.025387    
2022-01-25 18:32:19,421 - Epoch: [91][  170/  211]    Overall Loss 0.058311    Objective Loss 0.058311                                        LR 0.100000    Time 0.025344    
2022-01-25 18:32:19,708 - Epoch: [91][  180/  211]    Overall Loss 0.057755    Objective Loss 0.057755                                        LR 0.100000    Time 0.025529    
2022-01-25 18:32:19,958 - Epoch: [91][  190/  211]    Overall Loss 0.057640    Objective Loss 0.057640                                        LR 0.100000    Time 0.025498    
2022-01-25 18:32:20,233 - Epoch: [91][  200/  211]    Overall Loss 0.057751    Objective Loss 0.057751                                        LR 0.100000    Time 0.025597    
2022-01-25 18:32:20,477 - Epoch: [91][  210/  211]    Overall Loss 0.057730    Objective Loss 0.057730    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.025539    
2022-01-25 18:32:20,496 - Epoch: [91][  211/  211]    Overall Loss 0.057629    Objective Loss 0.057629    Top1 99.395161    Top5 100.000000    LR 0.100000    Time 0.025506    
2022-01-25 18:32:20,551 - --- validate (epoch=91)-----------
2022-01-25 18:32:20,551 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:21,024 - Epoch: [91][   10/   24]    Loss 0.057709    Top1 98.476562    Top5 99.960938    
2022-01-25 18:32:21,234 - Epoch: [91][   20/   24]    Loss 0.060129    Top1 98.476562    Top5 99.960938    
2022-01-25 18:32:21,304 - Epoch: [91][   24/   24]    Loss 0.059900    Top1 98.466667    Top5 99.966667    
2022-01-25 18:32:21,359 - ==> Top1: 98.467    Top5: 99.967    Loss: 0.060

2022-01-25 18:32:21,359 - ==> Confusion:
[[599   0   1   1   0   0   2   0   1   1]
 [  0 684   0   0   0   0   1   3   0   0]
 [  0   1 567   1   1   0   0  14   2   0]
 [  0   0   0 577   0   2   0   3   1   0]
 [  0   1   0   0 552   0   1   2   2   7]
 [  1   1   0   4   0 509   3   0   0   0]
 [  0   2   0   0   0   1 627   0   1   0]
 [  0   2   0   1   0   0   0 622   0   0]
 [  0   0   1   0   1   1   2   1 577   1]
 [  0   1   0   1   7   2   1   5   4 594]]

2022-01-25 18:32:21,361 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:32:21,361 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:21,366 - 

2022-01-25 18:32:21,367 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:22,067 - Epoch: [92][   10/  211]    Overall Loss 0.047124    Objective Loss 0.047124                                        LR 0.100000    Time 0.069962    
2022-01-25 18:32:22,332 - Epoch: [92][   20/  211]    Overall Loss 0.047864    Objective Loss 0.047864                                        LR 0.100000    Time 0.048200    
2022-01-25 18:32:22,574 - Epoch: [92][   30/  211]    Overall Loss 0.051012    Objective Loss 0.051012                                        LR 0.100000    Time 0.040203    
2022-01-25 18:32:22,852 - Epoch: [92][   40/  211]    Overall Loss 0.054399    Objective Loss 0.054399                                        LR 0.100000    Time 0.037096    
2022-01-25 18:32:23,101 - Epoch: [92][   50/  211]    Overall Loss 0.055796    Objective Loss 0.055796                                        LR 0.100000    Time 0.034640    
2022-01-25 18:32:23,383 - Epoch: [92][   60/  211]    Overall Loss 0.056725    Objective Loss 0.056725                                        LR 0.100000    Time 0.033569    
2022-01-25 18:32:23,631 - Epoch: [92][   70/  211]    Overall Loss 0.058013    Objective Loss 0.058013                                        LR 0.100000    Time 0.032310    
2022-01-25 18:32:23,915 - Epoch: [92][   80/  211]    Overall Loss 0.057609    Objective Loss 0.057609                                        LR 0.100000    Time 0.031820    
2022-01-25 18:32:24,163 - Epoch: [92][   90/  211]    Overall Loss 0.059192    Objective Loss 0.059192                                        LR 0.100000    Time 0.031033    
2022-01-25 18:32:24,444 - Epoch: [92][  100/  211]    Overall Loss 0.058443    Objective Loss 0.058443                                        LR 0.100000    Time 0.030739    
2022-01-25 18:32:24,691 - Epoch: [92][  110/  211]    Overall Loss 0.058354    Objective Loss 0.058354                                        LR 0.100000    Time 0.030180    
2022-01-25 18:32:24,979 - Epoch: [92][  120/  211]    Overall Loss 0.058844    Objective Loss 0.058844                                        LR 0.100000    Time 0.030063    
2022-01-25 18:32:25,227 - Epoch: [92][  130/  211]    Overall Loss 0.058682    Objective Loss 0.058682                                        LR 0.100000    Time 0.029655    
2022-01-25 18:32:25,507 - Epoch: [92][  140/  211]    Overall Loss 0.057882    Objective Loss 0.057882                                        LR 0.100000    Time 0.029535    
2022-01-25 18:32:25,757 - Epoch: [92][  150/  211]    Overall Loss 0.057971    Objective Loss 0.057971                                        LR 0.100000    Time 0.029229    
2022-01-25 18:32:26,034 - Epoch: [92][  160/  211]    Overall Loss 0.058110    Objective Loss 0.058110                                        LR 0.100000    Time 0.029132    
2022-01-25 18:32:26,287 - Epoch: [92][  170/  211]    Overall Loss 0.058859    Objective Loss 0.058859                                        LR 0.100000    Time 0.028905    
2022-01-25 18:32:26,564 - Epoch: [92][  180/  211]    Overall Loss 0.058975    Objective Loss 0.058975                                        LR 0.100000    Time 0.028838    
2022-01-25 18:32:26,810 - Epoch: [92][  190/  211]    Overall Loss 0.058739    Objective Loss 0.058739                                        LR 0.100000    Time 0.028613    
2022-01-25 18:32:27,090 - Epoch: [92][  200/  211]    Overall Loss 0.058651    Objective Loss 0.058651                                        LR 0.100000    Time 0.028582    
2022-01-25 18:32:27,335 - Epoch: [92][  210/  211]    Overall Loss 0.058597    Objective Loss 0.058597    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.028384    
2022-01-25 18:32:27,381 - Epoch: [92][  211/  211]    Overall Loss 0.058554    Objective Loss 0.058554    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.028467    
2022-01-25 18:32:27,437 - --- validate (epoch=92)-----------
2022-01-25 18:32:27,438 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:27,907 - Epoch: [92][   10/   24]    Loss 0.058950    Top1 98.710938    Top5 99.960938    
2022-01-25 18:32:28,103 - Epoch: [92][   20/   24]    Loss 0.057439    Top1 98.613281    Top5 99.941406    
2022-01-25 18:32:28,188 - Epoch: [92][   24/   24]    Loss 0.060213    Top1 98.550000    Top5 99.950000    
2022-01-25 18:32:28,243 - ==> Top1: 98.550    Top5: 99.950    Loss: 0.060

2022-01-25 18:32:28,244 - ==> Confusion:
[[598   0   0   0   0   0   6   1   0   0]
 [  0 684   1   1   0   0   1   1   0   0]
 [  0   0 583   1   0   0   1   0   1   0]
 [  0   0   6 574   0   1   0   0   2   0]
 [  0   2   0   0 551   1   2   0   1   8]
 [  0   0   0   2   0 503   8   0   4   1]
 [  0   0   0   0   2   0 629   0   0   0]
 [  0   1   5   1   2   0   0 614   0   2]
 [  0   0   2   0   0   1   3   1 575   2]
 [  0   2   0   0   3   2   0   3   3 602]]

2022-01-25 18:32:28,246 - ==> Best [Top1: 98.667   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 80]
2022-01-25 18:32:28,246 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:28,252 - 

2022-01-25 18:32:28,253 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:28,814 - Epoch: [93][   10/  211]    Overall Loss 0.066526    Objective Loss 0.066526                                        LR 0.100000    Time 0.056072    
2022-01-25 18:32:29,024 - Epoch: [93][   20/  211]    Overall Loss 0.060081    Objective Loss 0.060081                                        LR 0.100000    Time 0.038501    
2022-01-25 18:32:29,246 - Epoch: [93][   30/  211]    Overall Loss 0.056919    Objective Loss 0.056919                                        LR 0.100000    Time 0.033065    
2022-01-25 18:32:29,462 - Epoch: [93][   40/  211]    Overall Loss 0.057193    Objective Loss 0.057193                                        LR 0.100000    Time 0.030183    
2022-01-25 18:32:29,682 - Epoch: [93][   50/  211]    Overall Loss 0.056636    Objective Loss 0.056636                                        LR 0.100000    Time 0.028536    
2022-01-25 18:32:29,890 - Epoch: [93][   60/  211]    Overall Loss 0.058316    Objective Loss 0.058316                                        LR 0.100000    Time 0.027249    
2022-01-25 18:32:30,122 - Epoch: [93][   70/  211]    Overall Loss 0.058174    Objective Loss 0.058174                                        LR 0.100000    Time 0.026664    
2022-01-25 18:32:30,331 - Epoch: [93][   80/  211]    Overall Loss 0.057490    Objective Loss 0.057490                                        LR 0.100000    Time 0.025941    
2022-01-25 18:32:30,559 - Epoch: [93][   90/  211]    Overall Loss 0.057193    Objective Loss 0.057193                                        LR 0.100000    Time 0.025584    
2022-01-25 18:32:30,769 - Epoch: [93][  100/  211]    Overall Loss 0.057558    Objective Loss 0.057558                                        LR 0.100000    Time 0.025119    
2022-01-25 18:32:30,999 - Epoch: [93][  110/  211]    Overall Loss 0.058152    Objective Loss 0.058152                                        LR 0.100000    Time 0.024923    
2022-01-25 18:32:31,255 - Epoch: [93][  120/  211]    Overall Loss 0.058098    Objective Loss 0.058098                                        LR 0.100000    Time 0.024980    
2022-01-25 18:32:31,535 - Epoch: [93][  130/  211]    Overall Loss 0.058526    Objective Loss 0.058526                                        LR 0.100000    Time 0.025207    
2022-01-25 18:32:31,787 - Epoch: [93][  140/  211]    Overall Loss 0.057757    Objective Loss 0.057757                                        LR 0.100000    Time 0.025209    
2022-01-25 18:32:32,064 - Epoch: [93][  150/  211]    Overall Loss 0.057894    Objective Loss 0.057894                                        LR 0.100000    Time 0.025368    
2022-01-25 18:32:32,312 - Epoch: [93][  160/  211]    Overall Loss 0.057651    Objective Loss 0.057651                                        LR 0.100000    Time 0.025334    
2022-01-25 18:32:32,599 - Epoch: [93][  170/  211]    Overall Loss 0.057377    Objective Loss 0.057377                                        LR 0.100000    Time 0.025532    
2022-01-25 18:32:32,846 - Epoch: [93][  180/  211]    Overall Loss 0.057126    Objective Loss 0.057126                                        LR 0.100000    Time 0.025483    
2022-01-25 18:32:33,125 - Epoch: [93][  190/  211]    Overall Loss 0.057029    Objective Loss 0.057029                                        LR 0.100000    Time 0.025606    
2022-01-25 18:32:33,373 - Epoch: [93][  200/  211]    Overall Loss 0.057119    Objective Loss 0.057119                                        LR 0.100000    Time 0.025565    
2022-01-25 18:32:33,652 - Epoch: [93][  210/  211]    Overall Loss 0.056805    Objective Loss 0.056805    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.025674    
2022-01-25 18:32:33,670 - Epoch: [93][  211/  211]    Overall Loss 0.056749    Objective Loss 0.056749    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.025639    
2022-01-25 18:32:33,727 - --- validate (epoch=93)-----------
2022-01-25 18:32:33,727 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:34,239 - Epoch: [93][   10/   24]    Loss 0.057850    Top1 98.671875    Top5 99.960938    
2022-01-25 18:32:34,477 - Epoch: [93][   20/   24]    Loss 0.057780    Top1 98.652344    Top5 99.980469    
2022-01-25 18:32:34,580 - Epoch: [93][   24/   24]    Loss 0.056498    Top1 98.700000    Top5 99.983333    
2022-01-25 18:32:34,636 - ==> Top1: 98.700    Top5: 99.983    Loss: 0.056

2022-01-25 18:32:34,637 - ==> Confusion:
[[602   0   0   0   0   0   3   0   0   0]
 [  0 683   2   1   0   0   0   2   0   0]
 [  1   0 579   3   0   0   0   1   2   0]
 [  1   1   1 575   0   3   0   0   2   0]
 [  0   0   1   0 559   0   1   0   1   3]
 [  0   0   0   1   0 511   2   0   4   0]
 [  1   0   0   0   1   0 628   0   1   0]
 [  0   1   0   2   1   0   0 621   0   0]
 [  0   0   1   0   1   1   2   1 578   0]
 [  1   2   0   1  10   3   0   5   7 586]]

2022-01-25 18:32:34,639 - ==> Best [Top1: 98.700   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 93]
2022-01-25 18:32:34,639 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:34,646 - 

2022-01-25 18:32:34,646 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:35,344 - Epoch: [94][   10/  211]    Overall Loss 0.056293    Objective Loss 0.056293                                        LR 0.100000    Time 0.069728    
2022-01-25 18:32:35,594 - Epoch: [94][   20/  211]    Overall Loss 0.057760    Objective Loss 0.057760                                        LR 0.100000    Time 0.047313    
2022-01-25 18:32:35,841 - Epoch: [94][   30/  211]    Overall Loss 0.061486    Objective Loss 0.061486                                        LR 0.100000    Time 0.039769    
2022-01-25 18:32:36,118 - Epoch: [94][   40/  211]    Overall Loss 0.059090    Objective Loss 0.059090                                        LR 0.100000    Time 0.036753    
2022-01-25 18:32:36,366 - Epoch: [94][   50/  211]    Overall Loss 0.058746    Objective Loss 0.058746                                        LR 0.100000    Time 0.034344    
2022-01-25 18:32:36,650 - Epoch: [94][   60/  211]    Overall Loss 0.057391    Objective Loss 0.057391                                        LR 0.100000    Time 0.033361    
2022-01-25 18:32:36,905 - Epoch: [94][   70/  211]    Overall Loss 0.057437    Objective Loss 0.057437                                        LR 0.100000    Time 0.032232    
2022-01-25 18:32:37,187 - Epoch: [94][   80/  211]    Overall Loss 0.057607    Objective Loss 0.057607                                        LR 0.100000    Time 0.031727    
2022-01-25 18:32:37,436 - Epoch: [94][   90/  211]    Overall Loss 0.057555    Objective Loss 0.057555                                        LR 0.100000    Time 0.030960    
2022-01-25 18:32:37,717 - Epoch: [94][  100/  211]    Overall Loss 0.056708    Objective Loss 0.056708                                        LR 0.100000    Time 0.030669    
2022-01-25 18:32:37,973 - Epoch: [94][  110/  211]    Overall Loss 0.056682    Objective Loss 0.056682                                        LR 0.100000    Time 0.030200    
2022-01-25 18:32:38,250 - Epoch: [94][  120/  211]    Overall Loss 0.056384    Objective Loss 0.056384                                        LR 0.100000    Time 0.029996    
2022-01-25 18:32:38,502 - Epoch: [94][  130/  211]    Overall Loss 0.057316    Objective Loss 0.057316                                        LR 0.100000    Time 0.029619    
2022-01-25 18:32:38,777 - Epoch: [94][  140/  211]    Overall Loss 0.056912    Objective Loss 0.056912                                        LR 0.100000    Time 0.029469    
2022-01-25 18:32:39,027 - Epoch: [94][  150/  211]    Overall Loss 0.057666    Objective Loss 0.057666                                        LR 0.100000    Time 0.029170    
2022-01-25 18:32:39,311 - Epoch: [94][  160/  211]    Overall Loss 0.058065    Objective Loss 0.058065                                        LR 0.100000    Time 0.029119    
2022-01-25 18:32:39,558 - Epoch: [94][  170/  211]    Overall Loss 0.057520    Objective Loss 0.057520                                        LR 0.100000    Time 0.028856    
2022-01-25 18:32:39,836 - Epoch: [94][  180/  211]    Overall Loss 0.057102    Objective Loss 0.057102                                        LR 0.100000    Time 0.028792    
2022-01-25 18:32:40,084 - Epoch: [94][  190/  211]    Overall Loss 0.056590    Objective Loss 0.056590                                        LR 0.100000    Time 0.028583    
2022-01-25 18:32:40,362 - Epoch: [94][  200/  211]    Overall Loss 0.056159    Objective Loss 0.056159                                        LR 0.100000    Time 0.028540    
2022-01-25 18:32:40,617 - Epoch: [94][  210/  211]    Overall Loss 0.056008    Objective Loss 0.056008    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.028393    
2022-01-25 18:32:40,634 - Epoch: [94][  211/  211]    Overall Loss 0.055894    Objective Loss 0.055894    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.028341    
2022-01-25 18:32:40,691 - --- validate (epoch=94)-----------
2022-01-25 18:32:40,691 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:41,157 - Epoch: [94][   10/   24]    Loss 0.065189    Top1 98.398438    Top5 99.960938    
2022-01-25 18:32:41,357 - Epoch: [94][   20/   24]    Loss 0.061641    Top1 98.457031    Top5 99.980469    
2022-01-25 18:32:41,444 - Epoch: [94][   24/   24]    Loss 0.059098    Top1 98.516667    Top5 99.983333    
2022-01-25 18:32:41,507 - ==> Top1: 98.517    Top5: 99.983    Loss: 0.059

2022-01-25 18:32:41,508 - ==> Confusion:
[[600   0   0   1   0   0   1   1   1   1]
 [  0 687   0   0   0   0   0   1   0   0]
 [  1   0 573   1   0   0   1   9   0   1]
 [  0   0   0 580   0   1   0   1   1   0]
 [  0   2   0   0 554   0   1   1   0   7]
 [  1   2   0   2   0 509   3   0   1   0]
 [  1   2   1   0   1   1 624   0   1   0]
 [  0   3   1   0   1   0   0 620   0   0]
 [  5   1   1   1   2   2   3   1 564   4]
 [  0   1   0   0   4   1   0   7   2 600]]

2022-01-25 18:32:41,511 - ==> Best [Top1: 98.700   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 93]
2022-01-25 18:32:41,511 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:41,520 - 

2022-01-25 18:32:41,520 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:42,245 - Epoch: [95][   10/  211]    Overall Loss 0.059451    Objective Loss 0.059451                                        LR 0.100000    Time 0.072486    
2022-01-25 18:32:42,515 - Epoch: [95][   20/  211]    Overall Loss 0.054403    Objective Loss 0.054403                                        LR 0.100000    Time 0.049690    
2022-01-25 18:32:42,759 - Epoch: [95][   30/  211]    Overall Loss 0.054793    Objective Loss 0.054793                                        LR 0.100000    Time 0.041273    
2022-01-25 18:32:43,038 - Epoch: [95][   40/  211]    Overall Loss 0.054878    Objective Loss 0.054878                                        LR 0.100000    Time 0.037904    
2022-01-25 18:32:43,282 - Epoch: [95][   50/  211]    Overall Loss 0.054819    Objective Loss 0.054819                                        LR 0.100000    Time 0.035215    
2022-01-25 18:32:43,573 - Epoch: [95][   60/  211]    Overall Loss 0.055203    Objective Loss 0.055203                                        LR 0.100000    Time 0.034182    
2022-01-25 18:32:43,820 - Epoch: [95][   70/  211]    Overall Loss 0.056518    Objective Loss 0.056518                                        LR 0.100000    Time 0.032828    
2022-01-25 18:32:44,101 - Epoch: [95][   80/  211]    Overall Loss 0.057093    Objective Loss 0.057093                                        LR 0.100000    Time 0.032226    
2022-01-25 18:32:44,348 - Epoch: [95][   90/  211]    Overall Loss 0.057993    Objective Loss 0.057993                                        LR 0.100000    Time 0.031389    
2022-01-25 18:32:44,637 - Epoch: [95][  100/  211]    Overall Loss 0.059571    Objective Loss 0.059571                                        LR 0.100000    Time 0.031131    
2022-01-25 18:32:44,888 - Epoch: [95][  110/  211]    Overall Loss 0.058876    Objective Loss 0.058876                                        LR 0.100000    Time 0.030576    
2022-01-25 18:32:45,165 - Epoch: [95][  120/  211]    Overall Loss 0.058529    Objective Loss 0.058529                                        LR 0.100000    Time 0.030339    
2022-01-25 18:32:45,414 - Epoch: [95][  130/  211]    Overall Loss 0.058044    Objective Loss 0.058044                                        LR 0.100000    Time 0.029919    
2022-01-25 18:32:45,701 - Epoch: [95][  140/  211]    Overall Loss 0.057878    Objective Loss 0.057878                                        LR 0.100000    Time 0.029830    
2022-01-25 18:32:45,950 - Epoch: [95][  150/  211]    Overall Loss 0.057122    Objective Loss 0.057122                                        LR 0.100000    Time 0.029497    
2022-01-25 18:32:46,225 - Epoch: [95][  160/  211]    Overall Loss 0.056959    Objective Loss 0.056959                                        LR 0.100000    Time 0.029370    
2022-01-25 18:32:46,472 - Epoch: [95][  170/  211]    Overall Loss 0.056562    Objective Loss 0.056562                                        LR 0.100000    Time 0.029091    
2022-01-25 18:32:46,760 - Epoch: [95][  180/  211]    Overall Loss 0.055944    Objective Loss 0.055944                                        LR 0.100000    Time 0.029075    
2022-01-25 18:32:47,007 - Epoch: [95][  190/  211]    Overall Loss 0.055797    Objective Loss 0.055797                                        LR 0.100000    Time 0.028843    
2022-01-25 18:32:47,286 - Epoch: [95][  200/  211]    Overall Loss 0.056038    Objective Loss 0.056038                                        LR 0.100000    Time 0.028791    
2022-01-25 18:32:47,532 - Epoch: [95][  210/  211]    Overall Loss 0.055853    Objective Loss 0.055853    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.028594    
2022-01-25 18:32:47,577 - Epoch: [95][  211/  211]    Overall Loss 0.056009    Objective Loss 0.056009    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.028667    
2022-01-25 18:32:47,632 - --- validate (epoch=95)-----------
2022-01-25 18:32:47,632 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:48,155 - Epoch: [95][   10/   24]    Loss 0.064660    Top1 98.242188    Top5 99.960938    
2022-01-25 18:32:48,392 - Epoch: [95][   20/   24]    Loss 0.060498    Top1 98.359375    Top5 99.980469    
2022-01-25 18:32:48,477 - Epoch: [95][   24/   24]    Loss 0.058583    Top1 98.450000    Top5 99.983333    
2022-01-25 18:32:48,542 - ==> Top1: 98.450    Top5: 99.983    Loss: 0.059

2022-01-25 18:32:48,543 - ==> Confusion:
[[600   0   0   0   0   1   3   0   1   0]
 [  0 682   0   1   1   1   0   3   0   0]
 [  1   0 571   3   0   0   0   6   3   2]
 [  0   0   2 572   0   3   0   3   3   0]
 [  0   0   0   0 552   0   0   0   0  13]
 [  0   0   0   1   0 510   4   0   2   1]
 [  1   1   0   0   1   2 626   0   0   0]
 [  0   1   1   1   1   0   0 617   0   4]
 [  2   0   0   0   1   1   6   0 572   2]
 [  0   1   0   0   6   0   0   1   2 605]]

2022-01-25 18:32:48,544 - ==> Best [Top1: 98.700   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 93]
2022-01-25 18:32:48,545 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:48,551 - 

2022-01-25 18:32:48,551 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:49,102 - Epoch: [96][   10/  211]    Overall Loss 0.048230    Objective Loss 0.048230                                        LR 0.100000    Time 0.055048    
2022-01-25 18:32:49,365 - Epoch: [96][   20/  211]    Overall Loss 0.053906    Objective Loss 0.053906                                        LR 0.100000    Time 0.040654    
2022-01-25 18:32:49,610 - Epoch: [96][   30/  211]    Overall Loss 0.056630    Objective Loss 0.056630                                        LR 0.100000    Time 0.035231    
2022-01-25 18:32:49,886 - Epoch: [96][   40/  211]    Overall Loss 0.056842    Objective Loss 0.056842                                        LR 0.100000    Time 0.033330    
2022-01-25 18:32:50,139 - Epoch: [96][   50/  211]    Overall Loss 0.055246    Objective Loss 0.055246                                        LR 0.100000    Time 0.031710    
2022-01-25 18:32:50,420 - Epoch: [96][   60/  211]    Overall Loss 0.054628    Objective Loss 0.054628                                        LR 0.100000    Time 0.031106    
2022-01-25 18:32:50,630 - Epoch: [96][   70/  211]    Overall Loss 0.054800    Objective Loss 0.054800                                        LR 0.100000    Time 0.029661    
2022-01-25 18:32:50,857 - Epoch: [96][   80/  211]    Overall Loss 0.054440    Objective Loss 0.054440                                        LR 0.100000    Time 0.028786    
2022-01-25 18:32:51,075 - Epoch: [96][   90/  211]    Overall Loss 0.054038    Objective Loss 0.054038                                        LR 0.100000    Time 0.028007    
2022-01-25 18:32:51,297 - Epoch: [96][  100/  211]    Overall Loss 0.054681    Objective Loss 0.054681                                        LR 0.100000    Time 0.027415    
2022-01-25 18:32:51,542 - Epoch: [96][  110/  211]    Overall Loss 0.054811    Objective Loss 0.054811                                        LR 0.100000    Time 0.027150    
2022-01-25 18:32:51,822 - Epoch: [96][  120/  211]    Overall Loss 0.055655    Objective Loss 0.055655                                        LR 0.100000    Time 0.027222    
2022-01-25 18:32:52,072 - Epoch: [96][  130/  211]    Overall Loss 0.055839    Objective Loss 0.055839                                        LR 0.100000    Time 0.027043    
2022-01-25 18:32:52,351 - Epoch: [96][  140/  211]    Overall Loss 0.055310    Objective Loss 0.055310                                        LR 0.100000    Time 0.027107    
2022-01-25 18:32:52,605 - Epoch: [96][  150/  211]    Overall Loss 0.055025    Objective Loss 0.055025                                        LR 0.100000    Time 0.026990    
2022-01-25 18:32:52,885 - Epoch: [96][  160/  211]    Overall Loss 0.056092    Objective Loss 0.056092                                        LR 0.100000    Time 0.027050    
2022-01-25 18:32:53,131 - Epoch: [96][  170/  211]    Overall Loss 0.056929    Objective Loss 0.056929                                        LR 0.100000    Time 0.026901    
2022-01-25 18:32:53,413 - Epoch: [96][  180/  211]    Overall Loss 0.056847    Objective Loss 0.056847                                        LR 0.100000    Time 0.026972    
2022-01-25 18:32:53,660 - Epoch: [96][  190/  211]    Overall Loss 0.056480    Objective Loss 0.056480                                        LR 0.100000    Time 0.026849    
2022-01-25 18:32:53,949 - Epoch: [96][  200/  211]    Overall Loss 0.056037    Objective Loss 0.056037                                        LR 0.100000    Time 0.026951    
2022-01-25 18:32:54,192 - Epoch: [96][  210/  211]    Overall Loss 0.056382    Objective Loss 0.056382    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.026826    
2022-01-25 18:32:54,211 - Epoch: [96][  211/  211]    Overall Loss 0.056377    Objective Loss 0.056377    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.026788    
2022-01-25 18:32:54,270 - --- validate (epoch=96)-----------
2022-01-25 18:32:54,271 - 6000 samples (256 per mini-batch)
2022-01-25 18:32:54,748 - Epoch: [96][   10/   24]    Loss 0.060061    Top1 98.671875    Top5 100.000000    
2022-01-25 18:32:54,947 - Epoch: [96][   20/   24]    Loss 0.059716    Top1 98.613281    Top5 99.980469    
2022-01-25 18:32:55,030 - Epoch: [96][   24/   24]    Loss 0.061410    Top1 98.550000    Top5 99.966667    
2022-01-25 18:32:55,093 - ==> Top1: 98.550    Top5: 99.967    Loss: 0.061

2022-01-25 18:32:55,094 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 683   1   0   0   0   0   4   0   0]
 [  0   0 580   0   0   0   0   5   1   0]
 [  0   0   3 570   0   6   0   3   1   0]
 [  0   1   1   0 557   0   1   0   0   5]
 [  0   0   0   2   1 513   0   0   1   1]
 [  1   2   0   0   1   5 621   0   1   0]
 [  0   0   2   0   1   0   0 622   0   0]
 [  1   0   0   0   1   0   1   1 580   0]
 [  2   4   1   1  11   1   0   6   5 584]]

2022-01-25 18:32:55,096 - ==> Best [Top1: 98.700   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 93]
2022-01-25 18:32:55,096 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:32:55,103 - 

2022-01-25 18:32:55,103 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:32:55,808 - Epoch: [97][   10/  211]    Overall Loss 0.054116    Objective Loss 0.054116                                        LR 0.100000    Time 0.070429    
2022-01-25 18:32:56,016 - Epoch: [97][   20/  211]    Overall Loss 0.053639    Objective Loss 0.053639                                        LR 0.100000    Time 0.045586    
2022-01-25 18:32:56,239 - Epoch: [97][   30/  211]    Overall Loss 0.053688    Objective Loss 0.053688                                        LR 0.100000    Time 0.037810    
2022-01-25 18:32:56,449 - Epoch: [97][   40/  211]    Overall Loss 0.054944    Objective Loss 0.054944                                        LR 0.100000    Time 0.033618    
2022-01-25 18:32:56,674 - Epoch: [97][   50/  211]    Overall Loss 0.056064    Objective Loss 0.056064                                        LR 0.100000    Time 0.031374    
2022-01-25 18:32:56,894 - Epoch: [97][   60/  211]    Overall Loss 0.057938    Objective Loss 0.057938                                        LR 0.100000    Time 0.029805    
2022-01-25 18:32:57,114 - Epoch: [97][   70/  211]    Overall Loss 0.057073    Objective Loss 0.057073                                        LR 0.100000    Time 0.028693    
2022-01-25 18:32:57,330 - Epoch: [97][   80/  211]    Overall Loss 0.056994    Objective Loss 0.056994                                        LR 0.100000    Time 0.027798    
2022-01-25 18:32:57,552 - Epoch: [97][   90/  211]    Overall Loss 0.057594    Objective Loss 0.057594                                        LR 0.100000    Time 0.027171    
2022-01-25 18:32:57,772 - Epoch: [97][  100/  211]    Overall Loss 0.057216    Objective Loss 0.057216                                        LR 0.100000    Time 0.026650    
2022-01-25 18:32:57,992 - Epoch: [97][  110/  211]    Overall Loss 0.056822    Objective Loss 0.056822                                        LR 0.100000    Time 0.026229    
2022-01-25 18:32:58,214 - Epoch: [97][  120/  211]    Overall Loss 0.056492    Objective Loss 0.056492                                        LR 0.100000    Time 0.025889    
2022-01-25 18:32:58,434 - Epoch: [97][  130/  211]    Overall Loss 0.055668    Objective Loss 0.055668                                        LR 0.100000    Time 0.025588    
2022-01-25 18:32:58,641 - Epoch: [97][  140/  211]    Overall Loss 0.055400    Objective Loss 0.055400                                        LR 0.100000    Time 0.025235    
2022-01-25 18:32:58,865 - Epoch: [97][  150/  211]    Overall Loss 0.055656    Objective Loss 0.055656                                        LR 0.100000    Time 0.025045    
2022-01-25 18:32:59,079 - Epoch: [97][  160/  211]    Overall Loss 0.055796    Objective Loss 0.055796                                        LR 0.100000    Time 0.024814    
2022-01-25 18:32:59,340 - Epoch: [97][  170/  211]    Overall Loss 0.055973    Objective Loss 0.055973                                        LR 0.100000    Time 0.024889    
2022-01-25 18:32:59,588 - Epoch: [97][  180/  211]    Overall Loss 0.055962    Objective Loss 0.055962                                        LR 0.100000    Time 0.024877    
2022-01-25 18:32:59,866 - Epoch: [97][  190/  211]    Overall Loss 0.055778    Objective Loss 0.055778                                        LR 0.100000    Time 0.025032    
2022-01-25 18:33:00,116 - Epoch: [97][  200/  211]    Overall Loss 0.056047    Objective Loss 0.056047                                        LR 0.100000    Time 0.025027    
2022-01-25 18:33:00,396 - Epoch: [97][  210/  211]    Overall Loss 0.056236    Objective Loss 0.056236    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.025166    
2022-01-25 18:33:00,414 - Epoch: [97][  211/  211]    Overall Loss 0.056290    Objective Loss 0.056290    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.025134    
2022-01-25 18:33:00,470 - --- validate (epoch=97)-----------
2022-01-25 18:33:00,471 - 6000 samples (256 per mini-batch)
2022-01-25 18:33:00,942 - Epoch: [97][   10/   24]    Loss 0.053952    Top1 98.593750    Top5 100.000000    
2022-01-25 18:33:01,139 - Epoch: [97][   20/   24]    Loss 0.055356    Top1 98.632812    Top5 100.000000    
2022-01-25 18:33:01,225 - Epoch: [97][   24/   24]    Loss 0.054998    Top1 98.616667    Top5 100.000000    
2022-01-25 18:33:01,280 - ==> Top1: 98.617    Top5: 100.000    Loss: 0.055

2022-01-25 18:33:01,281 - ==> Confusion:
[[601   0   1   0   0   0   1   0   0   2]
 [  0 686   1   0   0   0   1   0   0   0]
 [  0   0 577   0   1   0   1   4   2   1]
 [  1   1   4 568   0   4   0   3   1   1]
 [  0   2   0   0 554   0   0   1   1   7]
 [  0   0   0   1   1 509   6   0   0   1]
 [  2   0   0   0   0   0 629   0   0   0]
 [  0   3   3   0   1   0   0 618   0   0]
 [  1   1   0   0   3   2   4   1 569   3]
 [  0   3   0   0   2   1   0   0   3 606]]

2022-01-25 18:33:01,284 - ==> Best [Top1: 98.700   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 93]
2022-01-25 18:33:01,284 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:33:01,291 - 

2022-01-25 18:33:01,292 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:33:01,847 - Epoch: [98][   10/  211]    Overall Loss 0.049526    Objective Loss 0.049526                                        LR 0.100000    Time 0.055496    
2022-01-25 18:33:02,058 - Epoch: [98][   20/  211]    Overall Loss 0.053355    Objective Loss 0.053355                                        LR 0.100000    Time 0.038257    
2022-01-25 18:33:02,273 - Epoch: [98][   30/  211]    Overall Loss 0.050667    Objective Loss 0.050667                                        LR 0.100000    Time 0.032675    
2022-01-25 18:33:02,478 - Epoch: [98][   40/  211]    Overall Loss 0.049797    Objective Loss 0.049797                                        LR 0.100000    Time 0.029617    
2022-01-25 18:33:02,711 - Epoch: [98][   50/  211]    Overall Loss 0.052975    Objective Loss 0.052975                                        LR 0.100000    Time 0.028337    
2022-01-25 18:33:02,925 - Epoch: [98][   60/  211]    Overall Loss 0.052940    Objective Loss 0.052940                                        LR 0.100000    Time 0.027181    
2022-01-25 18:33:03,150 - Epoch: [98][   70/  211]    Overall Loss 0.053805    Objective Loss 0.053805                                        LR 0.100000    Time 0.026512    
2022-01-25 18:33:03,376 - Epoch: [98][   80/  211]    Overall Loss 0.055269    Objective Loss 0.055269                                        LR 0.100000    Time 0.026016    
2022-01-25 18:33:03,602 - Epoch: [98][   90/  211]    Overall Loss 0.054715    Objective Loss 0.054715                                        LR 0.100000    Time 0.025634    
2022-01-25 18:33:03,815 - Epoch: [98][  100/  211]    Overall Loss 0.055229    Objective Loss 0.055229                                        LR 0.100000    Time 0.025198    
2022-01-25 18:33:04,038 - Epoch: [98][  110/  211]    Overall Loss 0.055898    Objective Loss 0.055898                                        LR 0.100000    Time 0.024927    
2022-01-25 18:33:04,253 - Epoch: [98][  120/  211]    Overall Loss 0.055272    Objective Loss 0.055272                                        LR 0.100000    Time 0.024640    
2022-01-25 18:33:04,478 - Epoch: [98][  130/  211]    Overall Loss 0.055135    Objective Loss 0.055135                                        LR 0.100000    Time 0.024475    
2022-01-25 18:33:04,722 - Epoch: [98][  140/  211]    Overall Loss 0.054636    Objective Loss 0.054636                                        LR 0.100000    Time 0.024463    
2022-01-25 18:33:05,001 - Epoch: [98][  150/  211]    Overall Loss 0.054794    Objective Loss 0.054794                                        LR 0.100000    Time 0.024694    
2022-01-25 18:33:05,247 - Epoch: [98][  160/  211]    Overall Loss 0.054582    Objective Loss 0.054582                                        LR 0.100000    Time 0.024681    
2022-01-25 18:33:05,524 - Epoch: [98][  170/  211]    Overall Loss 0.054455    Objective Loss 0.054455                                        LR 0.100000    Time 0.024861    
2022-01-25 18:33:05,781 - Epoch: [98][  180/  211]    Overall Loss 0.054288    Objective Loss 0.054288                                        LR 0.100000    Time 0.024901    
2022-01-25 18:33:06,055 - Epoch: [98][  190/  211]    Overall Loss 0.054670    Objective Loss 0.054670                                        LR 0.100000    Time 0.025034    
2022-01-25 18:33:06,305 - Epoch: [98][  200/  211]    Overall Loss 0.054994    Objective Loss 0.054994                                        LR 0.100000    Time 0.025029    
2022-01-25 18:33:06,582 - Epoch: [98][  210/  211]    Overall Loss 0.055197    Objective Loss 0.055197    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.025157    
2022-01-25 18:33:06,601 - Epoch: [98][  211/  211]    Overall Loss 0.055235    Objective Loss 0.055235    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.025126    
2022-01-25 18:33:06,674 - --- validate (epoch=98)-----------
2022-01-25 18:33:06,674 - 6000 samples (256 per mini-batch)
2022-01-25 18:33:07,146 - Epoch: [98][   10/   24]    Loss 0.065502    Top1 97.968750    Top5 100.000000    
2022-01-25 18:33:07,410 - Epoch: [98][   20/   24]    Loss 0.064348    Top1 98.300781    Top5 99.980469    
2022-01-25 18:33:07,510 - Epoch: [98][   24/   24]    Loss 0.062711    Top1 98.366667    Top5 99.983333    
2022-01-25 18:33:07,568 - ==> Top1: 98.367    Top5: 99.983    Loss: 0.063

2022-01-25 18:33:07,568 - ==> Confusion:
[[598   0   3   0   0   0   3   0   0   1]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   3 573   4   0   0   0   2   2   2]
 [  1   0   2 576   0   2   0   2   0   0]
 [  0   1   1   0 551   0   0   0   0  12]
 [  0   2   0   1   1 513   1   0   0   0]
 [  3   4   0   0   3   3 617   0   1   0]
 [  0   9   4   0   0   0   0 611   0   1]
 [  0   0   0   3   1   1   3   0 572   4]
 [  0   3   0   0   2   1   1   1   2 605]]

2022-01-25 18:33:07,570 - ==> Best [Top1: 98.700   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 93]
2022-01-25 18:33:07,570 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:33:07,576 - 

2022-01-25 18:33:07,576 - Training epoch: 54000 samples (256 per mini-batch)
2022-01-25 18:33:08,333 - Epoch: [99][   10/  211]    Overall Loss 0.063348    Objective Loss 0.063348                                        LR 0.100000    Time 0.075576    
2022-01-25 18:33:08,582 - Epoch: [99][   20/  211]    Overall Loss 0.059876    Objective Loss 0.059876                                        LR 0.100000    Time 0.050239    
2022-01-25 18:33:08,830 - Epoch: [99][   30/  211]    Overall Loss 0.056265    Objective Loss 0.056265                                        LR 0.100000    Time 0.041761    
2022-01-25 18:33:09,126 - Epoch: [99][   40/  211]    Overall Loss 0.055446    Objective Loss 0.055446                                        LR 0.100000    Time 0.038712    
2022-01-25 18:33:09,420 - Epoch: [99][   50/  211]    Overall Loss 0.056415    Objective Loss 0.056415                                        LR 0.100000    Time 0.036834    
2022-01-25 18:33:09,639 - Epoch: [99][   60/  211]    Overall Loss 0.055470    Objective Loss 0.055470                                        LR 0.100000    Time 0.034340    
2022-01-25 18:33:09,914 - Epoch: [99][   70/  211]    Overall Loss 0.055184    Objective Loss 0.055184                                        LR 0.100000    Time 0.033349    
2022-01-25 18:33:10,130 - Epoch: [99][   80/  211]    Overall Loss 0.054897    Objective Loss 0.054897                                        LR 0.100000    Time 0.031876    
2022-01-25 18:33:10,355 - Epoch: [99][   90/  211]    Overall Loss 0.056154    Objective Loss 0.056154                                        LR 0.100000    Time 0.030837    
2022-01-25 18:33:10,583 - Epoch: [99][  100/  211]    Overall Loss 0.056641    Objective Loss 0.056641                                        LR 0.100000    Time 0.030026    
2022-01-25 18:33:10,809 - Epoch: [99][  110/  211]    Overall Loss 0.055576    Objective Loss 0.055576                                        LR 0.100000    Time 0.029347    
2022-01-25 18:33:11,025 - Epoch: [99][  120/  211]    Overall Loss 0.055177    Objective Loss 0.055177                                        LR 0.100000    Time 0.028699    
2022-01-25 18:33:11,241 - Epoch: [99][  130/  211]    Overall Loss 0.055054    Objective Loss 0.055054                                        LR 0.100000    Time 0.028150    
2022-01-25 18:33:11,454 - Epoch: [99][  140/  211]    Overall Loss 0.055159    Objective Loss 0.055159                                        LR 0.100000    Time 0.027663    
2022-01-25 18:33:11,686 - Epoch: [99][  150/  211]    Overall Loss 0.055802    Objective Loss 0.055802                                        LR 0.100000    Time 0.027358    
2022-01-25 18:33:11,900 - Epoch: [99][  160/  211]    Overall Loss 0.056070    Objective Loss 0.056070                                        LR 0.100000    Time 0.026983    
2022-01-25 18:33:12,125 - Epoch: [99][  170/  211]    Overall Loss 0.056079    Objective Loss 0.056079                                        LR 0.100000    Time 0.026720    
2022-01-25 18:33:12,335 - Epoch: [99][  180/  211]    Overall Loss 0.056249    Objective Loss 0.056249                                        LR 0.100000    Time 0.026398    
2022-01-25 18:33:12,628 - Epoch: [99][  190/  211]    Overall Loss 0.056430    Objective Loss 0.056430                                        LR 0.100000    Time 0.026553    
2022-01-25 18:33:12,870 - Epoch: [99][  200/  211]    Overall Loss 0.056527    Objective Loss 0.056527                                        LR 0.100000    Time 0.026434    
2022-01-25 18:33:13,150 - Epoch: [99][  210/  211]    Overall Loss 0.056705    Objective Loss 0.056705    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.026504    
2022-01-25 18:33:13,169 - Epoch: [99][  211/  211]    Overall Loss 0.056778    Objective Loss 0.056778    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.026466    
2022-01-25 18:33:13,241 - --- validate (epoch=99)-----------
2022-01-25 18:33:13,241 - 6000 samples (256 per mini-batch)
2022-01-25 18:33:13,713 - Epoch: [99][   10/   24]    Loss 0.057137    Top1 98.632812    Top5 100.000000    
2022-01-25 18:33:13,910 - Epoch: [99][   20/   24]    Loss 0.057900    Top1 98.652344    Top5 100.000000    
2022-01-25 18:33:13,993 - Epoch: [99][   24/   24]    Loss 0.057994    Top1 98.666667    Top5 100.000000    
2022-01-25 18:33:14,048 - ==> Top1: 98.667    Top5: 100.000    Loss: 0.058

2022-01-25 18:33:14,049 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 579   0   0   0   0   6   0   1]
 [  0   0   1 580   0   0   0   1   0   1]
 [  0   2   1   0 550   0   2   3   0   7]
 [  0   0   0   4   0 507   3   1   1   2]
 [  2   3   0   0   2   0 624   0   0   0]
 [  1   1   0   0   0   0   0 623   0   0]
 [  4   1   1   1   1   3   2   2 566   3]
 [  0   3   0   1   2   1   0   4   2 602]]

2022-01-25 18:33:14,051 - ==> Best [Top1: 98.700   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 93]
2022-01-25 18:33:14,051 - Saving checkpoint to: logs/2022.01.25-182220/qat_checkpoint.pth.tar
2022-01-25 18:33:14,058 - --- test ---------------------
2022-01-25 18:33:14,058 - 10000 samples (256 per mini-batch)
2022-01-25 18:33:14,394 - Test: [   10/   40]    Loss 0.029948    Top1 99.179688    Top5 100.000000    
2022-01-25 18:33:14,513 - Test: [   20/   40]    Loss 0.032188    Top1 99.082031    Top5 100.000000    
2022-01-25 18:33:14,665 - Test: [   30/   40]    Loss 0.032061    Top1 99.114583    Top5 99.986979    
2022-01-25 18:33:14,772 - Test: [   40/   40]    Loss 0.030705    Top1 99.120000    Top5 99.990000    
2022-01-25 18:33:14,835 - ==> Top1: 99.120    Top5: 99.990    Loss: 0.031

2022-01-25 18:33:14,835 - ==> Confusion:
[[ 979    0    0    1    0    0    0    0    0    0]
 [   0 1129    2    2    0    0    0    2    0    0]
 [   2    0 1027    0    0    0    0    3    0    0]
 [   0    0    0 1008    0    0    0    2    0    0]
 [   1    1    0    0  969    0    0    1    1    9]
 [   1    0    0    8    0  877    2    1    0    3]
 [   7    3    1    0    1    1  944    0    1    0]
 [   0    2    1    0    0    0    0 1025    0    0]
 [   1    0    4    3    1    2    0    1  957    5]
 [   0    0    0    0    6    1    0    4    0  998]]

2022-01-25 18:33:14,842 - 
2022-01-25 18:33:14,842 - Log file for this run: /disks/disk2/lishengyan/mcuev/max7800-dev/ai8x-training/logs/2022.01.25-182220/2022.01.25-182220.log
